{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dataloader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import time\n",
    "from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
    "# reload library\n",
    "import importlib\n",
    "import cv2\n",
    "#import utils as ut\n",
    "import pandas as pd\n",
    "import DataDLC\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import tqdm\n",
    "\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dataloader)\n",
    "importlib.reload(DataDLC)\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Load the data\n",
    "dataset = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\DataLoaderTestFormat\\dataset.pkl', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first graph in the dataset\n",
    "data = dataset[59].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = dataset[10].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.behaviour_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.frame_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = data.x\n",
    "edge_index = data.edge_index\n",
    "frame_mask = data.frame_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_undirected(edge_index):\n",
    "    # Sort the edges to ensure each pair (u, v) and (v, u) is in the same order.\n",
    "    sorted_edges = edge_index.t().sort(dim=1)[0]\n",
    "    \n",
    "    # Find unique edges and count their occurrences.\n",
    "    unique_edges, counts = torch.unique(sorted_edges, dim=0, return_counts=True)\n",
    "    \n",
    "    # For the graph to be undirected, each unique edge should appear twice.\n",
    "    return torch.all(counts == 2), unique_edges, counts\n",
    "\n",
    "flag, unique_edges, counts = is_undirected(edge_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counts.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the edges that have other than 2 counts and their counts\n",
    "print(len(unique_edges[counts == 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = edge_index.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graph\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "G1 = nx.Graph()\n",
    "G.add_nodes_from(range(node_features.shape[0]))\n",
    "G1.add_nodes_from(range(node_features.shape[0]))\n",
    "edge_color = []\n",
    "edge1_color = []\n",
    "edges = []\n",
    "for edge in edge_index.T:\n",
    "    #if node_features[edge[0], 4] != node_features[edge[1], 4]:\n",
    "    if frame_mask[edge[0]] != frame_mask[edge[1]]:\n",
    "        G1.add_edge(edge[0], edge[1], color='y')\n",
    "        edges.append((edge[0], edge[1]))\n",
    "        edge1_color.append('y')\n",
    "        print('r')\n",
    "    else:\n",
    "        edges.append((edge[0], edge[1]))\n",
    "        G.add_edge(edge[0], edge[1], color='k')\n",
    "        edge_color.append('k')\n",
    "\n",
    "#G.add_edges_from(edge_index.T.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.frame_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The position of the nodes is the node features (first two dimensions), add +1 in x coord for different frames\n",
    "# Put different colors to the nodes depending on the node features\n",
    "colors = node_features[:, 3].numpy()\n",
    "# if colors is 0 -> red, if 1 -> yellow\n",
    "colors = ['r' if c == 0 else 'b' for c in colors]\n",
    "\n",
    "# Node sizes\n",
    "size = 100\n",
    "# alpha of the edges\n",
    "alpha = 0.3\n",
    "# Position of the nodes\n",
    "pos = node_features[:, :2].numpy()\n",
    "# Add data.frame_mask to the x coordinate\n",
    "# Frame difference\n",
    "frame_x_diff = data.frame_mask.numpy().copy()\n",
    "# Normalize the frame difference\n",
    "frame_x_diff = ((frame_x_diff - frame_x_diff.min())*2) / (frame_x_diff.max() - frame_x_diff.min())\n",
    "pos[:, 0] += frame_x_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_x_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count values of data.frame_mask.numpy()\n",
    "unique, counts = np.unique(data.frame_mask.numpy(), return_counts=True)\n",
    "dict(zip(unique, counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graph\n",
    "plt.figure(figsize=(25, 8))\n",
    "\n",
    "# Draw edges with different colors and alpha values\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.7, edge_color=edge_color, width=2)\n",
    "nx.draw_networkx_edges(G1, pos, alpha=0.5, edge_color=edge1_color, width=2, style='dashed')\n",
    "\n",
    "# Draw nodes with different colors and sizes\n",
    "node_sizes = [size if color == 'r' else size for color in colors]\n",
    "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=colors, edgecolors='k', linewidths=0.5)\n",
    "\n",
    "# Add legend for the nodes\n",
    "plt.scatter([], [], c='r', label='Individual 1', s=100, edgecolors='k')\n",
    "plt.scatter([], [], c='b', label='Individual 2', s=100, edgecolors='k')\n",
    "\n",
    "# Add legend for the edges\n",
    "plt.plot([], [], c='k', label='Spatial edges (same frame)', linewidth=2)\n",
    "plt.plot([], [], c='y', label='Temporal edges (different frame)', linewidth=2, linestyle='dashed')\n",
    "\n",
    "# Plot a discrete x-axis to show the frames\n",
    "centers = np.arange(pos[:, 0].min() - 0.1, pos[:, 0].max() + 0.1, (pos[:, 0].max() - pos[:, 0].min() + 0.2) / 5)\n",
    "frames = ['Frame: -2', 'Frame: -1', 'Frame: 0', 'Frame: 1', 'Frame: 2']\n",
    "\n",
    "num_frames = 5\n",
    "for i in range(num_frames):\n",
    "    plt.text(centers[i] + 0.2, pos[:, 1].min() - 0.1, frames[i], fontsize=12, fontweight='bold', color='darkblue')\n",
    "    plt.plot([centers[i], centers[i]], [pos[:, 1].min() - 0.1, pos[:, 1].max() + 0.1], 'k--')\n",
    "\n",
    "# Indicate the frame number\n",
    "plt.xlabel('Frame number', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Y Coordinate', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Center the x-axis\n",
    "plt.legend(loc='upper right', fontsize=12)\n",
    "plt.title('Spatio-Temporal Graph of Pose-Estimated Mice', fontsize=16, fontweight='bold')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets only plot the nodes that are in a same frame\n",
    "nodes_features_to_keep = node_features[node_features[:,4]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_features_to_keep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_index of the nodes that are in the same frame\n",
    "G = nx.Graph()\n",
    "\n",
    "# Get the indices of the nodes that are in the same frame\n",
    "nodes_in_frame = np.where(node_features[:,4]==0)[0]\n",
    "nodes_features_to_keep = node_features[node_features[:,4]==0]\n",
    "\n",
    "G.add_nodes_from(nodes_in_frame)\n",
    "\n",
    "edge_index = edge_index.numpy()\n",
    "\n",
    "# Keep only the edges that are between nodes in the same frame\n",
    "for i in range(edge_index.shape[1]):\n",
    "    if edge_index[0, i] in nodes_in_frame and edge_index[1, i]in nodes_in_frame:\n",
    "        G.add_edge(edge_index[0, i], edge_index[1, i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_in_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index[0, 0]\n",
    "edge_index[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_features_to_keep[:,:2].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# The position of the nodes is the node features (first two dimensions), add +1 in x coord for different frames\n",
    "pos = node_features[:, :2].numpy()\n",
    "# mappi\n",
    "colors = nodes_features_to_keep[:, 3].numpy()\n",
    "# if colors is 0 -> red, if 1 -> yellow\n",
    "colors = ['r' if c == 0 else 'y' for c in colors]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(25, 8))\n",
    "nx.draw_networkx_nodes(G, pos, node_size=40, node_color=colors)\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just Loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "def load_checkpoint(model, optimizer, path, device):\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded from {path}, at epoch {epoch}\")\n",
    "    return model, optimizer, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\runs\\new_encoder_no_linearResCon\\Dominance_R\\checkpoint_epoch_190.pth', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphencoder = models.GATEncoder_vfollowing(8, 16, 2, 4, dropout=0.5)\n",
    "class_head = models.ClassificationHead(n_latent=576, nhid = 32, nout = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "readout = 'concatenate'\n",
    "model = models.GraphClassifier(graphencoder, class_head, readout= readout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in checkpoint['model_state_dict']:\n",
    "    print(key, checkpoint['model_state_dict'][key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes of the model\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count parameters\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of validation accuracy per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\runs\\new_encoder_no_linearResCon\\Rearing_R\\Oct17_22-38-17\\csv.csv'\n",
    "\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Wall time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate rows 180 and 181 \n",
    "df.drop([40,41,42,43], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[30:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = df['Step']\n",
    "values = df['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only each 10 epochs\n",
    "steps = steps[::10]\n",
    "values = values[::10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = steps[:-3]\n",
    "values = values[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = values.max()\n",
    "max_step = steps[values.idxmax()]\n",
    "\n",
    "print(f\"Max value: {max_value} at step {max_step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df['Step'], df['Value'], alpha = 0.5, label = 'All epochs')\n",
    "sns.lineplot(x=steps, y=values, marker='o', color='b', label = 'Saved chackpoints (Every 10 epochs)')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Epoch', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.title('Average of per-class accuracy over epochs', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Customize the ticks\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# The reference in the x axis each 10 epochs\n",
    "plt.xticks(steps)\n",
    "\n",
    "\n",
    "# Add a grid\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Trace lines on the max value\n",
    "plt.axvline(x=max_step, color='r', ymax=0.88, linestyle='--', linewidth=1)\n",
    "plt.axhline(y=max_value, color='r', xmax=0.85, linestyle='--', linewidth=1)\n",
    "\n",
    "# Plot to 200 epochs\n",
    "plt.xlim(0, 200)\n",
    "# Indicate the max value\n",
    "plt.text(max_step+15, max_value+0.001, f'{max_value:.4f}', color='r', fontsize=12, fontweight='bold', ha='right')\n",
    "\n",
    "# Add a marker for the max value\n",
    "plt.scatter(max_step, max_value, color='r', s=80, zorder=5, edgecolors='w', label='Max Value')\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confussion martices for GAT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dataloader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import time\n",
    "from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
    "# reload library\n",
    "import importlib\n",
    "import cv2\n",
    "#import utils as ut\n",
    "import pandas as pd\n",
    "import DataDLC\n",
    "from torch_geometric.data import Data, DataLoader, DataListLoader\n",
    "import tqdm\n",
    "import time\n",
    "import augmentation\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import f1_score and matthews_corrcoef from sklearn\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "dataset = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\datasets\\dataset_5.pkl', map_location=device)\n",
    "\n",
    "#Index(['General_Contacts', 'Sniffing_R', 'Sniffing_head_R', 'Sniffing_other_R',\n",
    "    #    'Sniffing_anal_R', 'Poursuit_R', 'Dominance_R', 'Rearing_R',\n",
    "    #    'Grooming_R', 'Sniffing_V', 'Sniffing_head_V', 'Sniffing_other_V',\n",
    "    #    'Sniffing_anal_V', 'Poursuit_V', 'Dominance_V', 'Rearing_V',\n",
    "    #    'Grooming_V'],\n",
    "    #   dtype='object')\n",
    "# Select the behaviour to classify (Grooming in this case)\n",
    "indx_behaviour1 = 3\n",
    "indx_behaviour2 = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the behaviour to classify\n",
    "name_behaviour = dataset[0].behaviour_names[indx_behaviour1]\n",
    "print(f\"Behaviour selected: {name_behaviour}\")\n",
    "\n",
    "# Suffle the dataset\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "# Split train and test\n",
    "train_size = int(0.8 * len(dataset))\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "test_dataset = dataset[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Merging the behaviours')\n",
    "augmentation.merge_symetric_behaviours_version2(indx_behaviour1, indx_behaviour2, train_dataset, device=device)\n",
    "print('Generating rotation augmentation')\n",
    "# Rotate the dataset\n",
    "augmentation.rotate_samples(train_dataset, indx_behaviour1, device=device)\n",
    "#print('Downsampling the inactive behaviours')\n",
    "#train_dataset = augmentation.downsample_majority_class(train_dataset, indx_behaviour1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_dataset)):\n",
    "    test_dataset[i].behaviour = test_dataset[i].behaviour[indx_behaviour1]\n",
    "for i in range(len(train_dataset)):\n",
    "    train_dataset[i].behaviour = train_dataset[i].behaviour[indx_behaviour1]\n",
    "print('Done selecting the behaviour')\n",
    "\n",
    "print('The test dataset has %d samples' % len(test_dataset))\n",
    "print('The train dataset has %d samples' % len(train_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class balance\n",
    "behaviour = [data.behaviour.item() for data in train_dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balance\n",
    "unique, counts = np.unique(behaviour, return_counts=True)\n",
    "\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphencoder = models.GATEncoder(nout = 64, nhid=32, attention_heads = 2, n_in = 4, n_layers=4, dropout=0.2)\n",
    "class_head = models.ClassificationHead(n_latent=64, nhid = 32, nout = 2)\n",
    "\n",
    "readout = 'mean'\n",
    "model = models.GraphClassifier(graphencoder, class_head, readout=readout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "metric_0 = f1_score\n",
    "metric_1 = matthews_corrcoef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, path):\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded from {path}, at epoch {epoch}\")\n",
    "    return epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\Checkpoints\\new_encoder_no_linearResCon\\Sniffing_R\\checkpoint_epoch_150.pth'\n",
    "actual_epoch = load_checkpoint(model, optimizer, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "val_loss = 0\n",
    "correct = 0\n",
    "correct_class_0 = 0\n",
    "correct_class_1 = 0\n",
    "total_class_0 = 0\n",
    "total_class_1 = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for val_data in tqdm.tqdm(test_loader):\n",
    "        val_outputs = model(val_data)\n",
    "        val_labels = val_data.behaviour\n",
    "        val_predicted = val_outputs.argmax(dim=1)\n",
    "        correct_class_0 += (val_predicted[val_labels == 0] == val_labels[val_labels == 0]).sum().item()\n",
    "        correct_class_1 += (val_predicted[val_labels == 1] == val_labels[val_labels == 1]).sum().item()\n",
    "        total_class_0 += (val_labels == 0).sum().item()\n",
    "        total_class_1 += (val_labels == 1).sum().item()\n",
    "        correct += (val_predicted == val_labels).sum().item()\n",
    "        total += val_labels.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = correct / total\n",
    "print(f'Accuracy of the network on the test set: {100 * val_accuracy:.2f}%')\n",
    "\n",
    "val_accuracy_class_0 = correct_class_0 / total_class_0\n",
    "val_accuracy_class_1 = correct_class_1 / total_class_1\n",
    "print(f'Accuracy of the network on the test set for class 0: {100 * val_accuracy_class_0:.2f}%')\n",
    "print(f'Accuracy of the network on the test set for class 1: {100 * val_accuracy_class_1:.2f}%')\n",
    "\n",
    "avg_val_accuracy = (val_accuracy_class_0 + val_accuracy_class_1) / 2\n",
    "print(f'Average accuracy of the network on the test set: {100 * avg_val_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the confusion matrix\n",
    "cm = np.array([[\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_labels = torch.cat(val_labels, dim=0).cpu().numpy()\n",
    "val_preds = torch.cat(val_preds, dim=0).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_labels)\n",
    "len(val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the metrics\n",
    "f1_class_0 = metric_0(val_labels, val_preds, average='macro')\n",
    "mcc = metric_1(val_labels, val_preds)\n",
    "\n",
    "print(f'F1 Score (Class 0): {f1_class_0:.4f}')\n",
    "print(f'Matthews Correlation Coefficient: {mcc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm= sklearn.metrics.confusion_matrix(val_labels, val_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loqd pkl file\n",
    "\n",
    "path = r'c:\\Users\\Usuario\\Downloads\\results_epoch_150.pkl'\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    metrics = pkl.load(f)\n",
    "\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cm = np.array([[metrics['correct_class_0'], metrics['total_class_0'] - metrics['correct_class_0']], [metrics['total_class_1'] - metrics['correct_class_1'], metrics['correct_class_1']]])\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the confusion matrix\n",
    "\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt = '.2f', annot_kws={\"size\": 12}, cmap='Blues', cbar=False, linewidths=0.5, linecolor='k')\n",
    "             \n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Predicted', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True', fontsize=14, fontweight='bold')\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Customize the ticks\n",
    "plt.xticks([0.5, 1.5], ['Class 0', 'Class 1'], fontsize=12)\n",
    "plt.yticks([0.5, 1.5], ['Class 0', 'Class 1'], fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Classes Balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "dataset = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\datasets\\dataset_5.pkl', map_location=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select behaviour\n",
    "behaviour_idx = 0\n",
    "\n",
    "\n",
    "print(dataset[0].behaviour_names[behaviour_idx])\n",
    "\n",
    "label = []\n",
    "for i in range(len(dataset)):\n",
    "    label.append(dataset[i].behaviour[behaviour_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance\n",
    "unique, counts = np.unique(label, return_counts=True)\n",
    "print('Unique labels:', unique)\n",
    "print('Counts:', counts)\n",
    "\n",
    "print(\"The percentage of the minority class is: \", counts[1] / counts.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\runs\\new_encoder_no_linearResCon\\General_Contacts\\checkpoint_epoch_300.pth'\n",
    "\n",
    "# Load the model\n",
    "def load_checkpoint(model, optimizer, path, device):\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded from {path}, at epoch {epoch}\")\n",
    "    return epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "#graphencoder = models.GATEncoder(nout = 64, nhid=32, attention_hidden=2, n_in=4, dropout=0.5)\n",
    "#class_head = models.ClassificationHead(n_latent=64, nhid = 32, nout = 2)\n",
    "# Define the model\n",
    "graphencoder = models.GATEncoder(nout = 64, nhid=32, attention_heads = 2, n_in = 4, n_layers=4, dropout=0.2)\n",
    "class_head = models.ClassificationHead(n_latent=64, nhid = 32, nout = 2)\n",
    "\n",
    "readout = 'mean'\n",
    "model = models.GraphClassifier(graphencoder, class_head, readout= readout)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the checkpoint\n",
    "load_checkpoint(model, optimizer, path, device = 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envProj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
