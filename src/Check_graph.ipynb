{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import augmentation\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_8132\\3113225343.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\datasets\\entire_dataset_w11.pkl')\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\datasets\\entire_dataset_w11.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if both directions of the edges are present in the graphs\n",
    "\n",
    "**Rmk:** We will check also if the edges are not repeated (this is not as bad as missing edges, because we are using attention mechanism, so the attention will take care of ...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first graph of the dataset\n",
    "del graph_0\n",
    "graph_0 = dataset[1].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = graph_0.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert edge_index to list of tuples\n",
    "edges = edge_index.t().tolist()  # Transpose and convert to list\n",
    "\n",
    "# Convert edges to a set of tuples for fast lookups\n",
    "edge_set = set(map(tuple, edges))\n",
    "count = 0\n",
    "\n",
    "# Add reverse edges if missing\n",
    "for edge in edges:\n",
    "    reverse_edge = (edge[1], edge[0])\n",
    "    if reverse_edge not in edge_set and edge[0] != edge[1]:  # Ensure reverse edge doesn't exist, and avoid self-loops\n",
    "        edge_set.add(reverse_edge)  # Add the reverse edge\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8640\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(edges))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_reverse_edges(data):\n",
    "    edge_index = data.edge_index\n",
    "    \n",
    "    # Convert edge_index to list of tuples\n",
    "    edges = edge_index.t().tolist()  # Transpose and convert to list\n",
    "    \n",
    "    # Convert edges to a set of tuples for fast lookups\n",
    "    edge_set = set(map(tuple, edges))\n",
    "    \n",
    "    # Add reverse edges if missing\n",
    "    for edge in edges:\n",
    "        reverse_edge = (edge[1], edge[0])\n",
    "        if reverse_edge not in edge_set and edge[0] != edge[1]:  # Ensure reverse edge doesn't exist, and avoid self-loops\n",
    "            edge_set.add(reverse_edge)  # Add the reverse edge\n",
    "    \n",
    "    # Convert back to tensor\n",
    "    updated_edge_index = torch.tensor(list(edge_set), dtype=torch.long).t()  # Transpose back\n",
    "    \n",
    "    # Update the edge_index in the Data object\n",
    "    data.edge_index = updated_edge_index\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_12396\\3113225343.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\datasets\\entire_dataset_w11.pkl')\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\datasets\\entire_dataset_w11.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/309369 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3155/309369 [00:35<56:45, 89.92it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(dataset):\n\u001b[1;32m----> 2\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43madd_missing_reverse_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m, in \u001b[0;36madd_missing_reverse_edges\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     12\u001b[0m     reverse_edge \u001b[38;5;241m=\u001b[39m (edge[\u001b[38;5;241m1\u001b[39m], edge[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reverse_edge \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m edge_set \u001b[38;5;129;01mand\u001b[39;00m edge[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m edge[\u001b[38;5;241m1\u001b[39m]:  \u001b[38;5;66;03m# Ensure reverse edge doesn't exist, and avoid self-loops\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m         edge_set\u001b[38;5;241m.\u001b[39madd(reverse_edge)  \u001b[38;5;66;03m# Add the reverse edge\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Convert back to tensor\u001b[39;00m\n\u001b[0;32m     17\u001b[0m updated_edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mlist\u001b[39m(edge_set), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mt()  \u001b[38;5;66;03m# Transpose back\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_dataset = []\n",
    "\n",
    "for data in tqdm.tqdm(dataset):\n",
    "    data = add_missing_reverse_edges(data)\n",
    "    new_dataset.append(data)\n",
    "\n",
    "torch.save(new_dataset, r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\datasets\\new_entire_dataset_w11.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
