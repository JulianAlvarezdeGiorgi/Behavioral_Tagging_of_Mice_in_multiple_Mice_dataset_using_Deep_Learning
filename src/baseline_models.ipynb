{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader\n",
    "import DataDLC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import importlib\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'DataDLC' from 'c:\\\\Users\\\\jalvarez\\\\Documents\\\\Code\\\\GitHubCOde\\\\Behavioral_Tagging_of_Mice_in_multiple_Mice_dataset_using_Deep_Learning\\\\src\\\\DataDLC.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dataloader)\n",
    "importlib.reload(DataDLC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load DMD_null male dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DMD_fem_Test_10DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_11DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_12DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_13DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_14DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_15DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_16DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_17DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_18DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_19DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_1DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_20DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_21DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_22DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_23DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_24DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_25DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_26DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_27DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_28DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_29DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_2DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_30DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_31DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_32DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_3DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_4DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_5DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_6DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_7DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_8DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_fem_Test_9DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_mal_Test_10DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_mal_Test_1DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_mal_Test_2DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_mal_Test_32DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_mal_Test_3DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_mal_Test_4DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_mal_Test_5DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_mal_Test_6DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_mal_Test_7DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_mal_Test_8DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_mal_Test_9DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5']\n",
      "Loading data from d:\\Rearing, where we have 43 files\n",
      "We have 43 files\n",
      "Loading file DMD_fem_Test_10DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_11DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_12DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_13DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_14DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_15DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_16DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_17DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_18DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_19DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_1DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_20DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_21DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_22DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_23DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_24DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_25DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_26DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_27DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_28DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_29DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_2DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_30DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_31DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_32DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_3DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_4DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_5DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_6DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_7DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_8DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_fem_Test_9DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_mal_Test_10DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_mal_Test_1DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_mal_Test_2DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_mal_Test_32DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_mal_Test_3DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_mal_Test_4DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_mal_Test_5DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_mal_Test_6DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_mal_Test_7DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_mal_Test_8DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Loading file DMD_mal_Test_9DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n",
      "Number of files: 43\n"
     ]
    }
   ],
   "source": [
    "# Deactivate warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_loader = dataloader.DLCDataLoader(r'd:\\Rearing', build_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata_loader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "data_loader[0][0].values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the trainning and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_loader.data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['General_Contacts', 'Sniffing_R', 'Sniffing_head_R', 'Sniffing_other_R',\n",
       "       'Sniffing_anal_R', 'Poursuit_R', 'Dominance_R', 'Rearing_R',\n",
       "       'Grooming_R', 'Sniffing_V', 'Sniffing_head_V', 'Sniffing_other_V',\n",
       "       'Sniffing_anal_V', 'Poursuit_V', 'Dominance_V', 'Rearing_V',\n",
       "       'Grooming_V'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# behaviour names\n",
    "beh_names = dataset[0][1].columns\n",
    "beh_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:00<00:00, 367.75it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "coords_R = []\n",
    "\n",
    "behaviour = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(dataset))):\n",
    "\n",
    "    ### Prepare a dataset wich is simply all the points concatenated\n",
    "    n_frames, n_features_coords = dataset[i][0].shape\n",
    "    coords = dataset[i][0]\n",
    "    if coords.shape[0] != dataset[i][1].shape[0]:\n",
    "        print(\"Warrning: \", i, \" \", coords.shape[0], \" \", dataset[i][1].shape[0])\n",
    "    coords_R.append(coords.copy())\n",
    "    \n",
    "    behaviour.append(dataset[i][1].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate(behaviour)\n",
    "X = np.concatenate(coords_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113124, 108)\n",
      "(113124, 17)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check the size of the videos to see the bounderies, the trainning videos were cropped to (640,480)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video size:  640 480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a video\n",
    "path = r'c:\\Users\\jalvarez\\Documents\\Data\\DLC_analyzedvid\\MDX5CV_wo_tail\\MDX5CV male\\MDXCV_mal_Test_1.mp4'\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(path)\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "# Get the size of the video\n",
    "height, width, _ = frame.shape\n",
    "\n",
    "print(\"Video size: \", width, height)\n",
    "\n",
    "# Close everything\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " before clipping:  1.0 0.0\n",
      " before clipping:  1.0 0.0\n",
      " after clipping:  1.0 0.0\n",
      " after clipping:  1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# Introduce boundaries in features\n",
    "x_lim = [0, width]\n",
    "y_lim = [0, height]\n",
    "\n",
    "# Cast outliers to the limits\n",
    "print( ' before clipping: ', X_train[:, 0::3].max(), X_train[:, 0::3].min())\n",
    "print( ' before clipping: ', X_train[:, 1::3].max(), X_train[:, 1::3].min())\n",
    "X_train[:, 0::3] = np.clip(X_train[:, 0::3], x_lim[0], x_lim[1])\n",
    "X_train[:, 1::3] = np.clip(X_train[:, 1::3], y_lim[0], y_lim[1])\n",
    "X_test[:, 0::3] = np.clip(X_test[:, 0::3], x_lim[0], x_lim[1])\n",
    "X_test[:, 1::3] = np.clip(X_test[:, 1::3], y_lim[0], y_lim[1])\n",
    "print( ' after clipping: ', X_train[:, 0::3].max(), X_train[:, 0::3].min())\n",
    "print( ' after clipping: ', X_train[:, 1::3].max(), X_train[:, 1::3].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " after clipping:  1.0 0.0\n",
      " after clipping:  1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print( ' after clipping: ', X_train[:, 0::3].max(), X_train[:, 0::3].min())\n",
    "print( ' after clipping: ', X_train[:, 1::3].max(), X_train[:, 1::3].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90499, 108)\n",
      "(22625, 108)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'General_Contacts'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beh_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gencont_train = y_train[:, 0]\n",
    "y_gencont_test = y_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class balance\n",
    "plt.hist(y_gencont_train)\n",
    "plt.show()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline model\n",
    "model = joblib.load(r'C:\\Users\\jalvarez\\Documents\\Code\\GitHubCOde\\Behavioral_Tagging_of_Mice_in_multiple_Mice_dataset_using_Deep_Learning\\src\\baseline_models\\model_gencont.pkl')\n",
    "\n",
    "# Print the model and number of parameters\n",
    "print(model)\n",
    "total_params = 0\n",
    "for layer in model.coefs_:\n",
    "    total_params += layer.size\n",
    "print(\"Total number of parameters: \", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 train to see variance\n",
    "n_train = 5\n",
    "accs = []\n",
    "models = []\n",
    "for i in range(n_train):\n",
    "    print(\"Train \", i)\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, verbose=True, random_state=np.random.randint(0, 1000))\n",
    "    model.fit(X_train, y_gencont_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_gencont_test, y_pred)\n",
    "    accs.append(acc)\n",
    "    models.append(model)\n",
    "    print(\"Accuracy: \", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "print(\"Mean accuracy: \", np.mean(accs))\n",
    "print(\"Std accuracy: \", np.std(accs))\n",
    "print(\" variance accuracy: \", np.var(accs))\n",
    "\n",
    "print(\"The accuracy is:\", np.mean(accs), \" +/- \", np.std(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "model = models[np.argmax(accs)]\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_gencont_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_gencont_test, y_pred)\n",
    "cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure()\n",
    "plt.title('Confusion matrix of the best model for general contact')\n",
    "sns.heatmap(cm, annot=True, xticklabels=['Not Contact', 'Contact'], yticklabels=['Not Contact', 'Contact'], cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_gencont_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_gencont_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_gencont_test, y_pred)\n",
    "conf_matrix = conf_matrix / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(conf_matrix, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "joblib.dump(model, 'baseline_models/new_dataset/model_gencont.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_names[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sniff resident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sniffR_train = y_train[:, 1]\n",
    "y_sniffR_test = y_test[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Balance\n",
    "plt.hist(y_sniffR_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of parameters\n",
    "total_params = 0\n",
    "for layer in model.coefs_:\n",
    "    total_params += layer.size\n",
    "print(\"Total number of parameters: \", total_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 train to see variance\n",
    "n_train = 5\n",
    "accs = []\n",
    "models = []\n",
    "for i in range(n_train):\n",
    "    print(\"Train \", i)\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, verbose=True)\n",
    "    model.fit(X_train, y_sniffR_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_sniffR_test, y_pred)\n",
    "    accs.append(acc)\n",
    "    models.append(model)\n",
    "    print(\"Accuracy: \", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "print(\"Mean accuracy: \", np.mean(accs))\n",
    "print(\"Std accuracy: \", np.std(accs))\n",
    "print(\" variance accuracy: \", np.var(accs))\n",
    "\n",
    "print(\"The accuracy is:\", np.mean(accs), \" +/- \", np.std(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "model = models[np.argmax(accs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = joblib.load('baseline_models/new_dataset/model_sniffR.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_sniffR_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_sniffR_test, y_pred)\n",
    "cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure()\n",
    "plt.title('Confusion matrix of the best model for Sniffing')\n",
    "sns.heatmap(cm, annot=True, xticklabels=['No Sniffing', 'Sniffing'], yticklabels=['No Sniffing', 'Sniffing'], cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, 'baseline_models/new_dataset/model_sniffR.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = model.loss_curve_\n",
    "plt.plot(train_errors)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training Error')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, 'baseline_models/new_dataset/model_sniffR.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_names[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sniffing_head_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Shead_train = y_train[:, 2]\n",
    "y_Shead_test = y_test[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class balance\n",
    "plt.hist(y_Shead_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print(\"Train active: \", int(np.sum(y_Shead_train)))\n",
    "print(\"Train inactive: \", np.sum(y_Shead_train == 0))\n",
    "print(\"Percentage active: \", np.sum(y_Shead_train)*100 / len(y_Shead_train), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the inactive class\n",
    "idx = np.where(y_Shead_train == 0)[0]\n",
    "idx = np.random.choice(idx, np.sum(y_Shead_train == 1), replace=False)\n",
    "idx = np.concatenate([np.where(y_Shead_train == 1)[0], idx])\n",
    "\n",
    "X_train_Shead = X_train[idx]\n",
    "y_Shead_train = y_Shead_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class balance\n",
    "plt.hist(y_Shead_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 5\n",
    "accs = []\n",
    "models = []\n",
    "for i in range(n_train):\n",
    "    print(\"Train \", i)\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, verbose=True)\n",
    "    model.fit(X_train_Shead, y_Shead_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_Shead_test, y_pred)\n",
    "    accs.append(acc)\n",
    "    models.append(model)\n",
    "    print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy \n",
    "print(\"Mean accuracy: \", np.mean(accs))\n",
    "print(\"Std accuracy: \", np.std(accs))\n",
    "print(\"Accuracy = \", np.mean(accs), \" +/- \", np.std(accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model\n",
    "model = models[np.argmax(accs)]\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_Shead_test, y_pred)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_Shead_test, y_pred)\n",
    "cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure()\n",
    "plt.title('Confusion matrix of the best model for Sniffing Head')\n",
    "sns.heatmap(cm, annot=True, xticklabels=['Not Sniffing Head', 'Sniffing Head'], yticklabels=['Not Sniffing Head', 'Sniffing Head'], cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, 'baseline_models/new_dataset/model_Shead.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sniffing_other_R'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beh_names[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Sbody_train = y_train[:, 3]\n",
    "y_Sbody_test = y_test[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balance\n",
    "plt.hist(y_Sbody_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print(\"Train active: \", int(np.sum(y_Sbody_train)))\n",
    "print(\"Train inactive: \", np.sum(y_Sbody_train == 0))\n",
    "print(\"Percentage active: \", np.sum(y_Sbody_train)*100 / len(y_Sbody_train), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the inactive class\n",
    "idx = np.where(y_Sbody_train == 0)[0]\n",
    "idx = np.random.choice(idx, np.sum(y_Sbody_train == 1), replace=False)\n",
    "idx = np.concatenate([np.where(y_Sbody_train == 1)[0], idx])\n",
    "\n",
    "X_train_Sbody = X_train[idx]\n",
    "y_Sbody_train = y_Sbody_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class balance\n",
    "plt.hist(y_Sbody_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 5\n",
    "accs = []\n",
    "models = []\n",
    "for i in range(n_train):\n",
    "    print(\"Train \", i)\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, verbose=True)\n",
    "    model.fit(X_train_Sbody, y_Sbody_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_Sbody_test, y_pred)\n",
    "    accs.append(acc)\n",
    "    models.append(model)\n",
    "    print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "print(\"Mean accuracy: \", np.mean(accs))\n",
    "print(\"Std accuracy: \", np.std(accs))\n",
    "print(\"Accuracy = \", np.mean(accs), \" +/- \", np.std(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model\n",
    "model = models[np.argmax(accs)]\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_Sbody_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_Sbody_test, y_pred)\n",
    "cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure()\n",
    "plt.title('Confusion matrix of the best model for Sniffing Body')\n",
    "sns.heatmap(cm, annot=True, xticklabels=['Not Sniffing Body', 'Sniffing Body'], yticklabels=['Not Sniffing Body', 'Sniffing Body'], cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, 'baseline_models/new_dataset/model_Sbody.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sniffing_anal_R'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beh_names[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Sanus_train = y_train[:, 4]\n",
    "y_Sanus_test = y_test[:, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train active:  44036\n",
      "Train inactive:  204403\n",
      "Percentage active:  17.725075370614114 %\n"
     ]
    }
   ],
   "source": [
    "# Class balance\n",
    "plt.hist(y_Sanus_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print(\"Train active: \", int(np.sum(y_Sanus_train)))\n",
    "print(\"Train inactive: \", np.sum(y_Sanus_train == 0))\n",
    "print(\"Percentage active: \", np.sum(y_Sanus_train)*100 / len(y_Sanus_train), \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the inactive class\n",
    "idx = np.where(y_Sanus_train == 0)[0]\n",
    "idx = np.random.choice(idx, np.sum(y_Sanus_train == 1), replace=False)\n",
    "idx = np.concatenate([np.where(y_Sanus_train == 1)[0], idx])\n",
    "\n",
    "X_train_Sanus = X_train[idx]\n",
    "y_Sanus_train = y_Sanus_train[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class balance\n",
    "plt.hist(y_Sanus_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train  0\n",
      "Iteration 1, loss = 0.57969133\n",
      "Iteration 2, loss = 0.48421692\n",
      "Iteration 3, loss = 0.45755116\n",
      "Iteration 4, loss = 0.44780486\n",
      "Iteration 5, loss = 0.43989002\n",
      "Iteration 6, loss = 0.43571418\n",
      "Iteration 7, loss = 0.43009672\n",
      "Iteration 8, loss = 0.42811664\n",
      "Iteration 9, loss = 0.42484285\n",
      "Iteration 10, loss = 0.42219335\n",
      "Iteration 11, loss = 0.41866042\n",
      "Iteration 12, loss = 0.41658457\n",
      "Iteration 13, loss = 0.41373934\n",
      "Iteration 14, loss = 0.41295758\n",
      "Iteration 15, loss = 0.41039242\n",
      "Iteration 16, loss = 0.40882426\n",
      "Iteration 17, loss = 0.40638930\n",
      "Iteration 18, loss = 0.40533120\n",
      "Iteration 19, loss = 0.40432093\n",
      "Iteration 20, loss = 0.40136469\n",
      "Iteration 21, loss = 0.39901072\n",
      "Iteration 22, loss = 0.39820654\n",
      "Iteration 23, loss = 0.39377787\n",
      "Iteration 24, loss = 0.39526832\n",
      "Iteration 25, loss = 0.39305155\n",
      "Iteration 26, loss = 0.39141750\n",
      "Iteration 27, loss = 0.38827931\n",
      "Iteration 28, loss = 0.38904204\n",
      "Iteration 29, loss = 0.38617557\n",
      "Iteration 30, loss = 0.38346105\n",
      "Iteration 31, loss = 0.38302257\n",
      "Iteration 32, loss = 0.38100004\n",
      "Iteration 33, loss = 0.38277068\n",
      "Iteration 34, loss = 0.37846491\n",
      "Iteration 35, loss = 0.37959827\n",
      "Iteration 36, loss = 0.37870540\n",
      "Iteration 37, loss = 0.37460510\n",
      "Iteration 38, loss = 0.37388851\n",
      "Iteration 39, loss = 0.37220541\n",
      "Iteration 40, loss = 0.37094354\n",
      "Iteration 41, loss = 0.37043643\n",
      "Iteration 42, loss = 0.36805623\n",
      "Iteration 43, loss = 0.36788908\n",
      "Iteration 44, loss = 0.36691587\n",
      "Iteration 45, loss = 0.36638269\n",
      "Iteration 46, loss = 0.36640148\n",
      "Iteration 47, loss = 0.36421936\n",
      "Iteration 48, loss = 0.36231779\n",
      "Iteration 49, loss = 0.36211156\n",
      "Iteration 50, loss = 0.36091968\n",
      "Iteration 51, loss = 0.35975656\n",
      "Iteration 52, loss = 0.35876915\n",
      "Iteration 53, loss = 0.35825264\n",
      "Iteration 54, loss = 0.35730514\n",
      "Iteration 55, loss = 0.35695387\n",
      "Iteration 56, loss = 0.35635193\n",
      "Iteration 57, loss = 0.35428120\n",
      "Iteration 58, loss = 0.35424406\n",
      "Iteration 59, loss = 0.35431558\n",
      "Iteration 60, loss = 0.35402249\n",
      "Iteration 61, loss = 0.35048921\n",
      "Iteration 62, loss = 0.35210780\n",
      "Iteration 63, loss = 0.35049335\n",
      "Iteration 64, loss = 0.34953353\n",
      "Iteration 65, loss = 0.34741341\n",
      "Iteration 66, loss = 0.34826759\n",
      "Iteration 67, loss = 0.34728153\n",
      "Iteration 68, loss = 0.34754780\n",
      "Iteration 69, loss = 0.34551554\n",
      "Iteration 70, loss = 0.34500787\n",
      "Iteration 71, loss = 0.34566197\n",
      "Iteration 72, loss = 0.34197410\n",
      "Iteration 73, loss = 0.34160799\n",
      "Iteration 74, loss = 0.34111017\n",
      "Iteration 75, loss = 0.33983626\n",
      "Iteration 76, loss = 0.34036976\n",
      "Iteration 77, loss = 0.33903480\n",
      "Iteration 78, loss = 0.33782975\n",
      "Iteration 79, loss = 0.33804355\n",
      "Iteration 80, loss = 0.33692203\n",
      "Iteration 81, loss = 0.33555255\n",
      "Iteration 82, loss = 0.33401381\n",
      "Iteration 83, loss = 0.33478531\n",
      "Iteration 84, loss = 0.33465293\n",
      "Iteration 85, loss = 0.33366722\n",
      "Iteration 86, loss = 0.33363141\n",
      "Iteration 87, loss = 0.33235823\n",
      "Iteration 88, loss = 0.33243360\n",
      "Iteration 89, loss = 0.33067590\n",
      "Iteration 90, loss = 0.32910762\n",
      "Iteration 91, loss = 0.33031065\n",
      "Iteration 92, loss = 0.32706458\n",
      "Iteration 93, loss = 0.32768863\n",
      "Iteration 94, loss = 0.32822763\n",
      "Iteration 95, loss = 0.32573217\n",
      "Iteration 96, loss = 0.32547900\n",
      "Iteration 97, loss = 0.32436046\n",
      "Iteration 98, loss = 0.32319398\n",
      "Iteration 99, loss = 0.32541042\n",
      "Iteration 100, loss = 0.32322044\n",
      "Iteration 101, loss = 0.32260335\n",
      "Iteration 102, loss = 0.32158125\n",
      "Iteration 103, loss = 0.32323849\n",
      "Iteration 104, loss = 0.32064103\n",
      "Iteration 105, loss = 0.32129604\n",
      "Iteration 106, loss = 0.31902905\n",
      "Iteration 107, loss = 0.31962378\n",
      "Iteration 108, loss = 0.31887146\n",
      "Iteration 109, loss = 0.31682422\n",
      "Iteration 110, loss = 0.31824024\n",
      "Iteration 111, loss = 0.31744952\n",
      "Iteration 112, loss = 0.31602486\n",
      "Iteration 113, loss = 0.31486698\n",
      "Iteration 114, loss = 0.31588689\n",
      "Iteration 115, loss = 0.31349684\n",
      "Iteration 116, loss = 0.31358063\n",
      "Iteration 117, loss = 0.31308718\n",
      "Iteration 118, loss = 0.31346027\n",
      "Iteration 119, loss = 0.31213432\n",
      "Iteration 120, loss = 0.31093505\n",
      "Iteration 121, loss = 0.30985631\n",
      "Iteration 122, loss = 0.30977886\n",
      "Iteration 123, loss = 0.30899103\n",
      "Iteration 124, loss = 0.31094958\n",
      "Iteration 125, loss = 0.30879902\n",
      "Iteration 126, loss = 0.30797601\n",
      "Iteration 127, loss = 0.30647429\n",
      "Iteration 128, loss = 0.30629027\n",
      "Iteration 129, loss = 0.30775627\n",
      "Iteration 130, loss = 0.30563582\n",
      "Iteration 131, loss = 0.30528165\n",
      "Iteration 132, loss = 0.30383677\n",
      "Iteration 133, loss = 0.30344788\n",
      "Iteration 134, loss = 0.30540895\n",
      "Iteration 135, loss = 0.30329322\n",
      "Iteration 136, loss = 0.30190694\n",
      "Iteration 137, loss = 0.30309173\n",
      "Iteration 138, loss = 0.30238048\n",
      "Iteration 139, loss = 0.30254710\n",
      "Iteration 140, loss = 0.30216262\n",
      "Iteration 141, loss = 0.30199879\n",
      "Iteration 142, loss = 0.30049896\n",
      "Iteration 143, loss = 0.29975896\n",
      "Iteration 144, loss = 0.29991166\n",
      "Iteration 145, loss = 0.29945533\n",
      "Iteration 146, loss = 0.29997265\n",
      "Iteration 147, loss = 0.29979059\n",
      "Iteration 148, loss = 0.29724274\n",
      "Iteration 149, loss = 0.29850912\n",
      "Iteration 150, loss = 0.29774225\n",
      "Iteration 151, loss = 0.29573663\n",
      "Iteration 152, loss = 0.29596830\n",
      "Iteration 153, loss = 0.29480409\n",
      "Iteration 154, loss = 0.29669647\n",
      "Iteration 155, loss = 0.29617606\n",
      "Iteration 156, loss = 0.29458413\n",
      "Iteration 157, loss = 0.29402217\n",
      "Iteration 158, loss = 0.29369817\n",
      "Iteration 159, loss = 0.29365880\n",
      "Iteration 160, loss = 0.29246912\n",
      "Iteration 161, loss = 0.29330872\n",
      "Iteration 162, loss = 0.29191367\n",
      "Iteration 163, loss = 0.29211167\n",
      "Iteration 164, loss = 0.29043357\n",
      "Iteration 165, loss = 0.28949866\n",
      "Iteration 166, loss = 0.29150517\n",
      "Iteration 167, loss = 0.28953089\n",
      "Iteration 168, loss = 0.28867321\n",
      "Iteration 169, loss = 0.28946742\n",
      "Iteration 170, loss = 0.28911226\n",
      "Iteration 171, loss = 0.28907059\n",
      "Iteration 172, loss = 0.28831362\n",
      "Iteration 173, loss = 0.28703463\n",
      "Iteration 174, loss = 0.28743108\n",
      "Iteration 175, loss = 0.28717747\n",
      "Iteration 176, loss = 0.28706500\n",
      "Iteration 177, loss = 0.28785639\n",
      "Iteration 178, loss = 0.28467333\n",
      "Iteration 179, loss = 0.28795944\n",
      "Iteration 180, loss = 0.28579448\n",
      "Iteration 181, loss = 0.28353899\n",
      "Iteration 182, loss = 0.28876089\n",
      "Iteration 183, loss = 0.28503516\n",
      "Iteration 184, loss = 0.28460050\n",
      "Iteration 185, loss = 0.28306813\n",
      "Iteration 186, loss = 0.28534386\n",
      "Iteration 187, loss = 0.28199279\n",
      "Iteration 188, loss = 0.28209993\n",
      "Iteration 189, loss = 0.28327576\n",
      "Iteration 190, loss = 0.28314189\n",
      "Iteration 191, loss = 0.28095878\n",
      "Iteration 192, loss = 0.28137814\n",
      "Iteration 193, loss = 0.28108921\n",
      "Iteration 194, loss = 0.27996227\n",
      "Iteration 195, loss = 0.28138247\n",
      "Iteration 196, loss = 0.28169386\n",
      "Iteration 197, loss = 0.27800716\n",
      "Iteration 198, loss = 0.27945450\n",
      "Iteration 199, loss = 0.27870841\n",
      "Iteration 200, loss = 0.28066808\n",
      "Iteration 201, loss = 0.27776764\n",
      "Iteration 202, loss = 0.27660052\n",
      "Iteration 203, loss = 0.27654402\n",
      "Iteration 204, loss = 0.27672863\n",
      "Iteration 205, loss = 0.27576598\n",
      "Iteration 206, loss = 0.27717845\n",
      "Iteration 207, loss = 0.27477437\n",
      "Iteration 208, loss = 0.27642309\n",
      "Iteration 209, loss = 0.27602098\n",
      "Iteration 210, loss = 0.27547279\n",
      "Iteration 211, loss = 0.27521694\n",
      "Iteration 212, loss = 0.27483533\n",
      "Iteration 213, loss = 0.27627426\n",
      "Iteration 214, loss = 0.27437115\n",
      "Iteration 215, loss = 0.27429559\n",
      "Iteration 216, loss = 0.27464575\n",
      "Iteration 217, loss = 0.27399871\n",
      "Iteration 218, loss = 0.27213883\n",
      "Iteration 219, loss = 0.27152783\n",
      "Iteration 220, loss = 0.27007681\n",
      "Iteration 221, loss = 0.27136231\n",
      "Iteration 222, loss = 0.27238358\n",
      "Iteration 223, loss = 0.27199829\n",
      "Iteration 224, loss = 0.27216186\n",
      "Iteration 225, loss = 0.26992061\n",
      "Iteration 226, loss = 0.27100202\n",
      "Iteration 227, loss = 0.27007348\n",
      "Iteration 228, loss = 0.27051048\n",
      "Iteration 229, loss = 0.26980150\n",
      "Iteration 230, loss = 0.27027505\n",
      "Iteration 231, loss = 0.26809342\n",
      "Iteration 232, loss = 0.26923130\n",
      "Iteration 233, loss = 0.26787056\n",
      "Iteration 234, loss = 0.26770682\n",
      "Iteration 235, loss = 0.26662953\n",
      "Iteration 236, loss = 0.26873945\n",
      "Iteration 237, loss = 0.26640792\n",
      "Iteration 238, loss = 0.26842089\n",
      "Iteration 239, loss = 0.26583261\n",
      "Iteration 240, loss = 0.26563103\n",
      "Iteration 241, loss = 0.26546058\n",
      "Iteration 242, loss = 0.26559137\n",
      "Iteration 243, loss = 0.26532083\n",
      "Iteration 244, loss = 0.26709924\n",
      "Iteration 245, loss = 0.26494197\n",
      "Iteration 246, loss = 0.26677050\n",
      "Iteration 247, loss = 0.26437951\n",
      "Iteration 248, loss = 0.26323172\n",
      "Iteration 249, loss = 0.26366045\n",
      "Iteration 250, loss = 0.26545611\n",
      "Iteration 251, loss = 0.26411949\n",
      "Iteration 252, loss = 0.26296917\n",
      "Iteration 253, loss = 0.26384535\n",
      "Iteration 254, loss = 0.26195548\n",
      "Iteration 255, loss = 0.26333782\n",
      "Iteration 256, loss = 0.26143885\n",
      "Iteration 257, loss = 0.26288256\n",
      "Iteration 258, loss = 0.26288949\n",
      "Iteration 259, loss = 0.25951503\n",
      "Iteration 260, loss = 0.25987406\n",
      "Iteration 261, loss = 0.26105633\n",
      "Iteration 262, loss = 0.26243788\n",
      "Iteration 263, loss = 0.26088458\n",
      "Iteration 264, loss = 0.26039950\n",
      "Iteration 265, loss = 0.25871191\n",
      "Iteration 266, loss = 0.25923880\n",
      "Iteration 267, loss = 0.25877193\n",
      "Iteration 268, loss = 0.25799310\n",
      "Iteration 269, loss = 0.26032328\n",
      "Iteration 270, loss = 0.25996351\n",
      "Iteration 271, loss = 0.26015502\n",
      "Iteration 272, loss = 0.25794541\n",
      "Iteration 273, loss = 0.25836722\n",
      "Iteration 274, loss = 0.25929495\n",
      "Iteration 275, loss = 0.25778062\n",
      "Iteration 276, loss = 0.25757074\n",
      "Iteration 277, loss = 0.25611769\n",
      "Iteration 278, loss = 0.25798117\n",
      "Iteration 279, loss = 0.25679610\n",
      "Iteration 280, loss = 0.25606977\n",
      "Iteration 281, loss = 0.25766441\n",
      "Iteration 282, loss = 0.25436287\n",
      "Iteration 283, loss = 0.25703444\n",
      "Iteration 284, loss = 0.25679588\n",
      "Iteration 285, loss = 0.25672396\n",
      "Iteration 286, loss = 0.25523418\n",
      "Iteration 287, loss = 0.25455703\n",
      "Iteration 288, loss = 0.25644341\n",
      "Iteration 289, loss = 0.25506380\n",
      "Iteration 290, loss = 0.25275750\n",
      "Iteration 291, loss = 0.25441205\n",
      "Iteration 292, loss = 0.25374232\n",
      "Iteration 293, loss = 0.25187491\n",
      "Iteration 294, loss = 0.25170163\n",
      "Iteration 295, loss = 0.25424621\n",
      "Iteration 296, loss = 0.25390814\n",
      "Iteration 297, loss = 0.25324424\n",
      "Iteration 298, loss = 0.25200565\n",
      "Iteration 299, loss = 0.25125173\n",
      "Iteration 300, loss = 0.25338766\n",
      "Iteration 301, loss = 0.25181707\n",
      "Iteration 302, loss = 0.25307285\n",
      "Iteration 303, loss = 0.25265245\n",
      "Iteration 304, loss = 0.25091129\n",
      "Iteration 305, loss = 0.25275367\n",
      "Iteration 306, loss = 0.24822135\n",
      "Iteration 307, loss = 0.25166364\n",
      "Iteration 308, loss = 0.25000607\n",
      "Iteration 309, loss = 0.24976819\n",
      "Iteration 310, loss = 0.24910722\n",
      "Iteration 311, loss = 0.25216708\n",
      "Iteration 312, loss = 0.25121393\n",
      "Iteration 313, loss = 0.24985733\n",
      "Iteration 314, loss = 0.24850635\n",
      "Iteration 315, loss = 0.24851733\n",
      "Iteration 316, loss = 0.24937570\n",
      "Iteration 317, loss = 0.24894407\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy:  0.8208340041861214\n",
      "Train  1\n",
      "Iteration 1, loss = 0.58181346\n",
      "Iteration 2, loss = 0.48479479\n",
      "Iteration 3, loss = 0.45801173\n",
      "Iteration 4, loss = 0.44790432\n",
      "Iteration 5, loss = 0.43601068\n",
      "Iteration 6, loss = 0.43416235\n",
      "Iteration 7, loss = 0.42942067\n",
      "Iteration 8, loss = 0.42646314\n",
      "Iteration 9, loss = 0.42356150\n",
      "Iteration 10, loss = 0.42019640\n",
      "Iteration 11, loss = 0.41855561\n",
      "Iteration 12, loss = 0.41484869\n",
      "Iteration 13, loss = 0.41383841\n",
      "Iteration 14, loss = 0.41193232\n",
      "Iteration 15, loss = 0.41112097\n",
      "Iteration 16, loss = 0.40774889\n",
      "Iteration 17, loss = 0.40381057\n",
      "Iteration 18, loss = 0.40514100\n",
      "Iteration 19, loss = 0.40204203\n",
      "Iteration 20, loss = 0.40081486\n",
      "Iteration 21, loss = 0.39767593\n",
      "Iteration 22, loss = 0.39614079\n",
      "Iteration 23, loss = 0.39461506\n",
      "Iteration 24, loss = 0.39545824\n",
      "Iteration 25, loss = 0.39208202\n",
      "Iteration 26, loss = 0.39220872\n",
      "Iteration 27, loss = 0.38818951\n",
      "Iteration 28, loss = 0.38831767\n",
      "Iteration 29, loss = 0.38716499\n",
      "Iteration 30, loss = 0.38463757\n",
      "Iteration 31, loss = 0.38361809\n",
      "Iteration 32, loss = 0.38167269\n",
      "Iteration 33, loss = 0.38099442\n",
      "Iteration 34, loss = 0.38090583\n",
      "Iteration 35, loss = 0.37659498\n",
      "Iteration 36, loss = 0.37641721\n",
      "Iteration 37, loss = 0.37617943\n",
      "Iteration 38, loss = 0.37613153\n",
      "Iteration 39, loss = 0.37257600\n",
      "Iteration 40, loss = 0.37221966\n",
      "Iteration 41, loss = 0.37097997\n",
      "Iteration 42, loss = 0.37190870\n",
      "Iteration 43, loss = 0.36870605\n",
      "Iteration 44, loss = 0.36912447\n",
      "Iteration 45, loss = 0.36678858\n",
      "Iteration 46, loss = 0.36542777\n",
      "Iteration 47, loss = 0.36554380\n",
      "Iteration 48, loss = 0.36389885\n",
      "Iteration 49, loss = 0.36228612\n",
      "Iteration 50, loss = 0.36239209\n",
      "Iteration 51, loss = 0.36010861\n",
      "Iteration 52, loss = 0.36052888\n",
      "Iteration 53, loss = 0.35984330\n",
      "Iteration 54, loss = 0.35767064\n",
      "Iteration 55, loss = 0.35639343\n",
      "Iteration 56, loss = 0.35753217\n",
      "Iteration 57, loss = 0.35450691\n",
      "Iteration 58, loss = 0.35206889\n",
      "Iteration 59, loss = 0.35331793\n",
      "Iteration 60, loss = 0.35219409\n",
      "Iteration 61, loss = 0.35213238\n",
      "Iteration 62, loss = 0.34996071\n",
      "Iteration 63, loss = 0.34867714\n",
      "Iteration 64, loss = 0.34930871\n",
      "Iteration 65, loss = 0.34736418\n",
      "Iteration 66, loss = 0.34741042\n",
      "Iteration 67, loss = 0.34581622\n",
      "Iteration 68, loss = 0.34502198\n",
      "Iteration 69, loss = 0.34491692\n",
      "Iteration 70, loss = 0.34298579\n",
      "Iteration 71, loss = 0.34369744\n",
      "Iteration 72, loss = 0.34255821\n",
      "Iteration 73, loss = 0.34267434\n",
      "Iteration 74, loss = 0.34034930\n",
      "Iteration 75, loss = 0.34065354\n",
      "Iteration 76, loss = 0.33702641\n",
      "Iteration 77, loss = 0.33896224\n",
      "Iteration 78, loss = 0.33799264\n",
      "Iteration 79, loss = 0.33703272\n",
      "Iteration 80, loss = 0.33590299\n",
      "Iteration 81, loss = 0.33515802\n",
      "Iteration 82, loss = 0.33581953\n",
      "Iteration 83, loss = 0.33348575\n",
      "Iteration 84, loss = 0.33211254\n",
      "Iteration 85, loss = 0.33167617\n",
      "Iteration 86, loss = 0.33046909\n",
      "Iteration 87, loss = 0.33036645\n",
      "Iteration 88, loss = 0.33062381\n",
      "Iteration 89, loss = 0.32995347\n",
      "Iteration 90, loss = 0.32890860\n",
      "Iteration 91, loss = 0.32718654\n",
      "Iteration 92, loss = 0.32775296\n",
      "Iteration 93, loss = 0.32650010\n",
      "Iteration 94, loss = 0.32540925\n",
      "Iteration 95, loss = 0.32394011\n",
      "Iteration 96, loss = 0.32449369\n",
      "Iteration 97, loss = 0.32308581\n",
      "Iteration 98, loss = 0.32345484\n",
      "Iteration 99, loss = 0.32299050\n",
      "Iteration 100, loss = 0.32291986\n",
      "Iteration 101, loss = 0.31980974\n",
      "Iteration 102, loss = 0.32060959\n",
      "Iteration 103, loss = 0.31990150\n",
      "Iteration 104, loss = 0.31868103\n",
      "Iteration 105, loss = 0.32037842\n",
      "Iteration 106, loss = 0.31743350\n",
      "Iteration 107, loss = 0.31780874\n",
      "Iteration 108, loss = 0.31702898\n",
      "Iteration 109, loss = 0.31553996\n",
      "Iteration 110, loss = 0.31694056\n",
      "Iteration 111, loss = 0.31385924\n",
      "Iteration 112, loss = 0.31622172\n",
      "Iteration 113, loss = 0.31383909\n",
      "Iteration 114, loss = 0.31325846\n",
      "Iteration 115, loss = 0.31294021\n",
      "Iteration 116, loss = 0.31253932\n",
      "Iteration 117, loss = 0.31120086\n",
      "Iteration 118, loss = 0.31005834\n",
      "Iteration 119, loss = 0.31156647\n",
      "Iteration 120, loss = 0.31031994\n",
      "Iteration 121, loss = 0.31023037\n",
      "Iteration 122, loss = 0.30965853\n",
      "Iteration 123, loss = 0.30762329\n",
      "Iteration 124, loss = 0.30858229\n",
      "Iteration 125, loss = 0.30770026\n",
      "Iteration 126, loss = 0.30675216\n",
      "Iteration 127, loss = 0.30790128\n",
      "Iteration 128, loss = 0.30577155\n",
      "Iteration 129, loss = 0.30308669\n",
      "Iteration 130, loss = 0.30580712\n",
      "Iteration 131, loss = 0.30496557\n",
      "Iteration 132, loss = 0.30405152\n",
      "Iteration 133, loss = 0.30250874\n",
      "Iteration 134, loss = 0.30170979\n",
      "Iteration 135, loss = 0.30213431\n",
      "Iteration 136, loss = 0.30200461\n",
      "Iteration 137, loss = 0.30125029\n",
      "Iteration 138, loss = 0.30021054\n",
      "Iteration 139, loss = 0.29978163\n",
      "Iteration 140, loss = 0.29960486\n",
      "Iteration 141, loss = 0.30165397\n",
      "Iteration 142, loss = 0.30021219\n",
      "Iteration 143, loss = 0.29884150\n",
      "Iteration 144, loss = 0.29662300\n",
      "Iteration 145, loss = 0.29796013\n",
      "Iteration 146, loss = 0.29645656\n",
      "Iteration 147, loss = 0.29572042\n",
      "Iteration 148, loss = 0.29522458\n",
      "Iteration 149, loss = 0.29499073\n",
      "Iteration 150, loss = 0.29662940\n",
      "Iteration 151, loss = 0.29380298\n",
      "Iteration 152, loss = 0.29467929\n",
      "Iteration 153, loss = 0.29436816\n",
      "Iteration 154, loss = 0.29373091\n",
      "Iteration 155, loss = 0.29294444\n",
      "Iteration 156, loss = 0.29281694\n",
      "Iteration 157, loss = 0.29269395\n",
      "Iteration 158, loss = 0.29317434\n",
      "Iteration 159, loss = 0.29158359\n",
      "Iteration 160, loss = 0.28962442\n",
      "Iteration 161, loss = 0.29141482\n",
      "Iteration 162, loss = 0.28915394\n",
      "Iteration 163, loss = 0.29106104\n",
      "Iteration 164, loss = 0.28946360\n",
      "Iteration 165, loss = 0.28853354\n",
      "Iteration 166, loss = 0.28718486\n",
      "Iteration 167, loss = 0.28824525\n",
      "Iteration 168, loss = 0.28693062\n",
      "Iteration 169, loss = 0.28823565\n",
      "Iteration 170, loss = 0.28477923\n",
      "Iteration 171, loss = 0.28829936\n",
      "Iteration 172, loss = 0.28684329\n",
      "Iteration 173, loss = 0.28670048\n",
      "Iteration 174, loss = 0.28434864\n",
      "Iteration 175, loss = 0.28581474\n",
      "Iteration 176, loss = 0.28449988\n",
      "Iteration 177, loss = 0.28382319\n",
      "Iteration 178, loss = 0.28419201\n",
      "Iteration 179, loss = 0.28370475\n",
      "Iteration 180, loss = 0.28260762\n",
      "Iteration 181, loss = 0.28381181\n",
      "Iteration 182, loss = 0.28315710\n",
      "Iteration 183, loss = 0.28277395\n",
      "Iteration 184, loss = 0.28164950\n",
      "Iteration 185, loss = 0.28153600\n",
      "Iteration 186, loss = 0.28127394\n",
      "Iteration 187, loss = 0.28088925\n",
      "Iteration 188, loss = 0.28034076\n",
      "Iteration 189, loss = 0.27968328\n",
      "Iteration 190, loss = 0.28016934\n",
      "Iteration 191, loss = 0.27923003\n",
      "Iteration 192, loss = 0.27762517\n",
      "Iteration 193, loss = 0.27897044\n",
      "Iteration 194, loss = 0.27829476\n",
      "Iteration 195, loss = 0.27939498\n",
      "Iteration 196, loss = 0.27709912\n",
      "Iteration 197, loss = 0.27634763\n",
      "Iteration 198, loss = 0.27603852\n",
      "Iteration 199, loss = 0.27696014\n",
      "Iteration 200, loss = 0.27522172\n",
      "Iteration 201, loss = 0.27471109\n",
      "Iteration 202, loss = 0.27564848\n",
      "Iteration 203, loss = 0.27339645\n",
      "Iteration 204, loss = 0.27494001\n",
      "Iteration 205, loss = 0.27297492\n",
      "Iteration 206, loss = 0.27434708\n",
      "Iteration 207, loss = 0.27363779\n",
      "Iteration 208, loss = 0.27217291\n",
      "Iteration 209, loss = 0.27434342\n",
      "Iteration 210, loss = 0.27262019\n",
      "Iteration 211, loss = 0.27283337\n",
      "Iteration 212, loss = 0.27260240\n",
      "Iteration 213, loss = 0.27050470\n",
      "Iteration 214, loss = 0.27251357\n",
      "Iteration 215, loss = 0.27263146\n",
      "Iteration 216, loss = 0.27283487\n",
      "Iteration 217, loss = 0.27132870\n",
      "Iteration 218, loss = 0.26843942\n",
      "Iteration 219, loss = 0.26965713\n",
      "Iteration 220, loss = 0.26849522\n",
      "Iteration 221, loss = 0.27008512\n",
      "Iteration 222, loss = 0.26864791\n",
      "Iteration 223, loss = 0.26761416\n",
      "Iteration 224, loss = 0.26757577\n",
      "Iteration 225, loss = 0.26942980\n",
      "Iteration 226, loss = 0.26660367\n",
      "Iteration 227, loss = 0.26924860\n",
      "Iteration 228, loss = 0.26850539\n",
      "Iteration 229, loss = 0.26742157\n",
      "Iteration 230, loss = 0.26619889\n",
      "Iteration 231, loss = 0.26866721\n",
      "Iteration 232, loss = 0.26583757\n",
      "Iteration 233, loss = 0.26544947\n",
      "Iteration 234, loss = 0.26496517\n",
      "Iteration 235, loss = 0.26486433\n",
      "Iteration 236, loss = 0.26658883\n",
      "Iteration 237, loss = 0.26282762\n",
      "Iteration 238, loss = 0.26409238\n",
      "Iteration 239, loss = 0.26737514\n",
      "Iteration 240, loss = 0.26562739\n",
      "Iteration 241, loss = 0.26399901\n",
      "Iteration 242, loss = 0.26356822\n",
      "Iteration 243, loss = 0.26343410\n",
      "Iteration 244, loss = 0.26292245\n",
      "Iteration 245, loss = 0.26308794\n",
      "Iteration 246, loss = 0.26163715\n",
      "Iteration 247, loss = 0.26063207\n",
      "Iteration 248, loss = 0.26199664\n",
      "Iteration 249, loss = 0.26172033\n",
      "Iteration 250, loss = 0.26397318\n",
      "Iteration 251, loss = 0.26112934\n",
      "Iteration 252, loss = 0.26013603\n",
      "Iteration 253, loss = 0.26196160\n",
      "Iteration 254, loss = 0.26117470\n",
      "Iteration 255, loss = 0.26125287\n",
      "Iteration 256, loss = 0.25745959\n",
      "Iteration 257, loss = 0.26195301\n",
      "Iteration 258, loss = 0.25868430\n",
      "Iteration 259, loss = 0.25909869\n",
      "Iteration 260, loss = 0.25989813\n",
      "Iteration 261, loss = 0.25788701\n",
      "Iteration 262, loss = 0.25952914\n",
      "Iteration 263, loss = 0.25728490\n",
      "Iteration 264, loss = 0.25899402\n",
      "Iteration 265, loss = 0.25780812\n",
      "Iteration 266, loss = 0.25813590\n",
      "Iteration 267, loss = 0.25656444\n",
      "Iteration 268, loss = 0.25716029\n",
      "Iteration 269, loss = 0.25843813\n",
      "Iteration 270, loss = 0.25563714\n",
      "Iteration 271, loss = 0.25683837\n",
      "Iteration 272, loss = 0.25853208\n",
      "Iteration 273, loss = 0.25678481\n",
      "Iteration 274, loss = 0.25576832\n",
      "Iteration 275, loss = 0.25524019\n",
      "Iteration 276, loss = 0.25864108\n",
      "Iteration 277, loss = 0.25709048\n",
      "Iteration 278, loss = 0.25232552\n",
      "Iteration 279, loss = 0.25508267\n",
      "Iteration 280, loss = 0.25530969\n",
      "Iteration 281, loss = 0.25500681\n",
      "Iteration 282, loss = 0.25506187\n",
      "Iteration 283, loss = 0.25548653\n",
      "Iteration 284, loss = 0.25351527\n",
      "Iteration 285, loss = 0.25289849\n",
      "Iteration 286, loss = 0.25557361\n",
      "Iteration 287, loss = 0.25271825\n",
      "Iteration 288, loss = 0.25217453\n",
      "Iteration 289, loss = 0.25311202\n",
      "Iteration 290, loss = 0.25173804\n",
      "Iteration 291, loss = 0.25294793\n",
      "Iteration 292, loss = 0.25216438\n",
      "Iteration 293, loss = 0.25126805\n",
      "Iteration 294, loss = 0.25203675\n",
      "Iteration 295, loss = 0.25174226\n",
      "Iteration 296, loss = 0.25107980\n",
      "Iteration 297, loss = 0.25053982\n",
      "Iteration 298, loss = 0.25036246\n",
      "Iteration 299, loss = 0.25193448\n",
      "Iteration 300, loss = 0.24924192\n",
      "Iteration 301, loss = 0.25071478\n",
      "Iteration 302, loss = 0.25103989\n",
      "Iteration 303, loss = 0.25046739\n",
      "Iteration 304, loss = 0.24842332\n",
      "Iteration 305, loss = 0.24975768\n",
      "Iteration 306, loss = 0.24863982\n",
      "Iteration 307, loss = 0.24910077\n",
      "Iteration 308, loss = 0.24903873\n",
      "Iteration 309, loss = 0.24837526\n",
      "Iteration 310, loss = 0.24864223\n",
      "Iteration 311, loss = 0.24775721\n",
      "Iteration 312, loss = 0.24640745\n",
      "Iteration 313, loss = 0.24717643\n",
      "Iteration 314, loss = 0.24823421\n",
      "Iteration 315, loss = 0.24709711\n",
      "Iteration 316, loss = 0.24469384\n",
      "Iteration 317, loss = 0.24514336\n",
      "Iteration 318, loss = 0.24617808\n",
      "Iteration 319, loss = 0.24705133\n",
      "Iteration 320, loss = 0.24536923\n",
      "Iteration 321, loss = 0.24466649\n",
      "Iteration 322, loss = 0.24626727\n",
      "Iteration 323, loss = 0.24514433\n",
      "Iteration 324, loss = 0.24418176\n",
      "Iteration 325, loss = 0.24646792\n",
      "Iteration 326, loss = 0.24347282\n",
      "Iteration 327, loss = 0.24298328\n",
      "Iteration 328, loss = 0.24476878\n",
      "Iteration 329, loss = 0.24360449\n",
      "Iteration 330, loss = 0.24107873\n",
      "Iteration 331, loss = 0.24407661\n",
      "Iteration 332, loss = 0.24478058\n",
      "Iteration 333, loss = 0.24278067\n",
      "Iteration 334, loss = 0.24352177\n",
      "Iteration 335, loss = 0.24348186\n",
      "Iteration 336, loss = 0.24198991\n",
      "Iteration 337, loss = 0.24143249\n",
      "Iteration 338, loss = 0.24219753\n",
      "Iteration 339, loss = 0.24384174\n",
      "Iteration 340, loss = 0.24225548\n",
      "Iteration 341, loss = 0.24347568\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy:  0.8169376911930446\n",
      "Train  2\n",
      "Iteration 1, loss = 0.58458462\n",
      "Iteration 2, loss = 0.48563381\n",
      "Iteration 3, loss = 0.45853887\n",
      "Iteration 4, loss = 0.44637031\n",
      "Iteration 5, loss = 0.44388067\n",
      "Iteration 6, loss = 0.43711495\n",
      "Iteration 7, loss = 0.43367078\n",
      "Iteration 8, loss = 0.43013723\n",
      "Iteration 9, loss = 0.42775344\n",
      "Iteration 10, loss = 0.42434109\n",
      "Iteration 11, loss = 0.42123784\n",
      "Iteration 12, loss = 0.41758634\n",
      "Iteration 13, loss = 0.41702122\n",
      "Iteration 14, loss = 0.41439134\n",
      "Iteration 15, loss = 0.41399737\n",
      "Iteration 16, loss = 0.40818777\n",
      "Iteration 17, loss = 0.40844616\n",
      "Iteration 18, loss = 0.40622926\n",
      "Iteration 19, loss = 0.40360646\n",
      "Iteration 20, loss = 0.40367058\n",
      "Iteration 21, loss = 0.40032772\n",
      "Iteration 22, loss = 0.39925462\n",
      "Iteration 23, loss = 0.39898280\n",
      "Iteration 24, loss = 0.39540285\n",
      "Iteration 25, loss = 0.39517420\n",
      "Iteration 26, loss = 0.39112010\n",
      "Iteration 27, loss = 0.39169105\n",
      "Iteration 28, loss = 0.38999587\n",
      "Iteration 29, loss = 0.38727047\n",
      "Iteration 30, loss = 0.38707838\n",
      "Iteration 31, loss = 0.38468502\n",
      "Iteration 32, loss = 0.38422270\n",
      "Iteration 33, loss = 0.38152260\n",
      "Iteration 34, loss = 0.38088443\n",
      "Iteration 35, loss = 0.37982901\n",
      "Iteration 36, loss = 0.37618379\n",
      "Iteration 37, loss = 0.37623113\n",
      "Iteration 38, loss = 0.37495872\n",
      "Iteration 39, loss = 0.37309733\n",
      "Iteration 40, loss = 0.37227859\n",
      "Iteration 41, loss = 0.37008279\n",
      "Iteration 42, loss = 0.37022688\n",
      "Iteration 43, loss = 0.36724083\n",
      "Iteration 44, loss = 0.36794369\n",
      "Iteration 45, loss = 0.36600638\n",
      "Iteration 46, loss = 0.36522462\n",
      "Iteration 47, loss = 0.36386186\n",
      "Iteration 48, loss = 0.36374855\n",
      "Iteration 49, loss = 0.36155561\n",
      "Iteration 50, loss = 0.36242599\n",
      "Iteration 51, loss = 0.35925531\n",
      "Iteration 52, loss = 0.35770456\n",
      "Iteration 53, loss = 0.35770044\n",
      "Iteration 54, loss = 0.35831196\n",
      "Iteration 55, loss = 0.35583683\n",
      "Iteration 56, loss = 0.35546782\n",
      "Iteration 57, loss = 0.35484857\n",
      "Iteration 58, loss = 0.35219828\n",
      "Iteration 59, loss = 0.35349658\n",
      "Iteration 60, loss = 0.35260006\n",
      "Iteration 61, loss = 0.35026425\n",
      "Iteration 62, loss = 0.34891257\n",
      "Iteration 63, loss = 0.34923456\n",
      "Iteration 64, loss = 0.34894195\n",
      "Iteration 65, loss = 0.34726427\n",
      "Iteration 66, loss = 0.34670678\n",
      "Iteration 67, loss = 0.34478532\n",
      "Iteration 68, loss = 0.34544775\n",
      "Iteration 69, loss = 0.34445921\n",
      "Iteration 70, loss = 0.34292851\n",
      "Iteration 71, loss = 0.34267039\n",
      "Iteration 72, loss = 0.34222145\n",
      "Iteration 73, loss = 0.34065993\n",
      "Iteration 74, loss = 0.34086232\n",
      "Iteration 75, loss = 0.33861976\n",
      "Iteration 76, loss = 0.33882561\n",
      "Iteration 77, loss = 0.33764577\n",
      "Iteration 78, loss = 0.33586287\n",
      "Iteration 79, loss = 0.33722287\n",
      "Iteration 80, loss = 0.33664518\n",
      "Iteration 81, loss = 0.33569808\n",
      "Iteration 82, loss = 0.33601661\n",
      "Iteration 83, loss = 0.33319811\n",
      "Iteration 84, loss = 0.33304260\n",
      "Iteration 85, loss = 0.33171500\n",
      "Iteration 86, loss = 0.33077207\n",
      "Iteration 87, loss = 0.33117924\n",
      "Iteration 88, loss = 0.32914247\n",
      "Iteration 89, loss = 0.32772225\n",
      "Iteration 90, loss = 0.32838200\n",
      "Iteration 91, loss = 0.32818536\n",
      "Iteration 92, loss = 0.32788938\n",
      "Iteration 93, loss = 0.32425197\n",
      "Iteration 94, loss = 0.32451359\n",
      "Iteration 95, loss = 0.32622764\n",
      "Iteration 96, loss = 0.32373488\n",
      "Iteration 97, loss = 0.32318375\n",
      "Iteration 98, loss = 0.32408281\n",
      "Iteration 99, loss = 0.32142789\n",
      "Iteration 100, loss = 0.32173663\n",
      "Iteration 101, loss = 0.32185626\n",
      "Iteration 102, loss = 0.31914676\n",
      "Iteration 103, loss = 0.31984128\n",
      "Iteration 104, loss = 0.31879341\n",
      "Iteration 105, loss = 0.31994626\n",
      "Iteration 106, loss = 0.31943039\n",
      "Iteration 107, loss = 0.31804240\n",
      "Iteration 108, loss = 0.31799846\n",
      "Iteration 109, loss = 0.31767367\n",
      "Iteration 110, loss = 0.31686154\n",
      "Iteration 111, loss = 0.31659356\n",
      "Iteration 112, loss = 0.31488713\n",
      "Iteration 113, loss = 0.31351716\n",
      "Iteration 114, loss = 0.31582861\n",
      "Iteration 115, loss = 0.31353370\n",
      "Iteration 116, loss = 0.31359142\n",
      "Iteration 117, loss = 0.31255522\n",
      "Iteration 118, loss = 0.31051689\n",
      "Iteration 119, loss = 0.31067657\n",
      "Iteration 120, loss = 0.31052992\n",
      "Iteration 121, loss = 0.31027643\n",
      "Iteration 122, loss = 0.30813025\n",
      "Iteration 123, loss = 0.31059111\n",
      "Iteration 124, loss = 0.30652616\n",
      "Iteration 125, loss = 0.30786786\n",
      "Iteration 126, loss = 0.30708005\n",
      "Iteration 127, loss = 0.30533155\n",
      "Iteration 128, loss = 0.30611955\n",
      "Iteration 129, loss = 0.30488884\n",
      "Iteration 130, loss = 0.30643786\n",
      "Iteration 131, loss = 0.30640800\n",
      "Iteration 132, loss = 0.30174795\n",
      "Iteration 133, loss = 0.30370930\n",
      "Iteration 134, loss = 0.30291777\n",
      "Iteration 135, loss = 0.30096901\n",
      "Iteration 136, loss = 0.30074059\n",
      "Iteration 137, loss = 0.30224039\n",
      "Iteration 138, loss = 0.30279667\n",
      "Iteration 139, loss = 0.29990647\n",
      "Iteration 140, loss = 0.30125734\n",
      "Iteration 141, loss = 0.29922652\n",
      "Iteration 142, loss = 0.29932424\n",
      "Iteration 143, loss = 0.29805052\n",
      "Iteration 144, loss = 0.29953789\n",
      "Iteration 145, loss = 0.29926026\n",
      "Iteration 146, loss = 0.29646340\n",
      "Iteration 147, loss = 0.29600682\n",
      "Iteration 148, loss = 0.29657812\n",
      "Iteration 149, loss = 0.29742781\n",
      "Iteration 150, loss = 0.29572531\n",
      "Iteration 151, loss = 0.29568106\n",
      "Iteration 152, loss = 0.29662174\n",
      "Iteration 153, loss = 0.29570177\n",
      "Iteration 154, loss = 0.29254620\n",
      "Iteration 155, loss = 0.29396008\n",
      "Iteration 156, loss = 0.29312974\n",
      "Iteration 157, loss = 0.29332635\n",
      "Iteration 158, loss = 0.29418883\n",
      "Iteration 159, loss = 0.29202780\n",
      "Iteration 160, loss = 0.29078914\n",
      "Iteration 161, loss = 0.29346847\n",
      "Iteration 162, loss = 0.29252692\n",
      "Iteration 163, loss = 0.29089200\n",
      "Iteration 164, loss = 0.28991121\n",
      "Iteration 165, loss = 0.28930303\n",
      "Iteration 166, loss = 0.28971771\n",
      "Iteration 167, loss = 0.28936634\n",
      "Iteration 168, loss = 0.28942801\n",
      "Iteration 169, loss = 0.28752117\n",
      "Iteration 170, loss = 0.28747357\n",
      "Iteration 171, loss = 0.28798469\n",
      "Iteration 172, loss = 0.28749572\n",
      "Iteration 173, loss = 0.28882245\n",
      "Iteration 174, loss = 0.28662685\n",
      "Iteration 175, loss = 0.28640748\n",
      "Iteration 176, loss = 0.28575692\n",
      "Iteration 177, loss = 0.28703460\n",
      "Iteration 178, loss = 0.28686199\n",
      "Iteration 179, loss = 0.28681223\n",
      "Iteration 180, loss = 0.28486164\n",
      "Iteration 181, loss = 0.28331968\n",
      "Iteration 182, loss = 0.28508243\n",
      "Iteration 183, loss = 0.28149347\n",
      "Iteration 184, loss = 0.28300771\n",
      "Iteration 185, loss = 0.28172675\n",
      "Iteration 186, loss = 0.28263203\n",
      "Iteration 187, loss = 0.28481613\n",
      "Iteration 188, loss = 0.28090951\n",
      "Iteration 189, loss = 0.28128062\n",
      "Iteration 190, loss = 0.28157021\n",
      "Iteration 191, loss = 0.28007029\n",
      "Iteration 192, loss = 0.28107095\n",
      "Iteration 193, loss = 0.28019772\n",
      "Iteration 194, loss = 0.27836825\n",
      "Iteration 195, loss = 0.27958810\n",
      "Iteration 196, loss = 0.27891544\n",
      "Iteration 197, loss = 0.27816036\n",
      "Iteration 198, loss = 0.27806279\n",
      "Iteration 199, loss = 0.27818918\n",
      "Iteration 200, loss = 0.27811458\n",
      "Iteration 201, loss = 0.27717454\n",
      "Iteration 202, loss = 0.27800766\n",
      "Iteration 203, loss = 0.27627261\n",
      "Iteration 204, loss = 0.27529151\n",
      "Iteration 205, loss = 0.27578298\n",
      "Iteration 206, loss = 0.27670849\n",
      "Iteration 207, loss = 0.27496805\n",
      "Iteration 208, loss = 0.27364197\n",
      "Iteration 209, loss = 0.27603577\n",
      "Iteration 210, loss = 0.27408685\n",
      "Iteration 211, loss = 0.27435368\n",
      "Iteration 212, loss = 0.27409200\n",
      "Iteration 213, loss = 0.27358616\n",
      "Iteration 214, loss = 0.27209252\n",
      "Iteration 215, loss = 0.27372157\n",
      "Iteration 216, loss = 0.27274338\n",
      "Iteration 217, loss = 0.27453081\n",
      "Iteration 218, loss = 0.27237618\n",
      "Iteration 219, loss = 0.27285233\n",
      "Iteration 220, loss = 0.27058711\n",
      "Iteration 221, loss = 0.27272521\n",
      "Iteration 222, loss = 0.26991916\n",
      "Iteration 223, loss = 0.27259289\n",
      "Iteration 224, loss = 0.27081015\n",
      "Iteration 225, loss = 0.26959887\n",
      "Iteration 226, loss = 0.27047557\n",
      "Iteration 227, loss = 0.27006966\n",
      "Iteration 228, loss = 0.26991217\n",
      "Iteration 229, loss = 0.26781128\n",
      "Iteration 230, loss = 0.26723162\n",
      "Iteration 231, loss = 0.26682992\n",
      "Iteration 232, loss = 0.26822577\n",
      "Iteration 233, loss = 0.26873269\n",
      "Iteration 234, loss = 0.26793969\n",
      "Iteration 235, loss = 0.26748886\n",
      "Iteration 236, loss = 0.26794081\n",
      "Iteration 237, loss = 0.26672053\n",
      "Iteration 238, loss = 0.26636867\n",
      "Iteration 239, loss = 0.26858785\n",
      "Iteration 240, loss = 0.26549277\n",
      "Iteration 241, loss = 0.26588506\n",
      "Iteration 242, loss = 0.26569480\n",
      "Iteration 243, loss = 0.26801425\n",
      "Iteration 244, loss = 0.26714114\n",
      "Iteration 245, loss = 0.26364835\n",
      "Iteration 246, loss = 0.26416555\n",
      "Iteration 247, loss = 0.26544991\n",
      "Iteration 248, loss = 0.26421747\n",
      "Iteration 249, loss = 0.26334925\n",
      "Iteration 250, loss = 0.26307380\n",
      "Iteration 251, loss = 0.26243133\n",
      "Iteration 252, loss = 0.26298524\n",
      "Iteration 253, loss = 0.26406894\n",
      "Iteration 254, loss = 0.26185497\n",
      "Iteration 255, loss = 0.26011048\n",
      "Iteration 256, loss = 0.26228208\n",
      "Iteration 257, loss = 0.26271135\n",
      "Iteration 258, loss = 0.26065454\n",
      "Iteration 259, loss = 0.26162065\n",
      "Iteration 260, loss = 0.26051512\n",
      "Iteration 261, loss = 0.25952151\n",
      "Iteration 262, loss = 0.26189956\n",
      "Iteration 263, loss = 0.26052544\n",
      "Iteration 264, loss = 0.25801546\n",
      "Iteration 265, loss = 0.26082898\n",
      "Iteration 266, loss = 0.25909601\n",
      "Iteration 267, loss = 0.25954360\n",
      "Iteration 268, loss = 0.26204730\n",
      "Iteration 269, loss = 0.25851160\n",
      "Iteration 270, loss = 0.25673845\n",
      "Iteration 271, loss = 0.26000148\n",
      "Iteration 272, loss = 0.25796146\n",
      "Iteration 273, loss = 0.25702563\n",
      "Iteration 274, loss = 0.25636722\n",
      "Iteration 275, loss = 0.25622407\n",
      "Iteration 276, loss = 0.25797926\n",
      "Iteration 277, loss = 0.25578216\n",
      "Iteration 278, loss = 0.25707482\n",
      "Iteration 279, loss = 0.25720240\n",
      "Iteration 280, loss = 0.25579735\n",
      "Iteration 281, loss = 0.25790263\n",
      "Iteration 282, loss = 0.25551188\n",
      "Iteration 283, loss = 0.25521915\n",
      "Iteration 284, loss = 0.25639480\n",
      "Iteration 285, loss = 0.25681186\n",
      "Iteration 286, loss = 0.25529284\n",
      "Iteration 287, loss = 0.25445632\n",
      "Iteration 288, loss = 0.25391669\n",
      "Iteration 289, loss = 0.25399073\n",
      "Iteration 290, loss = 0.25490633\n",
      "Iteration 291, loss = 0.25388951\n",
      "Iteration 292, loss = 0.25329177\n",
      "Iteration 293, loss = 0.25420334\n",
      "Iteration 294, loss = 0.25249351\n",
      "Iteration 295, loss = 0.25365579\n",
      "Iteration 296, loss = 0.25356148\n",
      "Iteration 297, loss = 0.25115444\n",
      "Iteration 298, loss = 0.25286283\n",
      "Iteration 299, loss = 0.25265138\n",
      "Iteration 300, loss = 0.24978835\n",
      "Iteration 301, loss = 0.25052811\n",
      "Iteration 302, loss = 0.25007419\n",
      "Iteration 303, loss = 0.25209470\n",
      "Iteration 304, loss = 0.25223375\n",
      "Iteration 305, loss = 0.24977953\n",
      "Iteration 306, loss = 0.25136216\n",
      "Iteration 307, loss = 0.25004061\n",
      "Iteration 308, loss = 0.25079820\n",
      "Iteration 309, loss = 0.24925738\n",
      "Iteration 310, loss = 0.25083985\n",
      "Iteration 311, loss = 0.25073952\n",
      "Iteration 312, loss = 0.24765533\n",
      "Iteration 313, loss = 0.25068897\n",
      "Iteration 314, loss = 0.25039909\n",
      "Iteration 315, loss = 0.24862824\n",
      "Iteration 316, loss = 0.24817975\n",
      "Iteration 317, loss = 0.25049182\n",
      "Iteration 318, loss = 0.24712292\n",
      "Iteration 319, loss = 0.24900694\n",
      "Iteration 320, loss = 0.24799052\n",
      "Iteration 321, loss = 0.24588572\n",
      "Iteration 322, loss = 0.24860438\n",
      "Iteration 323, loss = 0.24762127\n",
      "Iteration 324, loss = 0.24960272\n",
      "Iteration 325, loss = 0.24581646\n",
      "Iteration 326, loss = 0.24757577\n",
      "Iteration 327, loss = 0.24665661\n",
      "Iteration 328, loss = 0.24787728\n",
      "Iteration 329, loss = 0.24634406\n",
      "Iteration 330, loss = 0.24728699\n",
      "Iteration 331, loss = 0.24460046\n",
      "Iteration 332, loss = 0.24655890\n",
      "Iteration 333, loss = 0.24498977\n",
      "Iteration 334, loss = 0.24567837\n",
      "Iteration 335, loss = 0.24401363\n",
      "Iteration 336, loss = 0.24532512\n",
      "Iteration 337, loss = 0.24631347\n",
      "Iteration 338, loss = 0.24521491\n",
      "Iteration 339, loss = 0.24590407\n",
      "Iteration 340, loss = 0.24354048\n",
      "Iteration 341, loss = 0.24241835\n",
      "Iteration 342, loss = 0.24246141\n",
      "Iteration 343, loss = 0.24401514\n",
      "Iteration 344, loss = 0.24553289\n",
      "Iteration 345, loss = 0.24278657\n",
      "Iteration 346, loss = 0.24249857\n",
      "Iteration 347, loss = 0.24307005\n",
      "Iteration 348, loss = 0.24363760\n",
      "Iteration 349, loss = 0.24175631\n",
      "Iteration 350, loss = 0.24236620\n",
      "Iteration 351, loss = 0.24268631\n",
      "Iteration 352, loss = 0.24145662\n",
      "Iteration 353, loss = 0.24112735\n",
      "Iteration 354, loss = 0.23994199\n",
      "Iteration 355, loss = 0.24103550\n",
      "Iteration 356, loss = 0.24128952\n",
      "Iteration 357, loss = 0.24303253\n",
      "Iteration 358, loss = 0.24127961\n",
      "Iteration 359, loss = 0.23943866\n",
      "Iteration 360, loss = 0.23967224\n",
      "Iteration 361, loss = 0.24136129\n",
      "Iteration 362, loss = 0.24198803\n",
      "Iteration 363, loss = 0.23887023\n",
      "Iteration 364, loss = 0.24093125\n",
      "Iteration 365, loss = 0.23912938\n",
      "Iteration 366, loss = 0.24031535\n",
      "Iteration 367, loss = 0.23971557\n",
      "Iteration 368, loss = 0.24167300\n",
      "Iteration 369, loss = 0.23873763\n",
      "Iteration 370, loss = 0.24040997\n",
      "Iteration 371, loss = 0.23779206\n",
      "Iteration 372, loss = 0.23917815\n",
      "Iteration 373, loss = 0.24015989\n",
      "Iteration 374, loss = 0.24004277\n",
      "Iteration 375, loss = 0.23776390\n",
      "Iteration 376, loss = 0.23832405\n",
      "Iteration 377, loss = 0.23708855\n",
      "Iteration 378, loss = 0.23825983\n",
      "Iteration 379, loss = 0.23565673\n",
      "Iteration 380, loss = 0.23682802\n",
      "Iteration 381, loss = 0.23638851\n",
      "Iteration 382, loss = 0.23860927\n",
      "Iteration 383, loss = 0.23825002\n",
      "Iteration 384, loss = 0.23689583\n",
      "Iteration 385, loss = 0.23800430\n",
      "Iteration 386, loss = 0.23655669\n",
      "Iteration 387, loss = 0.23708739\n",
      "Iteration 388, loss = 0.23646862\n",
      "Iteration 389, loss = 0.23740290\n",
      "Iteration 390, loss = 0.23545349\n",
      "Iteration 391, loss = 0.23527891\n",
      "Iteration 392, loss = 0.23652950\n",
      "Iteration 393, loss = 0.23533486\n",
      "Iteration 394, loss = 0.23710576\n",
      "Iteration 395, loss = 0.23597680\n",
      "Iteration 396, loss = 0.23484866\n",
      "Iteration 397, loss = 0.23412743\n",
      "Iteration 398, loss = 0.23504862\n",
      "Iteration 399, loss = 0.23571404\n",
      "Iteration 400, loss = 0.23461348\n",
      "Iteration 401, loss = 0.23191680\n",
      "Iteration 402, loss = 0.23580738\n",
      "Iteration 403, loss = 0.23369833\n",
      "Iteration 404, loss = 0.23480795\n",
      "Iteration 405, loss = 0.23509277\n",
      "Iteration 406, loss = 0.23225086\n",
      "Iteration 407, loss = 0.23547306\n",
      "Iteration 408, loss = 0.23402899\n",
      "Iteration 409, loss = 0.23337485\n",
      "Iteration 410, loss = 0.23373318\n",
      "Iteration 411, loss = 0.23375484\n",
      "Iteration 412, loss = 0.23438077\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy:  0.8370793753018837\n",
      "Train  3\n",
      "Iteration 1, loss = 0.58604021\n",
      "Iteration 2, loss = 0.48388225\n",
      "Iteration 3, loss = 0.45634887\n",
      "Iteration 4, loss = 0.44342213\n",
      "Iteration 5, loss = 0.43731795\n",
      "Iteration 6, loss = 0.43110563\n",
      "Iteration 7, loss = 0.42745982\n",
      "Iteration 8, loss = 0.42551968\n",
      "Iteration 9, loss = 0.42218709\n",
      "Iteration 10, loss = 0.41829434\n",
      "Iteration 11, loss = 0.41791493\n",
      "Iteration 12, loss = 0.41422123\n",
      "Iteration 13, loss = 0.41162439\n",
      "Iteration 14, loss = 0.41038824\n",
      "Iteration 15, loss = 0.40880972\n",
      "Iteration 16, loss = 0.40605691\n",
      "Iteration 17, loss = 0.40332435\n",
      "Iteration 18, loss = 0.40200391\n",
      "Iteration 19, loss = 0.40036126\n",
      "Iteration 20, loss = 0.39850897\n",
      "Iteration 21, loss = 0.39767614\n",
      "Iteration 22, loss = 0.39585066\n",
      "Iteration 23, loss = 0.39593866\n",
      "Iteration 24, loss = 0.39148503\n",
      "Iteration 25, loss = 0.39065389\n",
      "Iteration 26, loss = 0.38831383\n",
      "Iteration 27, loss = 0.38837271\n",
      "Iteration 28, loss = 0.38504752\n",
      "Iteration 29, loss = 0.38648600\n",
      "Iteration 30, loss = 0.38511533\n",
      "Iteration 31, loss = 0.38185499\n",
      "Iteration 32, loss = 0.38033104\n",
      "Iteration 33, loss = 0.37889209\n",
      "Iteration 34, loss = 0.37674003\n",
      "Iteration 35, loss = 0.37713338\n",
      "Iteration 36, loss = 0.37475758\n",
      "Iteration 37, loss = 0.37282039\n",
      "Iteration 38, loss = 0.37204752\n",
      "Iteration 39, loss = 0.37206371\n",
      "Iteration 40, loss = 0.37133983\n",
      "Iteration 41, loss = 0.36874339\n",
      "Iteration 42, loss = 0.36914853\n",
      "Iteration 43, loss = 0.36742600\n",
      "Iteration 44, loss = 0.36653059\n",
      "Iteration 45, loss = 0.36490829\n",
      "Iteration 46, loss = 0.36414883\n",
      "Iteration 47, loss = 0.36293368\n",
      "Iteration 48, loss = 0.36245676\n",
      "Iteration 49, loss = 0.36067807\n",
      "Iteration 50, loss = 0.35994254\n",
      "Iteration 51, loss = 0.36064939\n",
      "Iteration 52, loss = 0.36003871\n",
      "Iteration 53, loss = 0.35620281\n",
      "Iteration 54, loss = 0.35618918\n",
      "Iteration 55, loss = 0.35626234\n",
      "Iteration 56, loss = 0.35477402\n",
      "Iteration 57, loss = 0.35426960\n",
      "Iteration 58, loss = 0.35215614\n",
      "Iteration 59, loss = 0.35346509\n",
      "Iteration 60, loss = 0.35231989\n",
      "Iteration 61, loss = 0.34988979\n",
      "Iteration 62, loss = 0.35040844\n",
      "Iteration 63, loss = 0.34935712\n",
      "Iteration 64, loss = 0.34757118\n",
      "Iteration 65, loss = 0.34818607\n",
      "Iteration 66, loss = 0.34569214\n",
      "Iteration 67, loss = 0.34358655\n",
      "Iteration 68, loss = 0.34406366\n",
      "Iteration 69, loss = 0.34334636\n",
      "Iteration 70, loss = 0.34350186\n",
      "Iteration 71, loss = 0.34356520\n",
      "Iteration 72, loss = 0.34164246\n",
      "Iteration 73, loss = 0.34145874\n",
      "Iteration 74, loss = 0.33967040\n",
      "Iteration 75, loss = 0.34005091\n",
      "Iteration 76, loss = 0.33998721\n",
      "Iteration 77, loss = 0.33777396\n",
      "Iteration 78, loss = 0.33858421\n",
      "Iteration 79, loss = 0.33570596\n",
      "Iteration 80, loss = 0.33541996\n",
      "Iteration 81, loss = 0.33480037\n",
      "Iteration 82, loss = 0.33456341\n",
      "Iteration 83, loss = 0.33320024\n",
      "Iteration 84, loss = 0.33349197\n",
      "Iteration 85, loss = 0.33184859\n",
      "Iteration 86, loss = 0.33024548\n",
      "Iteration 87, loss = 0.33295635\n",
      "Iteration 88, loss = 0.33044981\n",
      "Iteration 89, loss = 0.32933573\n",
      "Iteration 90, loss = 0.32998133\n",
      "Iteration 91, loss = 0.32666147\n",
      "Iteration 92, loss = 0.32715376\n",
      "Iteration 93, loss = 0.32661467\n",
      "Iteration 94, loss = 0.32612394\n",
      "Iteration 95, loss = 0.32617311\n",
      "Iteration 96, loss = 0.32493442\n",
      "Iteration 97, loss = 0.32694486\n",
      "Iteration 98, loss = 0.32326068\n",
      "Iteration 99, loss = 0.32315135\n",
      "Iteration 100, loss = 0.32359226\n",
      "Iteration 101, loss = 0.32345399\n",
      "Iteration 102, loss = 0.32280326\n",
      "Iteration 103, loss = 0.32186694\n",
      "Iteration 104, loss = 0.32138942\n",
      "Iteration 105, loss = 0.32076098\n",
      "Iteration 106, loss = 0.31911376\n",
      "Iteration 107, loss = 0.32034142\n",
      "Iteration 108, loss = 0.31846669\n",
      "Iteration 109, loss = 0.31841640\n",
      "Iteration 110, loss = 0.31742539\n",
      "Iteration 111, loss = 0.31641021\n",
      "Iteration 112, loss = 0.31759955\n",
      "Iteration 113, loss = 0.31664552\n",
      "Iteration 114, loss = 0.31573838\n",
      "Iteration 115, loss = 0.31548864\n",
      "Iteration 116, loss = 0.31530925\n",
      "Iteration 117, loss = 0.31506793\n",
      "Iteration 118, loss = 0.31317500\n",
      "Iteration 119, loss = 0.31290448\n",
      "Iteration 120, loss = 0.31321989\n",
      "Iteration 121, loss = 0.31199970\n",
      "Iteration 122, loss = 0.31198918\n",
      "Iteration 123, loss = 0.31125026\n",
      "Iteration 124, loss = 0.30960877\n",
      "Iteration 125, loss = 0.31058682\n",
      "Iteration 126, loss = 0.30980698\n",
      "Iteration 127, loss = 0.30992850\n",
      "Iteration 128, loss = 0.30976049\n",
      "Iteration 129, loss = 0.30865737\n",
      "Iteration 130, loss = 0.30842880\n",
      "Iteration 131, loss = 0.30816826\n",
      "Iteration 132, loss = 0.30735292\n",
      "Iteration 133, loss = 0.30474688\n",
      "Iteration 134, loss = 0.30757980\n",
      "Iteration 135, loss = 0.30653287\n",
      "Iteration 136, loss = 0.30694397\n",
      "Iteration 137, loss = 0.30612322\n",
      "Iteration 138, loss = 0.30355064\n",
      "Iteration 139, loss = 0.30374176\n",
      "Iteration 140, loss = 0.30275631\n",
      "Iteration 141, loss = 0.30198299\n",
      "Iteration 142, loss = 0.30355029\n",
      "Iteration 143, loss = 0.30195383\n",
      "Iteration 144, loss = 0.30053554\n",
      "Iteration 145, loss = 0.30187658\n",
      "Iteration 146, loss = 0.30162193\n",
      "Iteration 147, loss = 0.30133499\n",
      "Iteration 148, loss = 0.30155139\n",
      "Iteration 149, loss = 0.29876962\n",
      "Iteration 150, loss = 0.30066721\n",
      "Iteration 151, loss = 0.29905261\n",
      "Iteration 152, loss = 0.29785462\n",
      "Iteration 153, loss = 0.29725157\n",
      "Iteration 154, loss = 0.29901594\n",
      "Iteration 155, loss = 0.29684277\n",
      "Iteration 156, loss = 0.29554745\n",
      "Iteration 157, loss = 0.29546393\n",
      "Iteration 158, loss = 0.29585100\n",
      "Iteration 159, loss = 0.29659123\n",
      "Iteration 160, loss = 0.29515626\n",
      "Iteration 161, loss = 0.29620673\n",
      "Iteration 162, loss = 0.29600783\n",
      "Iteration 163, loss = 0.29319280\n",
      "Iteration 164, loss = 0.29515948\n",
      "Iteration 165, loss = 0.29336972\n",
      "Iteration 166, loss = 0.29415750\n",
      "Iteration 167, loss = 0.29330520\n",
      "Iteration 168, loss = 0.29204204\n",
      "Iteration 169, loss = 0.29269727\n",
      "Iteration 170, loss = 0.29105891\n",
      "Iteration 171, loss = 0.29024452\n",
      "Iteration 172, loss = 0.29192518\n",
      "Iteration 173, loss = 0.28939097\n",
      "Iteration 174, loss = 0.29087977\n",
      "Iteration 175, loss = 0.28976006\n",
      "Iteration 176, loss = 0.28913506\n",
      "Iteration 177, loss = 0.28911980\n",
      "Iteration 178, loss = 0.28811143\n",
      "Iteration 179, loss = 0.28740588\n",
      "Iteration 180, loss = 0.28642614\n",
      "Iteration 181, loss = 0.28918693\n",
      "Iteration 182, loss = 0.28721294\n",
      "Iteration 183, loss = 0.28594304\n",
      "Iteration 184, loss = 0.28680493\n",
      "Iteration 185, loss = 0.28504089\n",
      "Iteration 186, loss = 0.28616828\n",
      "Iteration 187, loss = 0.28637855\n",
      "Iteration 188, loss = 0.28583214\n",
      "Iteration 189, loss = 0.28389808\n",
      "Iteration 190, loss = 0.28418421\n",
      "Iteration 191, loss = 0.28461032\n",
      "Iteration 192, loss = 0.28328173\n",
      "Iteration 193, loss = 0.28329884\n",
      "Iteration 194, loss = 0.28477112\n",
      "Iteration 195, loss = 0.28259920\n",
      "Iteration 196, loss = 0.28307934\n",
      "Iteration 197, loss = 0.28290242\n",
      "Iteration 198, loss = 0.28189984\n",
      "Iteration 199, loss = 0.28074617\n",
      "Iteration 200, loss = 0.28204720\n",
      "Iteration 201, loss = 0.28183994\n",
      "Iteration 202, loss = 0.28072090\n",
      "Iteration 203, loss = 0.28071502\n",
      "Iteration 204, loss = 0.28172053\n",
      "Iteration 205, loss = 0.27819632\n",
      "Iteration 206, loss = 0.28013069\n",
      "Iteration 207, loss = 0.27906673\n",
      "Iteration 208, loss = 0.27916995\n",
      "Iteration 209, loss = 0.27913780\n",
      "Iteration 210, loss = 0.27757578\n",
      "Iteration 211, loss = 0.27703986\n",
      "Iteration 212, loss = 0.27780262\n",
      "Iteration 213, loss = 0.27897986\n",
      "Iteration 214, loss = 0.27810136\n",
      "Iteration 215, loss = 0.27751480\n",
      "Iteration 216, loss = 0.27718698\n",
      "Iteration 217, loss = 0.27521633\n",
      "Iteration 218, loss = 0.27497451\n",
      "Iteration 219, loss = 0.27568169\n",
      "Iteration 220, loss = 0.27444710\n",
      "Iteration 221, loss = 0.27459198\n",
      "Iteration 222, loss = 0.27332007\n",
      "Iteration 223, loss = 0.27480150\n",
      "Iteration 224, loss = 0.27483600\n",
      "Iteration 225, loss = 0.27206733\n",
      "Iteration 226, loss = 0.27324268\n",
      "Iteration 227, loss = 0.27461236\n",
      "Iteration 228, loss = 0.27201342\n",
      "Iteration 229, loss = 0.27312645\n",
      "Iteration 230, loss = 0.27193131\n",
      "Iteration 231, loss = 0.27137163\n",
      "Iteration 232, loss = 0.27028856\n",
      "Iteration 233, loss = 0.27162651\n",
      "Iteration 234, loss = 0.27199387\n",
      "Iteration 235, loss = 0.27191333\n",
      "Iteration 236, loss = 0.26978500\n",
      "Iteration 237, loss = 0.26908778\n",
      "Iteration 238, loss = 0.27014132\n",
      "Iteration 239, loss = 0.27015284\n",
      "Iteration 240, loss = 0.26870499\n",
      "Iteration 241, loss = 0.27067419\n",
      "Iteration 242, loss = 0.27069550\n",
      "Iteration 243, loss = 0.26700726\n",
      "Iteration 244, loss = 0.26927972\n",
      "Iteration 245, loss = 0.26836750\n",
      "Iteration 246, loss = 0.26830459\n",
      "Iteration 247, loss = 0.26862099\n",
      "Iteration 248, loss = 0.26773893\n",
      "Iteration 249, loss = 0.26815547\n",
      "Iteration 250, loss = 0.26661387\n",
      "Iteration 251, loss = 0.26764575\n",
      "Iteration 252, loss = 0.26498787\n",
      "Iteration 253, loss = 0.26568135\n",
      "Iteration 254, loss = 0.26470078\n",
      "Iteration 255, loss = 0.26827559\n",
      "Iteration 256, loss = 0.26602744\n",
      "Iteration 257, loss = 0.26699639\n",
      "Iteration 258, loss = 0.26638252\n",
      "Iteration 259, loss = 0.26425773\n",
      "Iteration 260, loss = 0.26353118\n",
      "Iteration 261, loss = 0.26605914\n",
      "Iteration 262, loss = 0.26505644\n",
      "Iteration 263, loss = 0.26498362\n",
      "Iteration 264, loss = 0.26309462\n",
      "Iteration 265, loss = 0.26285816\n",
      "Iteration 266, loss = 0.26316652\n",
      "Iteration 267, loss = 0.25995252\n",
      "Iteration 268, loss = 0.26222123\n",
      "Iteration 269, loss = 0.26282648\n",
      "Iteration 270, loss = 0.26272055\n",
      "Iteration 271, loss = 0.26242177\n",
      "Iteration 272, loss = 0.26112545\n",
      "Iteration 273, loss = 0.26358311\n",
      "Iteration 274, loss = 0.25953710\n",
      "Iteration 275, loss = 0.26195660\n",
      "Iteration 276, loss = 0.26403119\n",
      "Iteration 277, loss = 0.25919282\n",
      "Iteration 278, loss = 0.25904989\n",
      "Iteration 279, loss = 0.25820985\n",
      "Iteration 280, loss = 0.26096819\n",
      "Iteration 281, loss = 0.25654447\n",
      "Iteration 282, loss = 0.25806674\n",
      "Iteration 283, loss = 0.26053811\n",
      "Iteration 284, loss = 0.26114307\n",
      "Iteration 285, loss = 0.25769829\n",
      "Iteration 286, loss = 0.25979629\n",
      "Iteration 287, loss = 0.25934530\n",
      "Iteration 288, loss = 0.25732204\n",
      "Iteration 289, loss = 0.25749305\n",
      "Iteration 290, loss = 0.25826650\n",
      "Iteration 291, loss = 0.25676168\n",
      "Iteration 292, loss = 0.25688007\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy:  0.8085654483980036\n",
      "Train  4\n",
      "Iteration 1, loss = 0.58053098\n",
      "Iteration 2, loss = 0.48604924\n",
      "Iteration 3, loss = 0.46438448\n",
      "Iteration 4, loss = 0.44952589\n",
      "Iteration 5, loss = 0.44442678\n",
      "Iteration 6, loss = 0.43933478\n",
      "Iteration 7, loss = 0.43550143\n",
      "Iteration 8, loss = 0.43081583\n",
      "Iteration 9, loss = 0.42691360\n",
      "Iteration 10, loss = 0.42570056\n",
      "Iteration 11, loss = 0.42308033\n",
      "Iteration 12, loss = 0.41900150\n",
      "Iteration 13, loss = 0.41712531\n",
      "Iteration 14, loss = 0.41668113\n",
      "Iteration 15, loss = 0.41325457\n",
      "Iteration 16, loss = 0.41133956\n",
      "Iteration 17, loss = 0.41033149\n",
      "Iteration 18, loss = 0.40773041\n",
      "Iteration 19, loss = 0.40522480\n",
      "Iteration 20, loss = 0.40138820\n",
      "Iteration 21, loss = 0.40127266\n",
      "Iteration 22, loss = 0.39937862\n",
      "Iteration 23, loss = 0.39770097\n",
      "Iteration 24, loss = 0.39559344\n",
      "Iteration 25, loss = 0.39589387\n",
      "Iteration 26, loss = 0.39239280\n",
      "Iteration 27, loss = 0.39164657\n",
      "Iteration 28, loss = 0.38976825\n",
      "Iteration 29, loss = 0.38905369\n",
      "Iteration 30, loss = 0.38676906\n",
      "Iteration 31, loss = 0.38464830\n",
      "Iteration 32, loss = 0.38301086\n",
      "Iteration 33, loss = 0.38236692\n",
      "Iteration 34, loss = 0.38012731\n",
      "Iteration 35, loss = 0.37888744\n",
      "Iteration 36, loss = 0.37842915\n",
      "Iteration 37, loss = 0.37755611\n",
      "Iteration 38, loss = 0.37540950\n",
      "Iteration 39, loss = 0.37520858\n",
      "Iteration 40, loss = 0.37492342\n",
      "Iteration 41, loss = 0.37311986\n",
      "Iteration 42, loss = 0.37152489\n",
      "Iteration 43, loss = 0.36877311\n",
      "Iteration 44, loss = 0.37058625\n",
      "Iteration 45, loss = 0.36744724\n",
      "Iteration 46, loss = 0.36599692\n",
      "Iteration 47, loss = 0.36556494\n",
      "Iteration 48, loss = 0.36613302\n",
      "Iteration 49, loss = 0.36531733\n",
      "Iteration 50, loss = 0.36299326\n",
      "Iteration 51, loss = 0.36196398\n",
      "Iteration 52, loss = 0.36145240\n",
      "Iteration 53, loss = 0.36104976\n",
      "Iteration 54, loss = 0.35793553\n",
      "Iteration 55, loss = 0.35785731\n",
      "Iteration 56, loss = 0.35768160\n",
      "Iteration 57, loss = 0.35521556\n",
      "Iteration 58, loss = 0.35419384\n",
      "Iteration 59, loss = 0.35408038\n",
      "Iteration 60, loss = 0.35427944\n",
      "Iteration 61, loss = 0.35106725\n",
      "Iteration 62, loss = 0.35134266\n",
      "Iteration 63, loss = 0.35218209\n",
      "Iteration 64, loss = 0.34969956\n",
      "Iteration 65, loss = 0.34990514\n",
      "Iteration 66, loss = 0.34799333\n",
      "Iteration 67, loss = 0.34746461\n",
      "Iteration 68, loss = 0.34610592\n",
      "Iteration 69, loss = 0.34601309\n",
      "Iteration 70, loss = 0.34485878\n",
      "Iteration 71, loss = 0.34336449\n",
      "Iteration 72, loss = 0.34276428\n",
      "Iteration 73, loss = 0.34247793\n",
      "Iteration 74, loss = 0.34126982\n",
      "Iteration 75, loss = 0.34083779\n",
      "Iteration 76, loss = 0.33934907\n",
      "Iteration 77, loss = 0.34009976\n",
      "Iteration 78, loss = 0.33788723\n",
      "Iteration 79, loss = 0.33886512\n",
      "Iteration 80, loss = 0.33747258\n",
      "Iteration 81, loss = 0.33400418\n",
      "Iteration 82, loss = 0.33635938\n",
      "Iteration 83, loss = 0.33551508\n",
      "Iteration 84, loss = 0.33311034\n",
      "Iteration 85, loss = 0.33252723\n",
      "Iteration 86, loss = 0.33239003\n",
      "Iteration 87, loss = 0.33058567\n",
      "Iteration 88, loss = 0.32985220\n",
      "Iteration 89, loss = 0.33094532\n",
      "Iteration 90, loss = 0.32907225\n",
      "Iteration 91, loss = 0.32815373\n",
      "Iteration 92, loss = 0.32857604\n",
      "Iteration 93, loss = 0.32708240\n",
      "Iteration 94, loss = 0.32622902\n",
      "Iteration 95, loss = 0.32629932\n",
      "Iteration 96, loss = 0.32510562\n",
      "Iteration 97, loss = 0.32572245\n",
      "Iteration 98, loss = 0.32598556\n",
      "Iteration 99, loss = 0.32397618\n",
      "Iteration 100, loss = 0.32257729\n",
      "Iteration 101, loss = 0.32281326\n",
      "Iteration 102, loss = 0.32271224\n",
      "Iteration 103, loss = 0.32078637\n",
      "Iteration 104, loss = 0.32018936\n",
      "Iteration 105, loss = 0.31909161\n",
      "Iteration 106, loss = 0.31933751\n",
      "Iteration 107, loss = 0.32022139\n",
      "Iteration 108, loss = 0.31906202\n",
      "Iteration 109, loss = 0.31755301\n",
      "Iteration 110, loss = 0.31567022\n",
      "Iteration 111, loss = 0.31679188\n",
      "Iteration 112, loss = 0.31700738\n",
      "Iteration 113, loss = 0.31489478\n",
      "Iteration 114, loss = 0.31474595\n",
      "Iteration 115, loss = 0.31384940\n",
      "Iteration 116, loss = 0.31268197\n",
      "Iteration 117, loss = 0.31266064\n",
      "Iteration 118, loss = 0.31150762\n",
      "Iteration 119, loss = 0.31160099\n",
      "Iteration 120, loss = 0.31180793\n",
      "Iteration 121, loss = 0.31094695\n",
      "Iteration 122, loss = 0.30943720\n",
      "Iteration 123, loss = 0.30961667\n",
      "Iteration 124, loss = 0.30993624\n",
      "Iteration 125, loss = 0.30759163\n",
      "Iteration 126, loss = 0.30703279\n",
      "Iteration 127, loss = 0.30561981\n",
      "Iteration 128, loss = 0.30761315\n",
      "Iteration 129, loss = 0.30598119\n",
      "Iteration 130, loss = 0.30604437\n",
      "Iteration 131, loss = 0.30615249\n",
      "Iteration 132, loss = 0.30457339\n",
      "Iteration 133, loss = 0.30389466\n",
      "Iteration 134, loss = 0.30475441\n",
      "Iteration 135, loss = 0.30281894\n",
      "Iteration 136, loss = 0.30297504\n",
      "Iteration 137, loss = 0.30184759\n",
      "Iteration 138, loss = 0.30101489\n",
      "Iteration 139, loss = 0.30135716\n",
      "Iteration 140, loss = 0.29920941\n",
      "Iteration 141, loss = 0.29887556\n",
      "Iteration 142, loss = 0.30147276\n",
      "Iteration 143, loss = 0.30002307\n",
      "Iteration 144, loss = 0.29846998\n",
      "Iteration 145, loss = 0.29777572\n",
      "Iteration 146, loss = 0.29763179\n",
      "Iteration 147, loss = 0.29794352\n",
      "Iteration 148, loss = 0.29718227\n",
      "Iteration 149, loss = 0.29566155\n",
      "Iteration 150, loss = 0.29661545\n",
      "Iteration 151, loss = 0.29464012\n",
      "Iteration 152, loss = 0.29529456\n",
      "Iteration 153, loss = 0.29393593\n",
      "Iteration 154, loss = 0.29495827\n",
      "Iteration 155, loss = 0.29534578\n",
      "Iteration 156, loss = 0.29335840\n",
      "Iteration 157, loss = 0.29300860\n",
      "Iteration 158, loss = 0.29035090\n",
      "Iteration 159, loss = 0.29196674\n",
      "Iteration 160, loss = 0.29140875\n",
      "Iteration 161, loss = 0.29061049\n",
      "Iteration 162, loss = 0.29071869\n",
      "Iteration 163, loss = 0.28960788\n",
      "Iteration 164, loss = 0.29027461\n",
      "Iteration 165, loss = 0.28945882\n",
      "Iteration 166, loss = 0.28978036\n",
      "Iteration 167, loss = 0.28965781\n",
      "Iteration 168, loss = 0.28707708\n",
      "Iteration 169, loss = 0.28713810\n",
      "Iteration 170, loss = 0.28784608\n",
      "Iteration 171, loss = 0.28688877\n",
      "Iteration 172, loss = 0.28689599\n",
      "Iteration 173, loss = 0.28644141\n",
      "Iteration 174, loss = 0.28602348\n",
      "Iteration 175, loss = 0.28569437\n",
      "Iteration 176, loss = 0.28644362\n",
      "Iteration 177, loss = 0.28486115\n",
      "Iteration 178, loss = 0.28280741\n",
      "Iteration 179, loss = 0.28175586\n",
      "Iteration 180, loss = 0.28470466\n",
      "Iteration 181, loss = 0.28196420\n",
      "Iteration 182, loss = 0.28287754\n",
      "Iteration 183, loss = 0.28149372\n",
      "Iteration 184, loss = 0.28122113\n",
      "Iteration 185, loss = 0.28026239\n",
      "Iteration 186, loss = 0.28002823\n",
      "Iteration 187, loss = 0.27945885\n",
      "Iteration 188, loss = 0.27821392\n",
      "Iteration 189, loss = 0.27997213\n",
      "Iteration 190, loss = 0.28112998\n",
      "Iteration 191, loss = 0.28101384\n",
      "Iteration 192, loss = 0.27817790\n",
      "Iteration 193, loss = 0.27777424\n",
      "Iteration 194, loss = 0.27811459\n",
      "Iteration 195, loss = 0.27489798\n",
      "Iteration 196, loss = 0.27836044\n",
      "Iteration 197, loss = 0.27614414\n",
      "Iteration 198, loss = 0.27582269\n",
      "Iteration 199, loss = 0.27620613\n",
      "Iteration 200, loss = 0.27498671\n",
      "Iteration 201, loss = 0.27562291\n",
      "Iteration 202, loss = 0.27514717\n",
      "Iteration 203, loss = 0.27410145\n",
      "Iteration 204, loss = 0.27457451\n",
      "Iteration 205, loss = 0.27401752\n",
      "Iteration 206, loss = 0.27469115\n",
      "Iteration 207, loss = 0.27412160\n",
      "Iteration 208, loss = 0.27291938\n",
      "Iteration 209, loss = 0.27321389\n",
      "Iteration 210, loss = 0.27136936\n",
      "Iteration 211, loss = 0.27190363\n",
      "Iteration 212, loss = 0.27171290\n",
      "Iteration 213, loss = 0.27029137\n",
      "Iteration 214, loss = 0.27085751\n",
      "Iteration 215, loss = 0.26977090\n",
      "Iteration 216, loss = 0.27063209\n",
      "Iteration 217, loss = 0.27011304\n",
      "Iteration 218, loss = 0.27175754\n",
      "Iteration 219, loss = 0.26884025\n",
      "Iteration 220, loss = 0.26994527\n",
      "Iteration 221, loss = 0.26697817\n",
      "Iteration 222, loss = 0.26793919\n",
      "Iteration 223, loss = 0.26954141\n",
      "Iteration 224, loss = 0.26946632\n",
      "Iteration 225, loss = 0.26718837\n",
      "Iteration 226, loss = 0.26846965\n",
      "Iteration 227, loss = 0.26689959\n",
      "Iteration 228, loss = 0.26752063\n",
      "Iteration 229, loss = 0.26498566\n",
      "Iteration 230, loss = 0.26746655\n",
      "Iteration 231, loss = 0.26420826\n",
      "Iteration 232, loss = 0.26446090\n",
      "Iteration 233, loss = 0.26512758\n",
      "Iteration 234, loss = 0.26755085\n",
      "Iteration 235, loss = 0.26681971\n",
      "Iteration 236, loss = 0.26389087\n",
      "Iteration 237, loss = 0.26332793\n",
      "Iteration 238, loss = 0.26639213\n",
      "Iteration 239, loss = 0.26280186\n",
      "Iteration 240, loss = 0.26191289\n",
      "Iteration 241, loss = 0.26310438\n",
      "Iteration 242, loss = 0.26354245\n",
      "Iteration 243, loss = 0.26391497\n",
      "Iteration 244, loss = 0.26092733\n",
      "Iteration 245, loss = 0.26139844\n",
      "Iteration 246, loss = 0.26357771\n",
      "Iteration 247, loss = 0.26219083\n",
      "Iteration 248, loss = 0.26030496\n",
      "Iteration 249, loss = 0.26003491\n",
      "Iteration 250, loss = 0.26266793\n",
      "Iteration 251, loss = 0.25970192\n",
      "Iteration 252, loss = 0.25845374\n",
      "Iteration 253, loss = 0.26056001\n",
      "Iteration 254, loss = 0.25744844\n",
      "Iteration 255, loss = 0.25942725\n",
      "Iteration 256, loss = 0.25786959\n",
      "Iteration 257, loss = 0.25853675\n",
      "Iteration 258, loss = 0.25710659\n",
      "Iteration 259, loss = 0.25619097\n",
      "Iteration 260, loss = 0.25782969\n",
      "Iteration 261, loss = 0.25759036\n",
      "Iteration 262, loss = 0.25812671\n",
      "Iteration 263, loss = 0.25755002\n",
      "Iteration 264, loss = 0.25723035\n",
      "Iteration 265, loss = 0.25754634\n",
      "Iteration 266, loss = 0.25455447\n",
      "Iteration 267, loss = 0.25560003\n",
      "Iteration 268, loss = 0.25588751\n",
      "Iteration 269, loss = 0.25499427\n",
      "Iteration 270, loss = 0.25384930\n",
      "Iteration 271, loss = 0.25582990\n",
      "Iteration 272, loss = 0.25528058\n",
      "Iteration 273, loss = 0.25632858\n",
      "Iteration 274, loss = 0.25531715\n",
      "Iteration 275, loss = 0.25322517\n",
      "Iteration 276, loss = 0.25446187\n",
      "Iteration 277, loss = 0.25370629\n",
      "Iteration 278, loss = 0.25210009\n",
      "Iteration 279, loss = 0.25624232\n",
      "Iteration 280, loss = 0.25310949\n",
      "Iteration 281, loss = 0.25133236\n",
      "Iteration 282, loss = 0.25210743\n",
      "Iteration 283, loss = 0.25219097\n",
      "Iteration 284, loss = 0.25133582\n",
      "Iteration 285, loss = 0.25103999\n",
      "Iteration 286, loss = 0.25056740\n",
      "Iteration 287, loss = 0.25055682\n",
      "Iteration 288, loss = 0.24910881\n",
      "Iteration 289, loss = 0.25314195\n",
      "Iteration 290, loss = 0.24916627\n",
      "Iteration 291, loss = 0.25061122\n",
      "Iteration 292, loss = 0.25015299\n",
      "Iteration 293, loss = 0.25148721\n",
      "Iteration 294, loss = 0.24850251\n",
      "Iteration 295, loss = 0.24759532\n",
      "Iteration 296, loss = 0.24763219\n",
      "Iteration 297, loss = 0.25001814\n",
      "Iteration 298, loss = 0.24790049\n",
      "Iteration 299, loss = 0.24953049\n",
      "Iteration 300, loss = 0.24646799\n",
      "Iteration 301, loss = 0.24838356\n",
      "Iteration 302, loss = 0.24609321\n",
      "Iteration 303, loss = 0.24675109\n",
      "Iteration 304, loss = 0.24662293\n",
      "Iteration 305, loss = 0.24715464\n",
      "Iteration 306, loss = 0.24668910\n",
      "Iteration 307, loss = 0.24816676\n",
      "Iteration 308, loss = 0.24547209\n",
      "Iteration 309, loss = 0.24506126\n",
      "Iteration 310, loss = 0.24386780\n",
      "Iteration 311, loss = 0.24632984\n",
      "Iteration 312, loss = 0.24388502\n",
      "Iteration 313, loss = 0.24664948\n",
      "Iteration 314, loss = 0.24347528\n",
      "Iteration 315, loss = 0.24604585\n",
      "Iteration 316, loss = 0.24609306\n",
      "Iteration 317, loss = 0.24578030\n",
      "Iteration 318, loss = 0.24305663\n",
      "Iteration 319, loss = 0.24204869\n",
      "Iteration 320, loss = 0.24280841\n",
      "Iteration 321, loss = 0.24522114\n",
      "Iteration 322, loss = 0.24300244\n",
      "Iteration 323, loss = 0.24557909\n",
      "Iteration 324, loss = 0.24218642\n",
      "Iteration 325, loss = 0.24416670\n",
      "Iteration 326, loss = 0.24087590\n",
      "Iteration 327, loss = 0.24277920\n",
      "Iteration 328, loss = 0.24250006\n",
      "Iteration 329, loss = 0.24164406\n",
      "Iteration 330, loss = 0.24036580\n",
      "Iteration 331, loss = 0.24009930\n",
      "Iteration 332, loss = 0.24118062\n",
      "Iteration 333, loss = 0.24048610\n",
      "Iteration 334, loss = 0.23975579\n",
      "Iteration 335, loss = 0.23926671\n",
      "Iteration 336, loss = 0.23922661\n",
      "Iteration 337, loss = 0.24051837\n",
      "Iteration 338, loss = 0.24064971\n",
      "Iteration 339, loss = 0.23927867\n",
      "Iteration 340, loss = 0.23947806\n",
      "Iteration 341, loss = 0.23970189\n",
      "Iteration 342, loss = 0.23805430\n",
      "Iteration 343, loss = 0.23909243\n",
      "Iteration 344, loss = 0.23876650\n",
      "Iteration 345, loss = 0.23939716\n",
      "Iteration 346, loss = 0.23773764\n",
      "Iteration 347, loss = 0.23820810\n",
      "Iteration 348, loss = 0.23751888\n",
      "Iteration 349, loss = 0.23709454\n",
      "Iteration 350, loss = 0.23574877\n",
      "Iteration 351, loss = 0.23682129\n",
      "Iteration 352, loss = 0.23674775\n",
      "Iteration 353, loss = 0.23595399\n",
      "Iteration 354, loss = 0.23484728\n",
      "Iteration 355, loss = 0.23754082\n",
      "Iteration 356, loss = 0.23589357\n",
      "Iteration 357, loss = 0.23586496\n",
      "Iteration 358, loss = 0.23593882\n",
      "Iteration 359, loss = 0.23759791\n",
      "Iteration 360, loss = 0.23809417\n",
      "Iteration 361, loss = 0.23465804\n",
      "Iteration 362, loss = 0.23499576\n",
      "Iteration 363, loss = 0.23312022\n",
      "Iteration 364, loss = 0.23376742\n",
      "Iteration 365, loss = 0.23497448\n",
      "Iteration 366, loss = 0.23355426\n",
      "Iteration 367, loss = 0.23412246\n",
      "Iteration 368, loss = 0.23220254\n",
      "Iteration 369, loss = 0.23313927\n",
      "Iteration 370, loss = 0.23419534\n",
      "Iteration 371, loss = 0.23274202\n",
      "Iteration 372, loss = 0.23446663\n",
      "Iteration 373, loss = 0.23405734\n",
      "Iteration 374, loss = 0.23368646\n",
      "Iteration 375, loss = 0.23436563\n",
      "Iteration 376, loss = 0.23270036\n",
      "Iteration 377, loss = 0.23195652\n",
      "Iteration 378, loss = 0.23178171\n",
      "Iteration 379, loss = 0.23203789\n",
      "Iteration 380, loss = 0.23421685\n",
      "Iteration 381, loss = 0.23227516\n",
      "Iteration 382, loss = 0.23191183\n",
      "Iteration 383, loss = 0.23168283\n",
      "Iteration 384, loss = 0.23053418\n",
      "Iteration 385, loss = 0.23053521\n",
      "Iteration 386, loss = 0.22924537\n",
      "Iteration 387, loss = 0.22831427\n",
      "Iteration 388, loss = 0.23202310\n",
      "Iteration 389, loss = 0.23108737\n",
      "Iteration 390, loss = 0.23090716\n",
      "Iteration 391, loss = 0.22968149\n",
      "Iteration 392, loss = 0.22903857\n",
      "Iteration 393, loss = 0.22938654\n",
      "Iteration 394, loss = 0.22885302\n",
      "Iteration 395, loss = 0.23030352\n",
      "Iteration 396, loss = 0.22777350\n",
      "Iteration 397, loss = 0.22833393\n",
      "Iteration 398, loss = 0.23039652\n",
      "Iteration 399, loss = 0.23055061\n",
      "Iteration 400, loss = 0.22781262\n",
      "Iteration 401, loss = 0.22760713\n",
      "Iteration 402, loss = 0.22779931\n",
      "Iteration 403, loss = 0.22852756\n",
      "Iteration 404, loss = 0.22835171\n",
      "Iteration 405, loss = 0.22719700\n",
      "Iteration 406, loss = 0.22684508\n",
      "Iteration 407, loss = 0.22654737\n",
      "Iteration 408, loss = 0.22830512\n",
      "Iteration 409, loss = 0.22823731\n",
      "Iteration 410, loss = 0.22727105\n",
      "Iteration 411, loss = 0.22720355\n",
      "Iteration 412, loss = 0.22860945\n",
      "Iteration 413, loss = 0.22528528\n",
      "Iteration 414, loss = 0.22563744\n",
      "Iteration 415, loss = 0.22474244\n",
      "Iteration 416, loss = 0.22565878\n",
      "Iteration 417, loss = 0.22679320\n",
      "Iteration 418, loss = 0.22774261\n",
      "Iteration 419, loss = 0.22502139\n",
      "Iteration 420, loss = 0.22440417\n",
      "Iteration 421, loss = 0.22509559\n",
      "Iteration 422, loss = 0.22568033\n",
      "Iteration 423, loss = 0.22470492\n",
      "Iteration 424, loss = 0.22660297\n",
      "Iteration 425, loss = 0.22486375\n",
      "Iteration 426, loss = 0.22322146\n",
      "Iteration 427, loss = 0.22524725\n",
      "Iteration 428, loss = 0.22590285\n",
      "Iteration 429, loss = 0.22546994\n",
      "Iteration 430, loss = 0.22508400\n",
      "Iteration 431, loss = 0.22359656\n",
      "Iteration 432, loss = 0.22385227\n",
      "Iteration 433, loss = 0.22351506\n",
      "Iteration 434, loss = 0.22265982\n",
      "Iteration 435, loss = 0.22307025\n",
      "Iteration 436, loss = 0.22271315\n",
      "Iteration 437, loss = 0.22347322\n",
      "Iteration 438, loss = 0.22192550\n",
      "Iteration 439, loss = 0.22447221\n",
      "Iteration 440, loss = 0.22374571\n",
      "Iteration 441, loss = 0.22134482\n",
      "Iteration 442, loss = 0.22029563\n",
      "Iteration 443, loss = 0.22299289\n",
      "Iteration 444, loss = 0.22212023\n",
      "Iteration 445, loss = 0.22125294\n",
      "Iteration 446, loss = 0.22147598\n",
      "Iteration 447, loss = 0.22293746\n",
      "Iteration 448, loss = 0.22263607\n",
      "Iteration 449, loss = 0.22195784\n",
      "Iteration 450, loss = 0.22128532\n",
      "Iteration 451, loss = 0.22173338\n",
      "Iteration 452, loss = 0.22102192\n",
      "Iteration 453, loss = 0.22109597\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy:  0.8272902914184511\n"
     ]
    }
   ],
   "source": [
    "n_train = 5\n",
    "accs = []\n",
    "models = []\n",
    "for i in range(n_train):\n",
    "    print(\"Train \", i)\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, verbose=True, random_state=np.random.randint(0, 1000))\n",
    "    model.fit(X_train_Sanus, y_Sanus_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_Sanus_test, y_pred)\n",
    "    accs.append(acc)\n",
    "    models.append(model)\n",
    "    print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy:  0.8221413620995008\n",
      "Std accuracy:  0.009620275671860821\n",
      "Accuracy =  0.8221413620995008  +/-  0.009620275671860821\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print(\"Mean accuracy: \", np.mean(accs))\n",
    "print(\"Std accuracy: \", np.std(accs))\n",
    "print(\"Accuracy = \", np.mean(accs), \" +/- \", np.std(accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8370793753018837\n"
     ]
    }
   ],
   "source": [
    "# best model\n",
    "model = models[np.argmax(accs)]\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_Sanus_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_Sanus_test, y_pred)\n",
    "cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure()\n",
    "plt.title('Confusion matrix of the best model for Sniffing Anogenital')\n",
    "sns.heatmap(cm, annot=True, xticklabels=['Not Sniffing', 'Sniffing '], yticklabels=['Not Sniffing', 'Sniffing'], cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseline_models/new_dataset/model_Sanus.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, 'baseline_models/new_dataset/model_Sanus.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(beh_names[5])\n",
    "print(beh_names.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poursuite Resident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_poursuitR_train = y_train[:, 5]\n",
    "y_poursuitR_test = y_test[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Nans in the data\n",
    "\n",
    "print(np.isnan(y_poursuitR_train).sum())\n",
    "\n",
    "# Discard the Nans\n",
    "X_train_pourR = X_train[~np.isnan(y_poursuitR_train)]\n",
    "y_poursuitR_train = y_poursuitR_train[~np.isnan(y_poursuitR_train)]\n",
    "\n",
    "X_test_pourR = X_test[~np.isnan(y_poursuitR_test)]\n",
    "y_poursuitR_test = y_poursuitR_test[~np.isnan(y_poursuitR_test)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Balance\n",
    "plt.hist(y_poursuitR_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print('Active: ', y_poursuitR_train.sum())\n",
    "print('Inactive: ', (1-y_poursuitR_train).sum())\n",
    "print(' Percentage of active: ', y_poursuitR_train.sum() / len(y_poursuitR_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I don't have yet sufficient data, but let's try it anyway**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the inactive class\n",
    "idx = np.where(y_poursuitR_train == 0)[0]\n",
    "idx = np.random.choice(idx, np.sum(y_poursuitR_train == 1), replace=False)\n",
    "idx = np.concatenate([np.where(y_poursuitR_train == 1)[0], idx])\n",
    "\n",
    "X_train_pourR = X_train[idx]\n",
    "y_poursuitR_train = y_poursuitR_train[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class balance\n",
    "plt.hist(y_poursuitR_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print('Dimension of the training set: ', X_train_pourR.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too many features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 train to see variance\n",
    "n_train = 5\n",
    "accs = []\n",
    "models = []\n",
    "for i in range(n_train):\n",
    "    print(\"Train \", i)\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, verbose=True)\n",
    "    model.fit(X_train_pourR, y_poursuitR_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_poursuitR_test, y_pred)\n",
    "    accs.append(acc)\n",
    "    models.append(model)\n",
    "    print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "print(\"accuracy: \", accs)\n",
    "print(\" variance accuracy: \", np.var(accs))\n",
    "\n",
    "print(\"The accuracy is:\", np.mean(accs), \" +/- \", np.std(accs))\n",
    "\n",
    "# Best model\n",
    "model = models[np.argmax(accs)]\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_poursuitR_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_poursuitR_test, y_pred)\n",
    "cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure()\n",
    "plt.title('Confusion matrix of the best model for Following')\n",
    "sns.heatmap(cm, annot=True, xticklabels=['Not Following', 'Following'], yticklabels=['Not Following', 'Following'], cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, 'baseline_models/new_dataset/model_poursuitR.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_names[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dominance Resident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_domR_train = y_train[:,6]\n",
    "y_domR_test = y_test[:,6]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class balance\n",
    "plt.hist(y_domR_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print('Active: ', y_domR_train.sum())\n",
    "print('Inactive: ', (1-y_domR_train).sum())\n",
    "print(' Percentage of active: ', y_domR_train.sum() / len(y_domR_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the inactive class\n",
    "idx = np.where(y_domR_train == 0)[0]\n",
    "idx = np.random.choice(idx, np.sum(y_domR_train == 1), replace=False)\n",
    "idx = np.concatenate([np.where(y_domR_train == 1)[0], idx])\n",
    "\n",
    "X_train_domR = X_train[idx]\n",
    "y_domR_train = y_domR_train[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class balance\n",
    "plt.hist(y_domR_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 train to see variance\n",
    "n_train = 5\n",
    "accs = []\n",
    "models = []\n",
    "for i in range(n_train):\n",
    "    print(\"Train \", i)\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, verbose=True)\n",
    "    model.fit(X_train_domR, y_domR_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_domR_test, y_pred)\n",
    "    accs.append(acc)\n",
    "    models.append(model)\n",
    "    print(\"Accuracy: \", acc)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "print(\"accuracy: \", accs)\n",
    "print(\" variance accuracy: \", np.var(accs))\n",
    "\n",
    "print(\"The accuracy is:\", np.mean(accs), \" +/- \", np.std(accs))\n",
    "\n",
    "# Best model\n",
    "model = models[np.argmax(accs)]\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_domR_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_domR_test, y_pred)\n",
    "cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure()\n",
    "plt.title('Confusion matrix of the best model for Dominance')\n",
    "sns.heatmap(cm, annot=True, xticklabels=['Not Dominance', 'Dominance'], yticklabels=['Not Dominance', 'Dominance'], cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, 'baseline_models/new_dataset/model_domR.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rearing_R'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beh_names[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rearing R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rearingR_train = y_train[:, 7]\n",
    "y_rearingR_test = y_test[:, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Nans in the data\n",
    "np.isnan(y_rearingR_train).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active:  3699\n",
      "Inactive:  86800\n",
      "Percentage:  0.040873379816351564\n"
     ]
    }
   ],
   "source": [
    "# Class Balance\n",
    "plt.hist(y_rearingR_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print('Active: ', np.sum(y_rearingR_train == 1))\n",
    "print('Inactive: ', np.sum(y_rearingR_train == 0))\n",
    "print('Percentage: ', np.sum(y_rearingR_train == 1) / len(y_rearingR_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train dataset size:  (7398, 108)\n"
     ]
    }
   ],
   "source": [
    "# Downsample the inactive class\n",
    "idx = np.where(y_rearingR_train == 0)[0]\n",
    "idx = np.random.choice(idx, np.sum(y_rearingR_train == 1), replace=False)\n",
    "idx = np.concatenate([np.where(y_rearingR_train == 1)[0], idx])\n",
    "idx = np.random.permutation(idx)\n",
    "\n",
    "X_rearingR_train = X_train[idx]\n",
    "y_rearingR_train = y_rearingR_train[idx]\n",
    "\n",
    "# class balance\n",
    "plt.hist(y_rearingR_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print(' Train dataset size: ', X_rearingR_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train  0\n",
      "Iteration 1, loss = 0.67594795\n",
      "Iteration 2, loss = 0.63067776\n",
      "Iteration 3, loss = 0.58493418\n",
      "Iteration 4, loss = 0.54579267\n",
      "Iteration 5, loss = 0.51545653\n",
      "Iteration 6, loss = 0.48757759\n",
      "Iteration 7, loss = 0.46850505\n",
      "Iteration 8, loss = 0.44794172\n",
      "Iteration 9, loss = 0.43264006\n",
      "Iteration 10, loss = 0.43262509\n",
      "Iteration 11, loss = 0.42487710\n",
      "Iteration 12, loss = 0.41445602\n",
      "Iteration 13, loss = 0.39223281\n",
      "Iteration 14, loss = 0.38319690\n",
      "Iteration 15, loss = 0.37918998\n",
      "Iteration 16, loss = 0.37340802\n",
      "Iteration 17, loss = 0.37516134\n",
      "Iteration 18, loss = 0.36444549\n",
      "Iteration 19, loss = 0.35594428\n",
      "Iteration 20, loss = 0.34860871\n",
      "Iteration 21, loss = 0.35126114\n",
      "Iteration 22, loss = 0.34368536\n",
      "Iteration 23, loss = 0.33702718\n",
      "Iteration 24, loss = 0.34430517\n",
      "Iteration 25, loss = 0.33070117\n",
      "Iteration 26, loss = 0.32570836\n",
      "Iteration 27, loss = 0.32073927\n",
      "Iteration 28, loss = 0.32322198\n",
      "Iteration 29, loss = 0.32058798\n",
      "Iteration 30, loss = 0.31861651\n",
      "Iteration 31, loss = 0.32023422\n",
      "Iteration 32, loss = 0.31027725\n",
      "Iteration 33, loss = 0.30354025\n",
      "Iteration 34, loss = 0.29977680\n",
      "Iteration 35, loss = 0.29759081\n",
      "Iteration 36, loss = 0.29199891\n",
      "Iteration 37, loss = 0.31113277\n",
      "Iteration 38, loss = 0.29139594\n",
      "Iteration 39, loss = 0.29818677\n",
      "Iteration 40, loss = 0.28695048\n",
      "Iteration 41, loss = 0.28937343\n",
      "Iteration 42, loss = 0.28250985\n",
      "Iteration 43, loss = 0.27432388\n",
      "Iteration 44, loss = 0.27841237\n",
      "Iteration 45, loss = 0.27774228\n",
      "Iteration 46, loss = 0.27270453\n",
      "Iteration 47, loss = 0.27118561\n",
      "Iteration 48, loss = 0.26137306\n",
      "Iteration 49, loss = 0.26092007\n",
      "Iteration 50, loss = 0.27584667\n",
      "Iteration 51, loss = 0.25908659\n",
      "Iteration 52, loss = 0.25707544\n",
      "Iteration 53, loss = 0.25990236\n",
      "Iteration 54, loss = 0.25998792\n",
      "Iteration 55, loss = 0.26775007\n",
      "Iteration 56, loss = 0.24995075\n",
      "Iteration 57, loss = 0.25081905\n",
      "Iteration 58, loss = 0.24938374\n",
      "Iteration 59, loss = 0.24638971\n",
      "Iteration 60, loss = 0.24586764\n",
      "Iteration 61, loss = 0.24285639\n",
      "Iteration 62, loss = 0.23612406\n",
      "Iteration 63, loss = 0.24365058\n",
      "Iteration 64, loss = 0.24095048\n",
      "Iteration 65, loss = 0.23905027\n",
      "Iteration 66, loss = 0.24043206\n",
      "Iteration 67, loss = 0.23326346\n",
      "Iteration 68, loss = 0.22891400\n",
      "Iteration 69, loss = 0.22633338\n",
      "Iteration 70, loss = 0.22787300\n",
      "Iteration 71, loss = 0.22979190\n",
      "Iteration 72, loss = 0.23041509\n",
      "Iteration 73, loss = 0.22110576\n",
      "Iteration 74, loss = 0.21734585\n",
      "Iteration 75, loss = 0.21545852\n",
      "Iteration 76, loss = 0.22058226\n",
      "Iteration 77, loss = 0.21578305\n",
      "Iteration 78, loss = 0.21645218\n",
      "Iteration 79, loss = 0.21123521\n",
      "Iteration 80, loss = 0.20624686\n",
      "Iteration 81, loss = 0.21492703\n",
      "Iteration 82, loss = 0.22352298\n",
      "Iteration 83, loss = 0.21032995\n",
      "Iteration 84, loss = 0.21627060\n",
      "Iteration 85, loss = 0.21434678\n",
      "Iteration 86, loss = 0.21539760\n",
      "Iteration 87, loss = 0.21181684\n",
      "Iteration 88, loss = 0.20643572\n",
      "Iteration 89, loss = 0.19938195\n",
      "Iteration 90, loss = 0.19676710\n",
      "Iteration 91, loss = 0.20599035\n",
      "Iteration 92, loss = 0.19995450\n",
      "Iteration 93, loss = 0.20996443\n",
      "Iteration 94, loss = 0.19660089\n",
      "Iteration 95, loss = 0.19420728\n",
      "Iteration 96, loss = 0.19191361\n",
      "Iteration 97, loss = 0.19267397\n",
      "Iteration 98, loss = 0.18637647\n",
      "Iteration 99, loss = 0.18669138\n",
      "Iteration 100, loss = 0.18730157\n",
      "Iteration 101, loss = 0.18288478\n",
      "Iteration 102, loss = 0.18392048\n",
      "Iteration 103, loss = 0.20675698\n",
      "Iteration 104, loss = 0.18508649\n",
      "Iteration 105, loss = 0.18879785\n",
      "Iteration 106, loss = 0.18416999\n",
      "Iteration 107, loss = 0.17923269\n",
      "Iteration 108, loss = 0.18033718\n",
      "Iteration 109, loss = 0.19807721\n",
      "Iteration 110, loss = 0.18039363\n",
      "Iteration 111, loss = 0.19529550\n",
      "Iteration 112, loss = 0.17902992\n",
      "Iteration 113, loss = 0.17504142\n",
      "Iteration 114, loss = 0.17511707\n",
      "Iteration 115, loss = 0.17362327\n",
      "Iteration 116, loss = 0.17875603\n",
      "Iteration 117, loss = 0.18178116\n",
      "Iteration 118, loss = 0.20621690\n",
      "Iteration 119, loss = 0.17809683\n",
      "Iteration 120, loss = 0.16601707\n",
      "Iteration 121, loss = 0.17104068\n",
      "Iteration 122, loss = 0.16432857\n",
      "Iteration 123, loss = 0.16850886\n",
      "Iteration 124, loss = 0.17775735\n",
      "Iteration 125, loss = 0.16284189\n",
      "Iteration 126, loss = 0.16365635\n",
      "Iteration 127, loss = 0.16463051\n",
      "Iteration 128, loss = 0.16115724\n",
      "Iteration 129, loss = 0.16215186\n",
      "Iteration 130, loss = 0.15557164\n",
      "Iteration 131, loss = 0.15954185\n",
      "Iteration 132, loss = 0.15753749\n",
      "Iteration 133, loss = 0.15292796\n",
      "Iteration 134, loss = 0.15456787\n",
      "Iteration 135, loss = 0.15860183\n",
      "Iteration 136, loss = 0.15320156\n",
      "Iteration 137, loss = 0.15677800\n",
      "Iteration 138, loss = 0.15640902\n",
      "Iteration 139, loss = 0.15330413\n",
      "Iteration 140, loss = 0.15565825\n",
      "Iteration 141, loss = 0.15237996\n",
      "Iteration 142, loss = 0.16121984\n",
      "Iteration 143, loss = 0.15117683\n",
      "Iteration 144, loss = 0.15238941\n",
      "Iteration 145, loss = 0.16026784\n",
      "Iteration 146, loss = 0.14535774\n",
      "Iteration 147, loss = 0.15409600\n",
      "Iteration 148, loss = 0.14668698\n",
      "Iteration 149, loss = 0.14434934\n",
      "Iteration 150, loss = 0.15236285\n",
      "Iteration 151, loss = 0.16698719\n",
      "Iteration 152, loss = 0.14750264\n",
      "Iteration 153, loss = 0.13914423\n",
      "Iteration 154, loss = 0.14193381\n",
      "Iteration 155, loss = 0.14812131\n",
      "Iteration 156, loss = 0.14693773\n",
      "Iteration 157, loss = 0.14599463\n",
      "Iteration 158, loss = 0.13939173\n",
      "Iteration 159, loss = 0.13603456\n",
      "Iteration 160, loss = 0.13726479\n",
      "Iteration 161, loss = 0.13026184\n",
      "Iteration 162, loss = 0.14162898\n",
      "Iteration 163, loss = 0.14475597\n",
      "Iteration 164, loss = 0.14191640\n",
      "Iteration 165, loss = 0.13653607\n",
      "Iteration 166, loss = 0.13694762\n",
      "Iteration 167, loss = 0.13371519\n",
      "Iteration 168, loss = 0.12959403\n",
      "Iteration 169, loss = 0.13273783\n",
      "Iteration 170, loss = 0.13213775\n",
      "Iteration 171, loss = 0.13402700\n",
      "Iteration 172, loss = 0.12532913\n",
      "Iteration 173, loss = 0.13196320\n",
      "Iteration 174, loss = 0.13554955\n",
      "Iteration 175, loss = 0.12828110\n",
      "Iteration 176, loss = 0.12217603\n",
      "Iteration 177, loss = 0.12398424\n",
      "Iteration 178, loss = 0.13103173\n",
      "Iteration 179, loss = 0.12549346\n",
      "Iteration 180, loss = 0.12369931\n",
      "Iteration 181, loss = 0.13801237\n",
      "Iteration 182, loss = 0.12945411\n",
      "Iteration 183, loss = 0.14017684\n",
      "Iteration 184, loss = 0.12378974\n",
      "Iteration 185, loss = 0.12070896\n",
      "Iteration 186, loss = 0.12366842\n",
      "Iteration 187, loss = 0.12042106\n",
      "Iteration 188, loss = 0.12073210\n",
      "Iteration 189, loss = 0.11709705\n",
      "Iteration 190, loss = 0.12129338\n",
      "Iteration 191, loss = 0.12440515\n",
      "Iteration 192, loss = 0.11754463\n",
      "Iteration 193, loss = 0.12421053\n",
      "Iteration 194, loss = 0.12197479\n",
      "Iteration 195, loss = 0.11959387\n",
      "Iteration 196, loss = 0.11844876\n",
      "Iteration 197, loss = 0.11990091\n",
      "Iteration 198, loss = 0.13099521\n",
      "Iteration 199, loss = 0.11758550\n",
      "Iteration 200, loss = 0.11312475\n",
      "Iteration 201, loss = 0.11065942\n",
      "Iteration 202, loss = 0.13340318\n",
      "Iteration 203, loss = 0.11349720\n",
      "Iteration 204, loss = 0.11177373\n",
      "Iteration 205, loss = 0.11118261\n",
      "Iteration 206, loss = 0.11043951\n",
      "Iteration 207, loss = 0.10996244\n",
      "Iteration 208, loss = 0.10472078\n",
      "Iteration 209, loss = 0.10346849\n",
      "Iteration 210, loss = 0.10472000\n",
      "Iteration 211, loss = 0.10806726\n",
      "Iteration 212, loss = 0.11314586\n",
      "Iteration 213, loss = 0.10627385\n",
      "Iteration 214, loss = 0.09925278\n",
      "Iteration 215, loss = 0.10066269\n",
      "Iteration 216, loss = 0.10516252\n",
      "Iteration 217, loss = 0.11441414\n",
      "Iteration 218, loss = 0.10892007\n",
      "Iteration 219, loss = 0.10604975\n",
      "Iteration 220, loss = 0.11575623\n",
      "Iteration 221, loss = 0.10774790\n",
      "Iteration 222, loss = 0.11073396\n",
      "Iteration 223, loss = 0.09421876\n",
      "Iteration 224, loss = 0.09978963\n",
      "Iteration 225, loss = 0.10598323\n",
      "Iteration 226, loss = 0.11536707\n",
      "Iteration 227, loss = 0.11096925\n",
      "Iteration 228, loss = 0.10310757\n",
      "Iteration 229, loss = 0.10095767\n",
      "Iteration 230, loss = 0.10240136\n",
      "Iteration 231, loss = 0.10173286\n",
      "Iteration 232, loss = 0.09546763\n",
      "Iteration 233, loss = 0.10816126\n",
      "Iteration 234, loss = 0.09406487\n",
      "Iteration 235, loss = 0.09445522\n",
      "Iteration 236, loss = 0.10422846\n",
      "Iteration 237, loss = 0.10087643\n",
      "Iteration 238, loss = 0.11006804\n",
      "Iteration 239, loss = 0.12864281\n",
      "Iteration 240, loss = 0.09885555\n",
      "Iteration 241, loss = 0.10418501\n",
      "Iteration 242, loss = 0.09337624\n",
      "Iteration 243, loss = 0.09124142\n",
      "Iteration 244, loss = 0.09096760\n",
      "Iteration 245, loss = 0.10114385\n",
      "Iteration 246, loss = 0.09097362\n",
      "Iteration 247, loss = 0.09280668\n",
      "Iteration 248, loss = 0.09137819\n",
      "Iteration 249, loss = 0.09943534\n",
      "Iteration 250, loss = 0.09463581\n",
      "Iteration 251, loss = 0.09079589\n",
      "Iteration 252, loss = 0.08963564\n",
      "Iteration 253, loss = 0.09647953\n",
      "Iteration 254, loss = 0.08915165\n",
      "Iteration 255, loss = 0.10529141\n",
      "Iteration 256, loss = 0.10030620\n",
      "Iteration 257, loss = 0.09515376\n",
      "Iteration 258, loss = 0.08654742\n",
      "Iteration 259, loss = 0.08328002\n",
      "Iteration 260, loss = 0.08310149\n",
      "Iteration 261, loss = 0.09060402\n",
      "Iteration 262, loss = 0.08610163\n",
      "Iteration 263, loss = 0.08820597\n",
      "Iteration 264, loss = 0.09045103\n",
      "Iteration 265, loss = 0.09018174\n",
      "Iteration 266, loss = 0.09502021\n",
      "Iteration 267, loss = 0.08558374\n",
      "Iteration 268, loss = 0.08867097\n",
      "Iteration 269, loss = 0.09815117\n",
      "Iteration 270, loss = 0.08670817\n",
      "Iteration 271, loss = 0.09785812\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy:  0.8592265193370165\n",
      "Train  1\n",
      "Iteration 1, loss = 0.67744796\n",
      "Iteration 2, loss = 0.62839682\n",
      "Iteration 3, loss = 0.58027216\n",
      "Iteration 4, loss = 0.53997960\n",
      "Iteration 5, loss = 0.50989713\n",
      "Iteration 6, loss = 0.48724719\n",
      "Iteration 7, loss = 0.46372959\n",
      "Iteration 8, loss = 0.44719388\n",
      "Iteration 9, loss = 0.43171192\n",
      "Iteration 10, loss = 0.43487636\n",
      "Iteration 11, loss = 0.41685381\n",
      "Iteration 12, loss = 0.40102285\n",
      "Iteration 13, loss = 0.38969891\n",
      "Iteration 14, loss = 0.38299935\n",
      "Iteration 15, loss = 0.37555420\n",
      "Iteration 16, loss = 0.37238897\n",
      "Iteration 17, loss = 0.36416605\n",
      "Iteration 18, loss = 0.35462376\n",
      "Iteration 19, loss = 0.34870498\n",
      "Iteration 20, loss = 0.34908494\n",
      "Iteration 21, loss = 0.33889064\n",
      "Iteration 22, loss = 0.33830508\n",
      "Iteration 23, loss = 0.34329072\n",
      "Iteration 24, loss = 0.32095200\n",
      "Iteration 25, loss = 0.33220658\n",
      "Iteration 26, loss = 0.31783056\n",
      "Iteration 27, loss = 0.33643550\n",
      "Iteration 28, loss = 0.33648328\n",
      "Iteration 29, loss = 0.32244827\n",
      "Iteration 30, loss = 0.31844579\n",
      "Iteration 31, loss = 0.30014908\n",
      "Iteration 32, loss = 0.29777912\n",
      "Iteration 33, loss = 0.29552880\n",
      "Iteration 34, loss = 0.29750631\n",
      "Iteration 35, loss = 0.31362942\n",
      "Iteration 36, loss = 0.30472352\n",
      "Iteration 37, loss = 0.28486910\n",
      "Iteration 38, loss = 0.28121325\n",
      "Iteration 39, loss = 0.28267497\n",
      "Iteration 40, loss = 0.28103089\n",
      "Iteration 41, loss = 0.27579961\n",
      "Iteration 42, loss = 0.27683140\n",
      "Iteration 43, loss = 0.27774550\n",
      "Iteration 44, loss = 0.27656312\n",
      "Iteration 45, loss = 0.28747398\n",
      "Iteration 46, loss = 0.27163813\n",
      "Iteration 47, loss = 0.27138819\n",
      "Iteration 48, loss = 0.26755872\n",
      "Iteration 49, loss = 0.25866637\n",
      "Iteration 50, loss = 0.25559609\n",
      "Iteration 51, loss = 0.25230319\n",
      "Iteration 52, loss = 0.25555969\n",
      "Iteration 53, loss = 0.24471712\n",
      "Iteration 54, loss = 0.25261834\n",
      "Iteration 55, loss = 0.25333764\n",
      "Iteration 56, loss = 0.24964890\n",
      "Iteration 57, loss = 0.24160717\n",
      "Iteration 58, loss = 0.24966882\n",
      "Iteration 59, loss = 0.25764170\n",
      "Iteration 60, loss = 0.23835058\n",
      "Iteration 61, loss = 0.23633006\n",
      "Iteration 62, loss = 0.23721992\n",
      "Iteration 63, loss = 0.24598434\n",
      "Iteration 64, loss = 0.24224769\n",
      "Iteration 65, loss = 0.23240662\n",
      "Iteration 66, loss = 0.22691249\n",
      "Iteration 67, loss = 0.23273407\n",
      "Iteration 68, loss = 0.23624911\n",
      "Iteration 69, loss = 0.22580949\n",
      "Iteration 70, loss = 0.22467026\n",
      "Iteration 71, loss = 0.21857296\n",
      "Iteration 72, loss = 0.22110069\n",
      "Iteration 73, loss = 0.23185684\n",
      "Iteration 74, loss = 0.22833563\n",
      "Iteration 75, loss = 0.21935294\n",
      "Iteration 76, loss = 0.21337084\n",
      "Iteration 77, loss = 0.21913975\n",
      "Iteration 78, loss = 0.21629522\n",
      "Iteration 79, loss = 0.21124717\n",
      "Iteration 80, loss = 0.21368226\n",
      "Iteration 81, loss = 0.21738337\n",
      "Iteration 82, loss = 0.21039159\n",
      "Iteration 83, loss = 0.20822405\n",
      "Iteration 84, loss = 0.20351001\n",
      "Iteration 85, loss = 0.23429929\n",
      "Iteration 86, loss = 0.20184553\n",
      "Iteration 87, loss = 0.21238760\n",
      "Iteration 88, loss = 0.19663249\n",
      "Iteration 89, loss = 0.19860384\n",
      "Iteration 90, loss = 0.19945518\n",
      "Iteration 91, loss = 0.20011300\n",
      "Iteration 92, loss = 0.19696974\n",
      "Iteration 93, loss = 0.19172965\n",
      "Iteration 94, loss = 0.19357472\n",
      "Iteration 95, loss = 0.19057738\n",
      "Iteration 96, loss = 0.19030690\n",
      "Iteration 97, loss = 0.19029208\n",
      "Iteration 98, loss = 0.19368418\n",
      "Iteration 99, loss = 0.19631713\n",
      "Iteration 100, loss = 0.19025005\n",
      "Iteration 101, loss = 0.19070257\n",
      "Iteration 102, loss = 0.19191114\n",
      "Iteration 103, loss = 0.17928332\n",
      "Iteration 104, loss = 0.17948270\n",
      "Iteration 105, loss = 0.17928302\n",
      "Iteration 106, loss = 0.17673428\n",
      "Iteration 107, loss = 0.17947510\n",
      "Iteration 108, loss = 0.17573297\n",
      "Iteration 109, loss = 0.17690019\n",
      "Iteration 110, loss = 0.17130890\n",
      "Iteration 111, loss = 0.18297272\n",
      "Iteration 112, loss = 0.18803796\n",
      "Iteration 113, loss = 0.17946235\n",
      "Iteration 114, loss = 0.17628509\n",
      "Iteration 115, loss = 0.16980077\n",
      "Iteration 116, loss = 0.17720969\n",
      "Iteration 117, loss = 0.17781360\n",
      "Iteration 118, loss = 0.17710777\n",
      "Iteration 119, loss = 0.16521465\n",
      "Iteration 120, loss = 0.16955090\n",
      "Iteration 121, loss = 0.16783195\n",
      "Iteration 122, loss = 0.17591689\n",
      "Iteration 123, loss = 0.20269647\n",
      "Iteration 124, loss = 0.17686900\n",
      "Iteration 125, loss = 0.17171680\n",
      "Iteration 126, loss = 0.16036346\n",
      "Iteration 127, loss = 0.16219997\n",
      "Iteration 128, loss = 0.15974971\n",
      "Iteration 129, loss = 0.16019456\n",
      "Iteration 130, loss = 0.15705718\n",
      "Iteration 131, loss = 0.16347618\n",
      "Iteration 132, loss = 0.15428920\n",
      "Iteration 133, loss = 0.15443497\n",
      "Iteration 134, loss = 0.15760195\n",
      "Iteration 135, loss = 0.15580845\n",
      "Iteration 136, loss = 0.15109847\n",
      "Iteration 137, loss = 0.15760359\n",
      "Iteration 138, loss = 0.15182155\n",
      "Iteration 139, loss = 0.16368242\n",
      "Iteration 140, loss = 0.16288109\n",
      "Iteration 141, loss = 0.14894296\n",
      "Iteration 142, loss = 0.15593476\n",
      "Iteration 143, loss = 0.14537047\n",
      "Iteration 144, loss = 0.14626665\n",
      "Iteration 145, loss = 0.14941914\n",
      "Iteration 146, loss = 0.16064460\n",
      "Iteration 147, loss = 0.16603233\n",
      "Iteration 148, loss = 0.17872294\n",
      "Iteration 149, loss = 0.14888518\n",
      "Iteration 150, loss = 0.14743837\n",
      "Iteration 151, loss = 0.17039454\n",
      "Iteration 152, loss = 0.14651889\n",
      "Iteration 153, loss = 0.14311714\n",
      "Iteration 154, loss = 0.14561537\n",
      "Iteration 155, loss = 0.14623460\n",
      "Iteration 156, loss = 0.14178879\n",
      "Iteration 157, loss = 0.14925569\n",
      "Iteration 158, loss = 0.13546938\n",
      "Iteration 159, loss = 0.13544616\n",
      "Iteration 160, loss = 0.14463122\n",
      "Iteration 161, loss = 0.14520508\n",
      "Iteration 162, loss = 0.13862673\n",
      "Iteration 163, loss = 0.13931982\n",
      "Iteration 164, loss = 0.13975454\n",
      "Iteration 165, loss = 0.14207386\n",
      "Iteration 166, loss = 0.13511663\n",
      "Iteration 167, loss = 0.13852247\n",
      "Iteration 168, loss = 0.13462288\n",
      "Iteration 169, loss = 0.15629351\n",
      "Iteration 170, loss = 0.14096550\n",
      "Iteration 171, loss = 0.13825994\n",
      "Iteration 172, loss = 0.12961843\n",
      "Iteration 173, loss = 0.13260556\n",
      "Iteration 174, loss = 0.14057068\n",
      "Iteration 175, loss = 0.13124771\n",
      "Iteration 176, loss = 0.12705370\n",
      "Iteration 177, loss = 0.12314432\n",
      "Iteration 178, loss = 0.15849442\n",
      "Iteration 179, loss = 0.13840221\n",
      "Iteration 180, loss = 0.12624096\n",
      "Iteration 181, loss = 0.13221141\n",
      "Iteration 182, loss = 0.13197841\n",
      "Iteration 183, loss = 0.12899640\n",
      "Iteration 184, loss = 0.13207455\n",
      "Iteration 185, loss = 0.12740405\n",
      "Iteration 186, loss = 0.12290802\n",
      "Iteration 187, loss = 0.12053685\n",
      "Iteration 188, loss = 0.12652448\n",
      "Iteration 189, loss = 0.12632947\n",
      "Iteration 190, loss = 0.13186326\n",
      "Iteration 191, loss = 0.13117544\n",
      "Iteration 192, loss = 0.13224974\n",
      "Iteration 193, loss = 0.12285410\n",
      "Iteration 194, loss = 0.12107259\n",
      "Iteration 195, loss = 0.12195403\n",
      "Iteration 196, loss = 0.11760324\n",
      "Iteration 197, loss = 0.12211875\n",
      "Iteration 198, loss = 0.12200805\n",
      "Iteration 199, loss = 0.12712618\n",
      "Iteration 200, loss = 0.12668863\n",
      "Iteration 201, loss = 0.11946275\n",
      "Iteration 202, loss = 0.12694150\n",
      "Iteration 203, loss = 0.12110431\n",
      "Iteration 204, loss = 0.11906277\n",
      "Iteration 205, loss = 0.12780063\n",
      "Iteration 206, loss = 0.13092980\n",
      "Iteration 207, loss = 0.13289110\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy:  0.8574585635359117\n",
      "Train  2\n",
      "Iteration 1, loss = 0.66920906\n",
      "Iteration 2, loss = 0.61035116\n",
      "Iteration 3, loss = 0.56148747\n",
      "Iteration 4, loss = 0.52512879\n",
      "Iteration 5, loss = 0.49178987\n",
      "Iteration 6, loss = 0.47388956\n",
      "Iteration 7, loss = 0.44482659\n",
      "Iteration 8, loss = 0.43207546\n",
      "Iteration 9, loss = 0.42240446\n",
      "Iteration 10, loss = 0.40881702\n",
      "Iteration 11, loss = 0.40624838\n",
      "Iteration 12, loss = 0.38894561\n",
      "Iteration 13, loss = 0.38487669\n",
      "Iteration 14, loss = 0.37560470\n",
      "Iteration 15, loss = 0.36331894\n",
      "Iteration 16, loss = 0.35713432\n",
      "Iteration 17, loss = 0.34748441\n",
      "Iteration 18, loss = 0.35628789\n",
      "Iteration 19, loss = 0.34468761\n",
      "Iteration 20, loss = 0.33916516\n",
      "Iteration 21, loss = 0.33879504\n",
      "Iteration 22, loss = 0.33771998\n",
      "Iteration 23, loss = 0.32974383\n",
      "Iteration 24, loss = 0.32646776\n",
      "Iteration 25, loss = 0.32190010\n",
      "Iteration 26, loss = 0.30889871\n",
      "Iteration 27, loss = 0.31518615\n",
      "Iteration 28, loss = 0.30389349\n",
      "Iteration 29, loss = 0.31516498\n",
      "Iteration 30, loss = 0.30588362\n",
      "Iteration 31, loss = 0.30798707\n",
      "Iteration 32, loss = 0.29375299\n",
      "Iteration 33, loss = 0.28976067\n",
      "Iteration 34, loss = 0.29118698\n",
      "Iteration 35, loss = 0.29001140\n",
      "Iteration 36, loss = 0.28934069\n",
      "Iteration 37, loss = 0.28049364\n",
      "Iteration 38, loss = 0.28404782\n",
      "Iteration 39, loss = 0.28168175\n",
      "Iteration 40, loss = 0.27762340\n",
      "Iteration 41, loss = 0.27401680\n",
      "Iteration 42, loss = 0.27220297\n",
      "Iteration 43, loss = 0.27241373\n",
      "Iteration 44, loss = 0.28109891\n",
      "Iteration 45, loss = 0.27398178\n",
      "Iteration 46, loss = 0.26233765\n",
      "Iteration 47, loss = 0.26179140\n",
      "Iteration 48, loss = 0.26524309\n",
      "Iteration 49, loss = 0.26016286\n",
      "Iteration 50, loss = 0.26580409\n",
      "Iteration 51, loss = 0.25706351\n",
      "Iteration 52, loss = 0.24634622\n",
      "Iteration 53, loss = 0.25660070\n",
      "Iteration 54, loss = 0.26611598\n",
      "Iteration 55, loss = 0.25167990\n",
      "Iteration 56, loss = 0.24740809\n",
      "Iteration 57, loss = 0.25109366\n",
      "Iteration 58, loss = 0.24178324\n",
      "Iteration 59, loss = 0.24074156\n",
      "Iteration 60, loss = 0.23600421\n",
      "Iteration 61, loss = 0.23437984\n",
      "Iteration 62, loss = 0.24903715\n",
      "Iteration 63, loss = 0.23572670\n",
      "Iteration 64, loss = 0.22856984\n",
      "Iteration 65, loss = 0.24038217\n",
      "Iteration 66, loss = 0.22688600\n",
      "Iteration 67, loss = 0.23197452\n",
      "Iteration 68, loss = 0.22496177\n",
      "Iteration 69, loss = 0.23182657\n",
      "Iteration 70, loss = 0.21866724\n",
      "Iteration 71, loss = 0.22507949\n",
      "Iteration 72, loss = 0.21778447\n",
      "Iteration 73, loss = 0.21401660\n",
      "Iteration 74, loss = 0.21668810\n",
      "Iteration 75, loss = 0.20740671\n",
      "Iteration 76, loss = 0.20976758\n",
      "Iteration 77, loss = 0.21266306\n",
      "Iteration 78, loss = 0.21515637\n",
      "Iteration 79, loss = 0.20699517\n",
      "Iteration 80, loss = 0.20333360\n",
      "Iteration 81, loss = 0.19769830\n",
      "Iteration 82, loss = 0.20668522\n",
      "Iteration 83, loss = 0.20328323\n",
      "Iteration 84, loss = 0.20280822\n",
      "Iteration 85, loss = 0.20494500\n",
      "Iteration 86, loss = 0.19570488\n",
      "Iteration 87, loss = 0.20396819\n",
      "Iteration 88, loss = 0.18959863\n",
      "Iteration 89, loss = 0.19676899\n",
      "Iteration 90, loss = 0.20100418\n",
      "Iteration 91, loss = 0.19520066\n",
      "Iteration 92, loss = 0.19601351\n",
      "Iteration 93, loss = 0.18837214\n",
      "Iteration 94, loss = 0.19412028\n",
      "Iteration 95, loss = 0.18532895\n",
      "Iteration 96, loss = 0.18200506\n",
      "Iteration 97, loss = 0.17684508\n",
      "Iteration 98, loss = 0.18316179\n",
      "Iteration 99, loss = 0.17931898\n",
      "Iteration 100, loss = 0.17891600\n",
      "Iteration 101, loss = 0.17306382\n",
      "Iteration 102, loss = 0.17117144\n",
      "Iteration 103, loss = 0.17556965\n",
      "Iteration 104, loss = 0.17058794\n",
      "Iteration 105, loss = 0.17481964\n",
      "Iteration 106, loss = 0.17956549\n",
      "Iteration 107, loss = 0.16484765\n",
      "Iteration 108, loss = 0.16617152\n",
      "Iteration 109, loss = 0.17165446\n",
      "Iteration 110, loss = 0.17010155\n",
      "Iteration 111, loss = 0.16814277\n",
      "Iteration 112, loss = 0.16703043\n",
      "Iteration 113, loss = 0.17366957\n",
      "Iteration 114, loss = 0.17191039\n",
      "Iteration 115, loss = 0.17479692\n",
      "Iteration 116, loss = 0.16285182\n",
      "Iteration 117, loss = 0.16322085\n",
      "Iteration 118, loss = 0.15781678\n",
      "Iteration 119, loss = 0.16773677\n",
      "Iteration 120, loss = 0.16110942\n",
      "Iteration 121, loss = 0.16182350\n",
      "Iteration 122, loss = 0.15968318\n",
      "Iteration 123, loss = 0.16009701\n",
      "Iteration 124, loss = 0.15663578\n",
      "Iteration 125, loss = 0.15584520\n",
      "Iteration 126, loss = 0.15607253\n",
      "Iteration 127, loss = 0.15344112\n",
      "Iteration 128, loss = 0.17528445\n",
      "Iteration 129, loss = 0.15406201\n",
      "Iteration 130, loss = 0.15694383\n",
      "Iteration 131, loss = 0.15070753\n",
      "Iteration 132, loss = 0.14371100\n",
      "Iteration 133, loss = 0.14411760\n",
      "Iteration 134, loss = 0.14692782\n",
      "Iteration 135, loss = 0.14166787\n",
      "Iteration 136, loss = 0.14200103\n",
      "Iteration 137, loss = 0.14091846\n",
      "Iteration 138, loss = 0.14612258\n",
      "Iteration 139, loss = 0.14006179\n",
      "Iteration 140, loss = 0.13755589\n",
      "Iteration 141, loss = 0.13599417\n",
      "Iteration 142, loss = 0.14091150\n",
      "Iteration 143, loss = 0.14206720\n",
      "Iteration 144, loss = 0.14946767\n",
      "Iteration 145, loss = 0.14337490\n",
      "Iteration 146, loss = 0.15156951\n",
      "Iteration 147, loss = 0.13927185\n",
      "Iteration 148, loss = 0.14658839\n",
      "Iteration 149, loss = 0.13510347\n",
      "Iteration 150, loss = 0.12961041\n",
      "Iteration 151, loss = 0.13656618\n",
      "Iteration 152, loss = 0.14427973\n",
      "Iteration 153, loss = 0.13880600\n",
      "Iteration 154, loss = 0.13093554\n",
      "Iteration 155, loss = 0.13962307\n",
      "Iteration 156, loss = 0.13052118\n",
      "Iteration 157, loss = 0.12710147\n",
      "Iteration 158, loss = 0.12890771\n",
      "Iteration 159, loss = 0.12657494\n",
      "Iteration 160, loss = 0.13379118\n",
      "Iteration 161, loss = 0.12968576\n",
      "Iteration 162, loss = 0.13562663\n",
      "Iteration 163, loss = 0.13805076\n",
      "Iteration 164, loss = 0.13418003\n",
      "Iteration 165, loss = 0.13553296\n",
      "Iteration 166, loss = 0.14381537\n",
      "Iteration 167, loss = 0.13976250\n",
      "Iteration 168, loss = 0.13117149\n",
      "Iteration 169, loss = 0.12826969\n",
      "Iteration 170, loss = 0.13211715\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy:  0.8833149171270718\n",
      "Train  3\n",
      "Iteration 1, loss = 0.66402275\n",
      "Iteration 2, loss = 0.60577047\n",
      "Iteration 3, loss = 0.55599648\n",
      "Iteration 4, loss = 0.51925813\n",
      "Iteration 5, loss = 0.48993862\n",
      "Iteration 6, loss = 0.47473856\n",
      "Iteration 7, loss = 0.46256368\n",
      "Iteration 8, loss = 0.44002358\n",
      "Iteration 9, loss = 0.42983934\n",
      "Iteration 10, loss = 0.41497319\n",
      "Iteration 11, loss = 0.40852235\n",
      "Iteration 12, loss = 0.40666202\n",
      "Iteration 13, loss = 0.41608384\n",
      "Iteration 14, loss = 0.38919852\n",
      "Iteration 15, loss = 0.37640927\n",
      "Iteration 16, loss = 0.36673022\n",
      "Iteration 17, loss = 0.36130777\n",
      "Iteration 18, loss = 0.36404572\n",
      "Iteration 19, loss = 0.35441731\n",
      "Iteration 20, loss = 0.34539005\n",
      "Iteration 21, loss = 0.33572973\n",
      "Iteration 22, loss = 0.33643162\n",
      "Iteration 23, loss = 0.33210927\n",
      "Iteration 24, loss = 0.33084087\n",
      "Iteration 25, loss = 0.32191060\n",
      "Iteration 26, loss = 0.32313129\n",
      "Iteration 27, loss = 0.31820919\n",
      "Iteration 28, loss = 0.31634014\n",
      "Iteration 29, loss = 0.30376010\n",
      "Iteration 30, loss = 0.30450252\n",
      "Iteration 31, loss = 0.31748218\n",
      "Iteration 32, loss = 0.30926464\n",
      "Iteration 33, loss = 0.29570100\n",
      "Iteration 34, loss = 0.30526220\n",
      "Iteration 35, loss = 0.29523424\n",
      "Iteration 36, loss = 0.29833262\n",
      "Iteration 37, loss = 0.30058070\n",
      "Iteration 38, loss = 0.29303111\n",
      "Iteration 39, loss = 0.28376171\n",
      "Iteration 40, loss = 0.30520812\n",
      "Iteration 41, loss = 0.28726275\n",
      "Iteration 42, loss = 0.27262191\n",
      "Iteration 43, loss = 0.26977128\n",
      "Iteration 44, loss = 0.27303022\n",
      "Iteration 45, loss = 0.27256723\n",
      "Iteration 46, loss = 0.27802611\n",
      "Iteration 47, loss = 0.27061070\n",
      "Iteration 48, loss = 0.26970072\n",
      "Iteration 49, loss = 0.27305969\n",
      "Iteration 50, loss = 0.26184689\n",
      "Iteration 51, loss = 0.26603475\n",
      "Iteration 52, loss = 0.25970126\n",
      "Iteration 53, loss = 0.25739103\n",
      "Iteration 54, loss = 0.25673254\n",
      "Iteration 55, loss = 0.25317900\n",
      "Iteration 56, loss = 0.25660144\n",
      "Iteration 57, loss = 0.25425083\n",
      "Iteration 58, loss = 0.24611979\n",
      "Iteration 59, loss = 0.24510818\n",
      "Iteration 60, loss = 0.24596845\n",
      "Iteration 61, loss = 0.24476986\n",
      "Iteration 62, loss = 0.24141977\n",
      "Iteration 63, loss = 0.23974078\n",
      "Iteration 64, loss = 0.23725468\n",
      "Iteration 65, loss = 0.27999854\n",
      "Iteration 66, loss = 0.25549173\n",
      "Iteration 67, loss = 0.23569410\n",
      "Iteration 68, loss = 0.23192582\n",
      "Iteration 69, loss = 0.24291362\n",
      "Iteration 70, loss = 0.23225950\n",
      "Iteration 71, loss = 0.22925108\n",
      "Iteration 72, loss = 0.23537729\n",
      "Iteration 73, loss = 0.22295051\n",
      "Iteration 74, loss = 0.22942607\n",
      "Iteration 75, loss = 0.21803611\n",
      "Iteration 76, loss = 0.22433352\n",
      "Iteration 77, loss = 0.22838407\n",
      "Iteration 78, loss = 0.21858418\n",
      "Iteration 79, loss = 0.22481075\n",
      "Iteration 80, loss = 0.21647314\n",
      "Iteration 81, loss = 0.21159678\n",
      "Iteration 82, loss = 0.23273881\n",
      "Iteration 83, loss = 0.22100043\n",
      "Iteration 84, loss = 0.21020389\n",
      "Iteration 85, loss = 0.21276850\n",
      "Iteration 86, loss = 0.20752883\n",
      "Iteration 87, loss = 0.20842716\n",
      "Iteration 88, loss = 0.20835975\n",
      "Iteration 89, loss = 0.19910341\n",
      "Iteration 90, loss = 0.19808998\n",
      "Iteration 91, loss = 0.20590240\n",
      "Iteration 92, loss = 0.20131755\n",
      "Iteration 93, loss = 0.20674735\n",
      "Iteration 94, loss = 0.20086516\n",
      "Iteration 95, loss = 0.19282546\n",
      "Iteration 96, loss = 0.19153513\n",
      "Iteration 97, loss = 0.20871669\n",
      "Iteration 98, loss = 0.20627266\n",
      "Iteration 99, loss = 0.20014535\n",
      "Iteration 100, loss = 0.18857701\n",
      "Iteration 101, loss = 0.19768975\n",
      "Iteration 102, loss = 0.20018444\n",
      "Iteration 103, loss = 0.18417232\n",
      "Iteration 104, loss = 0.18929950\n",
      "Iteration 105, loss = 0.18053817\n",
      "Iteration 106, loss = 0.17984204\n",
      "Iteration 107, loss = 0.18241229\n",
      "Iteration 108, loss = 0.18324596\n",
      "Iteration 109, loss = 0.18758680\n",
      "Iteration 110, loss = 0.19619783\n",
      "Iteration 111, loss = 0.18244621\n",
      "Iteration 112, loss = 0.17400164\n",
      "Iteration 113, loss = 0.19148753\n",
      "Iteration 114, loss = 0.18953497\n",
      "Iteration 115, loss = 0.17290693\n",
      "Iteration 116, loss = 0.16591176\n",
      "Iteration 117, loss = 0.17066958\n",
      "Iteration 118, loss = 0.17965624\n",
      "Iteration 119, loss = 0.18308208\n",
      "Iteration 120, loss = 0.17084662\n",
      "Iteration 121, loss = 0.16916730\n",
      "Iteration 122, loss = 0.17392775\n",
      "Iteration 123, loss = 0.16967632\n",
      "Iteration 124, loss = 0.16277999\n",
      "Iteration 125, loss = 0.16791049\n",
      "Iteration 126, loss = 0.16586028\n",
      "Iteration 127, loss = 0.16342240\n",
      "Iteration 128, loss = 0.16468608\n",
      "Iteration 129, loss = 0.16941086\n",
      "Iteration 130, loss = 0.15833912\n",
      "Iteration 131, loss = 0.16472488\n",
      "Iteration 132, loss = 0.17197980\n",
      "Iteration 133, loss = 0.16191422\n",
      "Iteration 134, loss = 0.15332831\n",
      "Iteration 135, loss = 0.15190851\n",
      "Iteration 136, loss = 0.15217519\n",
      "Iteration 137, loss = 0.15536418\n",
      "Iteration 138, loss = 0.15727322\n",
      "Iteration 139, loss = 0.15898769\n",
      "Iteration 140, loss = 0.16316661\n",
      "Iteration 141, loss = 0.17441430\n",
      "Iteration 142, loss = 0.16627345\n",
      "Iteration 143, loss = 0.15919780\n",
      "Iteration 144, loss = 0.15274317\n",
      "Iteration 145, loss = 0.15206704\n",
      "Iteration 146, loss = 0.14660140\n",
      "Iteration 147, loss = 0.16344235\n",
      "Iteration 148, loss = 0.14721018\n",
      "Iteration 149, loss = 0.14665787\n",
      "Iteration 150, loss = 0.14444178\n",
      "Iteration 151, loss = 0.15996840\n",
      "Iteration 152, loss = 0.15360159\n",
      "Iteration 153, loss = 0.14252211\n",
      "Iteration 154, loss = 0.13783430\n",
      "Iteration 155, loss = 0.14381529\n",
      "Iteration 156, loss = 0.14470973\n",
      "Iteration 157, loss = 0.14368607\n",
      "Iteration 158, loss = 0.14812507\n",
      "Iteration 159, loss = 0.14554846\n",
      "Iteration 160, loss = 0.13514475\n",
      "Iteration 161, loss = 0.15070489\n",
      "Iteration 162, loss = 0.16221665\n",
      "Iteration 163, loss = 0.14100349\n",
      "Iteration 164, loss = 0.13977201\n",
      "Iteration 165, loss = 0.13371764\n",
      "Iteration 166, loss = 0.14427052\n",
      "Iteration 167, loss = 0.13544558\n",
      "Iteration 168, loss = 0.12862219\n",
      "Iteration 169, loss = 0.13211380\n",
      "Iteration 170, loss = 0.14592120\n",
      "Iteration 171, loss = 0.14098752\n",
      "Iteration 172, loss = 0.14126260\n",
      "Iteration 173, loss = 0.12529798\n",
      "Iteration 174, loss = 0.13430985\n",
      "Iteration 175, loss = 0.12225799\n",
      "Iteration 176, loss = 0.13650666\n",
      "Iteration 177, loss = 0.14373289\n",
      "Iteration 178, loss = 0.12755636\n",
      "Iteration 179, loss = 0.12642849\n",
      "Iteration 180, loss = 0.14371368\n",
      "Iteration 181, loss = 0.12825523\n",
      "Iteration 182, loss = 0.12704414\n",
      "Iteration 183, loss = 0.13062475\n",
      "Iteration 184, loss = 0.12430730\n",
      "Iteration 185, loss = 0.12600485\n",
      "Iteration 186, loss = 0.14047687\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy:  0.882475138121547\n",
      "Train  4\n",
      "Iteration 1, loss = 0.66777660\n",
      "Iteration 2, loss = 0.61525384\n",
      "Iteration 3, loss = 0.56032974\n",
      "Iteration 4, loss = 0.52281412\n",
      "Iteration 5, loss = 0.50455051\n",
      "Iteration 6, loss = 0.47038330\n",
      "Iteration 7, loss = 0.45472711\n",
      "Iteration 8, loss = 0.44111108\n",
      "Iteration 9, loss = 0.42652298\n",
      "Iteration 10, loss = 0.41837190\n",
      "Iteration 11, loss = 0.40481115\n",
      "Iteration 12, loss = 0.39555143\n",
      "Iteration 13, loss = 0.38692603\n",
      "Iteration 14, loss = 0.39158762\n",
      "Iteration 15, loss = 0.37428568\n",
      "Iteration 16, loss = 0.37039973\n",
      "Iteration 17, loss = 0.36217323\n",
      "Iteration 18, loss = 0.35482854\n",
      "Iteration 19, loss = 0.35532918\n",
      "Iteration 20, loss = 0.34965163\n",
      "Iteration 21, loss = 0.33863382\n",
      "Iteration 22, loss = 0.34965647\n",
      "Iteration 23, loss = 0.33584274\n",
      "Iteration 24, loss = 0.34580061\n",
      "Iteration 25, loss = 0.33064102\n",
      "Iteration 26, loss = 0.33170580\n",
      "Iteration 27, loss = 0.32782541\n",
      "Iteration 28, loss = 0.31919838\n",
      "Iteration 29, loss = 0.31270717\n",
      "Iteration 30, loss = 0.31766931\n",
      "Iteration 31, loss = 0.31297047\n",
      "Iteration 32, loss = 0.31169385\n",
      "Iteration 33, loss = 0.30688874\n",
      "Iteration 34, loss = 0.30029401\n",
      "Iteration 35, loss = 0.29329962\n",
      "Iteration 36, loss = 0.29046251\n",
      "Iteration 37, loss = 0.29033568\n",
      "Iteration 38, loss = 0.28993243\n",
      "Iteration 39, loss = 0.29878004\n",
      "Iteration 40, loss = 0.28427895\n",
      "Iteration 41, loss = 0.28152420\n",
      "Iteration 42, loss = 0.28329313\n",
      "Iteration 43, loss = 0.28676257\n",
      "Iteration 44, loss = 0.28703099\n",
      "Iteration 45, loss = 0.28487383\n",
      "Iteration 46, loss = 0.27208925\n",
      "Iteration 47, loss = 0.26755805\n",
      "Iteration 48, loss = 0.26809417\n",
      "Iteration 49, loss = 0.26737668\n",
      "Iteration 50, loss = 0.26852026\n",
      "Iteration 51, loss = 0.26839872\n",
      "Iteration 52, loss = 0.26417845\n",
      "Iteration 53, loss = 0.26569686\n",
      "Iteration 54, loss = 0.25485611\n",
      "Iteration 55, loss = 0.25609931\n",
      "Iteration 56, loss = 0.25901037\n",
      "Iteration 57, loss = 0.25170053\n",
      "Iteration 58, loss = 0.25325198\n",
      "Iteration 59, loss = 0.24526669\n",
      "Iteration 60, loss = 0.25620942\n",
      "Iteration 61, loss = 0.24358450\n",
      "Iteration 62, loss = 0.24789245\n",
      "Iteration 63, loss = 0.24005816\n",
      "Iteration 64, loss = 0.24454213\n",
      "Iteration 65, loss = 0.23332955\n",
      "Iteration 66, loss = 0.24169435\n",
      "Iteration 67, loss = 0.24809196\n",
      "Iteration 68, loss = 0.25303630\n",
      "Iteration 69, loss = 0.23199896\n",
      "Iteration 70, loss = 0.23260741\n",
      "Iteration 71, loss = 0.23080585\n",
      "Iteration 72, loss = 0.22321915\n",
      "Iteration 73, loss = 0.21855389\n",
      "Iteration 74, loss = 0.22464546\n",
      "Iteration 75, loss = 0.22728740\n",
      "Iteration 76, loss = 0.21607724\n",
      "Iteration 77, loss = 0.21631568\n",
      "Iteration 78, loss = 0.21296019\n",
      "Iteration 79, loss = 0.22292855\n",
      "Iteration 80, loss = 0.21674803\n",
      "Iteration 81, loss = 0.21695757\n",
      "Iteration 82, loss = 0.23300472\n",
      "Iteration 83, loss = 0.20891997\n",
      "Iteration 84, loss = 0.21463825\n",
      "Iteration 85, loss = 0.20641038\n",
      "Iteration 86, loss = 0.21809056\n",
      "Iteration 87, loss = 0.20234303\n",
      "Iteration 88, loss = 0.20330863\n",
      "Iteration 89, loss = 0.20340038\n",
      "Iteration 90, loss = 0.19584970\n",
      "Iteration 91, loss = 0.19700139\n",
      "Iteration 92, loss = 0.20859007\n",
      "Iteration 93, loss = 0.20028450\n",
      "Iteration 94, loss = 0.19545005\n",
      "Iteration 95, loss = 0.19784527\n",
      "Iteration 96, loss = 0.20709369\n",
      "Iteration 97, loss = 0.20106649\n",
      "Iteration 98, loss = 0.19048721\n",
      "Iteration 99, loss = 0.19851193\n",
      "Iteration 100, loss = 0.19612375\n",
      "Iteration 101, loss = 0.19625273\n",
      "Iteration 102, loss = 0.19018682\n",
      "Iteration 103, loss = 0.18872347\n",
      "Iteration 104, loss = 0.19502689\n",
      "Iteration 105, loss = 0.18630463\n",
      "Iteration 106, loss = 0.18378668\n",
      "Iteration 107, loss = 0.18083193\n",
      "Iteration 108, loss = 0.18532898\n",
      "Iteration 109, loss = 0.18405252\n",
      "Iteration 110, loss = 0.17231883\n",
      "Iteration 111, loss = 0.17345552\n",
      "Iteration 112, loss = 0.17342180\n",
      "Iteration 113, loss = 0.17319159\n",
      "Iteration 114, loss = 0.17890995\n",
      "Iteration 115, loss = 0.18150447\n",
      "Iteration 116, loss = 0.18391292\n",
      "Iteration 117, loss = 0.17349639\n",
      "Iteration 118, loss = 0.17623324\n",
      "Iteration 119, loss = 0.17656243\n",
      "Iteration 120, loss = 0.18675933\n",
      "Iteration 121, loss = 0.16918686\n",
      "Iteration 122, loss = 0.16039664\n",
      "Iteration 123, loss = 0.16173024\n",
      "Iteration 124, loss = 0.16774672\n",
      "Iteration 125, loss = 0.17502642\n",
      "Iteration 126, loss = 0.16439953\n",
      "Iteration 127, loss = 0.15814098\n",
      "Iteration 128, loss = 0.16165364\n",
      "Iteration 129, loss = 0.15479199\n",
      "Iteration 130, loss = 0.17012832\n",
      "Iteration 131, loss = 0.16331635\n",
      "Iteration 132, loss = 0.16062396\n",
      "Iteration 133, loss = 0.15983559\n",
      "Iteration 134, loss = 0.16603832\n",
      "Iteration 135, loss = 0.16300065\n",
      "Iteration 136, loss = 0.15207024\n",
      "Iteration 137, loss = 0.14439363\n",
      "Iteration 138, loss = 0.14621495\n",
      "Iteration 139, loss = 0.15463020\n",
      "Iteration 140, loss = 0.16410279\n",
      "Iteration 141, loss = 0.15026863\n",
      "Iteration 142, loss = 0.14710031\n",
      "Iteration 143, loss = 0.15009655\n",
      "Iteration 144, loss = 0.14553351\n",
      "Iteration 145, loss = 0.16151107\n",
      "Iteration 146, loss = 0.14596314\n",
      "Iteration 147, loss = 0.13879158\n",
      "Iteration 148, loss = 0.14707225\n",
      "Iteration 149, loss = 0.13581455\n",
      "Iteration 150, loss = 0.14725760\n",
      "Iteration 151, loss = 0.14418068\n",
      "Iteration 152, loss = 0.14684496\n",
      "Iteration 153, loss = 0.13645024\n",
      "Iteration 154, loss = 0.13879137\n",
      "Iteration 155, loss = 0.14137894\n",
      "Iteration 156, loss = 0.13855194\n",
      "Iteration 157, loss = 0.13783577\n",
      "Iteration 158, loss = 0.13835781\n",
      "Iteration 159, loss = 0.13356577\n",
      "Iteration 160, loss = 0.13921077\n",
      "Iteration 161, loss = 0.15105769\n",
      "Iteration 162, loss = 0.14890644\n",
      "Iteration 163, loss = 0.14727908\n",
      "Iteration 164, loss = 0.13002787\n",
      "Iteration 165, loss = 0.13363528\n",
      "Iteration 166, loss = 0.13611506\n",
      "Iteration 167, loss = 0.14389551\n",
      "Iteration 168, loss = 0.14050976\n",
      "Iteration 169, loss = 0.13044128\n",
      "Iteration 170, loss = 0.13025617\n",
      "Iteration 171, loss = 0.12206386\n",
      "Iteration 172, loss = 0.13392305\n",
      "Iteration 173, loss = 0.13675295\n",
      "Iteration 174, loss = 0.12626888\n",
      "Iteration 175, loss = 0.12882524\n",
      "Iteration 176, loss = 0.12280014\n",
      "Iteration 177, loss = 0.11535923\n",
      "Iteration 178, loss = 0.11868084\n",
      "Iteration 179, loss = 0.11978191\n",
      "Iteration 180, loss = 0.12107811\n",
      "Iteration 181, loss = 0.11849647\n",
      "Iteration 182, loss = 0.11224855\n",
      "Iteration 183, loss = 0.12009097\n",
      "Iteration 184, loss = 0.11461698\n",
      "Iteration 185, loss = 0.12304452\n",
      "Iteration 186, loss = 0.12881022\n",
      "Iteration 187, loss = 0.11699109\n",
      "Iteration 188, loss = 0.11464069\n",
      "Iteration 189, loss = 0.13663255\n",
      "Iteration 190, loss = 0.12907630\n",
      "Iteration 191, loss = 0.11285651\n",
      "Iteration 192, loss = 0.11553548\n",
      "Iteration 193, loss = 0.11479171\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy:  0.8923314917127072\n"
     ]
    }
   ],
   "source": [
    "# 5 train to see variance\n",
    "n_train = 5\n",
    "accs = []\n",
    "models = []\n",
    "for i in range(n_train):\n",
    "    print(\"Train \", i)\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, verbose=True, random_state=np.random.randint(0, 1000))\n",
    "    model.fit(X_rearingR_train, y_rearingR_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_rearingR_test, y_pred)\n",
    "    accs.append(acc)\n",
    "    models.append(model)\n",
    "    print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['General_Contacts', 'Sniffing_R', 'Sniffing_head_R', 'Sniffing_other_R',\n",
       "       'Sniffing_anal_R', 'Poursuit_R', 'Dominance_R', 'Rearing_R',\n",
       "       'Grooming_R', 'Sniffing_V', 'Sniffing_head_V', 'Sniffing_other_V',\n",
       "       'Sniffing_anal_V', 'Poursuit_V', 'Dominance_V', 'Rearing_V',\n",
       "       'Grooming_V'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beh_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  [0.8592265193370165, 0.8574585635359117, 0.8833149171270718, 0.882475138121547, 0.8923314917127072]\n",
      " variance accuracy:  0.0001963786697597752\n",
      "The accuracy is: 0.8749613259668507  +/-  0.01401351739427954\n",
      "Accuracy:  0.8923314917127072\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy\n",
    "print(\"accuracy: \", accs)\n",
    "print(\" variance accuracy: \", np.var(accs))\n",
    "\n",
    "print(\"The accuracy is:\", np.mean(accs), \" +/- \", np.std(accs))\n",
    "\n",
    "# Best model\n",
    "model = models[np.argmax(accs)]\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_rearingR_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_rearingR_test, y_pred)\n",
    "cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure()\n",
    "plt.title('Confusion matrix of the best model for Rearing')\n",
    "sns.heatmap(cm, annot=True, xticklabels=['No Rearing', 'Rearing'], yticklabels=['No Rearing', 'Rearing'], cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/baseline_models/new_dataset/model_rearingR.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "joblib.dump(model, 'models/baseline_models/new_dataset/model_rearingR.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_names[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grooming Resident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_groomR_train = y_train[:, 8]\n",
    "y_groomR_test = y_test[:, 8]\n",
    "\n",
    "# Check Nans in the data\n",
    "print(\"Nan's \", np.isnan(y_groomR_train).sum())\n",
    "\n",
    "# Class Balance\n",
    "plt.hist(y_groomR_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print('Active: ', np.sum(y_groomR_train == 1))\n",
    "print('Inactive: ', np.sum(y_groomR_train == 0))\n",
    "print('Percentage: ', np.sum(y_groomR_train == 1) / len(y_groomR_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the inactive class\n",
    "idx = np.where(y_groomR_train == 0)[0]\n",
    "idx = np.random.choice(idx, np.sum(y_groomR_train == 1), replace=False)\n",
    "idx = np.concatenate([np.where(y_groomR_train == 1)[0], idx])\n",
    "idx = np.random.permutation(idx)\n",
    "\n",
    "X_groomR_train = X_train[idx]\n",
    "y_groomR_train = y_groomR_train[idx]\n",
    "\n",
    "# class balance\n",
    "plt.hist(y_groomR_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print(' Train dataset size: ', X_groomR_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 train to see variance\n",
    "n_train = 5\n",
    "accs = []\n",
    "models = []\n",
    "for i in range(n_train):\n",
    "    print(\"Train \", i)\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, verbose=True)\n",
    "    model.fit(X_groomR_train, y_groomR_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_groomR_test, y_pred)\n",
    "    accs.append(acc)\n",
    "    models.append(model)\n",
    "    print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "print(\"accuracy: \", accs)\n",
    "print(\" variance accuracy: \", np.var(accs))\n",
    "\n",
    "print(\"The accuracy is:\", np.mean(accs), \" +/- \", np.std(accs))\n",
    "\n",
    "# Best model\n",
    "model = models[np.argmax(accs)]\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_groomR_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_groomR_test, y_pred)\n",
    "cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure()\n",
    "plt.title('Confusion matrix of the best model for Grooming')\n",
    "sns.heatmap(cm, annot=True, xticklabels=['No Grooming', 'Grooming'], yticklabels=['No Grooming', 'Grooming'], cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THis makes no sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "joblib.dump(model, 'baseline_models/new_dataset/model_groomR.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run several times to get the variance of the accuracy\n",
    "acc = []\n",
    "\n",
    "for i in range(10):\n",
    "    y_groomR_train = y_train[:, 6]\n",
    "    y_groomR_test = y_test[:, 6]\n",
    "\n",
    "    # Downsample the inactive class\n",
    "    idx = np.where(y_groomR_train == 0)[0]\n",
    "    idx = np.random.choice(idx, np.sum(y_groomR_train == 1), replace=False)\n",
    "    idx = np.concatenate([np.where(y_groomR_train == 1)[0], idx])\n",
    "    idx = np.random.permutation(idx)\n",
    "\n",
    "    X_groomR_train = X_train[idx]\n",
    "    y_groomR_train = y_groomR_train[idx]\n",
    "\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100), max_iter=1000, verbose=False, random_state=42) \n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_groomR_train, y_groomR_train)\n",
    "\n",
    "    # Test the model\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc.append(accuracy_score(y_groomR_test, y_pred))\n",
    "\n",
    "print('Mean accuracy: ', np.mean(acc))\n",
    "print('Variance: ', np.var(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_names[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinff Visiteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sniffV_train = y_train[:, 7]\n",
    "y_sniffV_test = y_test[:, 7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Balance\n",
    "plt.hist(y_sniffV_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print('Active: ', np.sum(y_sniffV_train == 1))\n",
    "print('Inactive: ', np.sum(y_sniffV_train == 0))\n",
    "print('Percentage: ', np.sum(y_sniffV_train == 1) / len(y_sniffV_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the Inactive class\n",
    "np.random.seed(42)\n",
    "idx = np.where(y_sniffV_train == 0)[0]\n",
    "idx = np.random.choice(idx, np.sum(y_sniffV_train == 1), replace=False)\n",
    "idx = np.concatenate([idx, np.where(y_sniffV_train == 1)[0]])\n",
    "idx = np.random.permutation(idx)\n",
    "X_train_sniff_V = X_train[idx]\n",
    "y_sniffV_train = y_sniffV_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class balance\n",
    "plt.hist(y_sniffV_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print(' Train dataset size: ', X_train_sniff_V.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_sniff_V, y_sniffV_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_sniffV_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_sniffV_test, y_pred)\n",
    "conf_matrix = conf_matrix / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(conf_matrix, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, 'baseline_models/model_sniffV.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_names[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poursuite Visiteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_poursuitV_train = y_train[:, 8]\n",
    "y_poursuitV_test = y_test[:, 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Nans in the data\n",
    "print(np.isnan(y_poursuitV_train).sum())\n",
    "\n",
    "# Class Balance\n",
    "plt.hist(y_poursuitV_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print('Active: ', np.sum(y_poursuitV_train == 1))\n",
    "print('Inactive: ', np.sum(y_poursuitV_train == 0))\n",
    "print('Percentage: ', np.sum(y_poursuitV_train == 1) / len(y_poursuitV_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_names[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dominance Visiteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_domV_train = y_train[:, 9]\n",
    "y_domV_test = y_test[:, 9]\n",
    "\n",
    "# Check Nans in the data\n",
    "print(np.isnan(y_domV_train).sum())\n",
    "\n",
    "# Class Balance\n",
    "plt.hist(y_domV_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print('Active: ', np.sum(y_domV_train == 1))\n",
    "print('Inactive: ', np.sum(y_domV_train == 0))\n",
    "print('Percentage: ', np.sum(y_domV_train == 1) / len(y_domV_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the Inactive class\n",
    "np.random.seed(42)\n",
    "idx = np.where(y_domV_train == 0)[0]\n",
    "idx = np.random.choice(idx, np.sum(y_domV_train == 1), replace=False)\n",
    "idx = np.concatenate([idx, np.where(y_domV_train == 1)[0]])\n",
    "idx = np.random.permutation(idx)\n",
    "\n",
    "X_train_dom_V = X_train[idx]\n",
    "y_domV_train = y_domV_train[idx]\n",
    "\n",
    "# class balance\n",
    "plt.hist(y_domV_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print(' Train dataset size: ', X_train_dom_V.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = MLPClassifier(hidden_layer_sizes=(100), max_iter=1000, verbose=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_dom_V, y_domV_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_domV_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_domV_test, y_pred)\n",
    "conf_matrix = conf_matrix / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(conf_matrix, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_names[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_names[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grooming Visiteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_groomV_train = y_train[:, 11]\n",
    "y_groomV_test = y_test[:, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_groomV_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Balance\n",
    "plt.hist(y_groomV_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print('Active: ', np.sum(y_groomV_train == 1))\n",
    "print('Inactive: ', np.sum(y_groomV_train == 0))\n",
    "print('Percentage: ', np.sum(y_groomV_train == 1) / len(y_groomV_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the Inactive class\n",
    "np.random.seed(42)\n",
    "idx = np.where(y_groomV_train == 0)[0]\n",
    "idx = np.random.choice(idx, np.sum(y_groomV_train == 1), replace=False)\n",
    "idx = np.concatenate([idx, np.where(y_groomV_train == 1)[0]])\n",
    "idx = np.random.permutation(idx)\n",
    "X_train_groom_V = X_train[idx]\n",
    "y_groomV_train = y_groomV_train[idx]\n",
    "\n",
    "# class balance\n",
    "plt.hist(y_groomV_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n",
    "\n",
    "print(X_train_groom_V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, verbose=True, tol = 1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_groom_V, y_groomV_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_groomV_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Predicted: ', y_pred.sum())\n",
    "print(' Non predicted: ', len(y_pred) - y_pred.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_groomV_test, y_pred)\n",
    "conf_matrix = conf_matrix / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(conf_matrix, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_names[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pourV_train = y_train[:, 7]\n",
    "y_pourV_test = y_test[:, 10]\n",
    "\n",
    "# Class Balance\n",
    "plt.hist(y_pourV_train)\n",
    "plt.title('Train class balance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is only data cleannning, renaming, grouping, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'c:\\Users\\jalvarez\\Documents\\Data\\DataLoader_DMD_null_male\\DMD_mal_Test_1.csv')\n",
    "original_column = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the columns are ordered in the .csv files contained in the path\n",
    "files_path = r'c:\\Users\\jalvarez\\Documents\\Data\\DataLoader_DMD_null_male' \n",
    "\n",
    "for file in os.listdir(files_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(os.path.join(files_path, file))\n",
    "        if not np.array_equal(original_column, df.columns):\n",
    "            print(file)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding all the missing behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = r'c:\\Users\\jalvarez\\Documents\\Data\\Behaviour\\MDX5CV\\male female\\Test_1.csv'\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviours = ['Frames', 'General_Contacts', 'Sniffing_R', 'Poursuit_R', 'Dominance_R', 'Rearing_R', 'Grooming_R', 'Sniffing_V', 'Poursuit_V', 'Dominance_V', 'Rearing_V', 'Grooming_V']\n",
    "original_column = ['Frame', 'contacts generaux (R + V) active', 'sniff total resident active', 'poursuite R active', 'dominance R active', 'redressement R active', 'grooming R active',\n",
    "                    'sniff total visiteur active', 'poursuite V active', 'dominance V active', 'redressement V active', 'grooming V active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_columns = dict(zip(original_column, behaviours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(behaviours)):\n",
    "    print(behaviours[i], '--', original_column[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder and rename the columns\n",
    "df = pd.read_csv(csv_file)\n",
    "df.sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[original_column]\n",
    "df.sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = behaviours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the csv files in the path\n",
    "path = r'c:\\Users\\jalvarez\\Documents\\Data\\Behaviour\\MDX5CV\\male female - Copie'\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(os.path.join(path, file))\n",
    "        df = df[original_column]\n",
    "        df.columns = behaviours\n",
    "        df.to_csv(os.path.join(path, file), index=False)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now DMD null**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r'c:\\Users\\jalvarez\\Documents\\Data\\Behaviour\\DMD\\male female\\Test_1.csv'\n",
    "df = pd.read_csv(file)\n",
    "df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviours = ['Frames', 'General_Contacts', 'Sniffing_R', 'Poursuit_R', 'Dominance_R', 'Rearing_R', 'Grooming_R', 'Sniffing_V', 'Poursuit_V', 'Dominance_V', 'Rearing_V', 'Grooming_V']\n",
    "original_column = ['Frame', 'contacts generaux (R + V) active', 'sniff total R active', 'Poursuit R active', 'dominance R active', 'Redressement R active', 'Grooming R active',\n",
    "                    'sniff total V active', 'Poursuit V active', 'Dominance V active', 'Redressement Q active', 'Grooming V active']\n",
    "\n",
    "dict_columns = dict(zip(original_column, behaviours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_columns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_columns = list(df.columns)\n",
    "actual_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for beh in dict_columns.keys():\n",
    "    if beh not in actual_columns:\n",
    "        print(beh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = r'c:\\Users\\jalvarez\\Documents\\Data\\Behaviour\\DMD\\male female - Copie'\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(os.path.join(folder, file))\n",
    "        for beh in dict_columns.keys():\n",
    "            if beh not in df.columns:\n",
    "                # Add the column in that position, filled with NaNs\n",
    "                df[dict_columns[beh]] = np.nan\n",
    "            else:\n",
    "                df = df.rename(columns={beh: dict_columns[beh]})\n",
    "        df = df[behaviours]\n",
    "        df.to_csv(os.path.join(folder, file), index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r'c:\\Users\\jalvarez\\Documents\\Data\\Behaviour\\DMD\\male female - Copie\\Test_1.csv'\n",
    "df = pd.read_csv(file)\n",
    "df.sum(axis=0)\n",
    "df.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a name before each file\n",
    "\n",
    "folder = r'c:\\Users\\jalvarez\\Documents\\Data\\Behaviour\\MDX5CV\\male female - Copie'\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        new_name = 'MDXCV_fem_' + file\n",
    "        os.rename(os.path.join(folder, file), os.path.join(folder, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(DataDLC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dlc = DataDLC.DataDLC(r'c:\\Users\\jalvarez\\Documents\\Data\\DataLoader_Baseline_models\\DMD_mal_Test_21DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r'c:\\Users\\jalvarez\\Documents\\Data\\DLC_analyzedvid\\DMD_null\\DMD_null_male\\DMD_mal_Test 21DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered_id_labeled.mp4'\n",
    "output_path = r'c:\\Users\\jalvarez\\Documents\\Data\\OL\\Nouveau dossier'\n",
    "behaviour_path = r'c:\\Users\\jalvarez\\Documents\\Data\\DataLoader_Baseline_models\\DMD_mal_Test_21.csv'\n",
    "\n",
    "events = pd.read_csv(behaviour_path) # Load the events\n",
    "data_dlc.create_video_per_event(video_path, output_path, events, split_behaviour=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grooming trainning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each video in the dataset, see which has more grooming events\n",
    "import os\n",
    "\n",
    "groomingR = []\n",
    "for data_point in dataset:\n",
    "    beh = data_point[1]\n",
    "    groomingR.append(beh['Grooming_R'].sum()) \n",
    "\n",
    "print('The video with more grooming events is: ', data_loader.files[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = r'c:\\Users\\jalvarez\\Documents\\Data\\videos\\+2mice\\OBS Studio\\2024-08-29 11-37-00.mkv'\n",
    "\n",
    "# See frame rate\n",
    "cap = cv2.VideoCapture(video)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "cap.release()\n",
    "\n",
    "print('Frame rate: ', fps)\n",
    "\n",
    "# Close everything\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
