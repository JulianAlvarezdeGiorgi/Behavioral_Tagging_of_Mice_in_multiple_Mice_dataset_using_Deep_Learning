{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the ENC-DEC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dataloader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import time\n",
    "from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
    "# reload library\n",
    "import importlib\n",
    "import cv2\n",
    "#import utils as ut\n",
    "import pandas as pd\n",
    "import DataDLC\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import tqdm\n",
    "import time\n",
    "import augmentation\n",
    "import sklearn\n",
    "\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import pickle as pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'DataDLC' from 'c:\\\\Users\\\\Usuario\\\\Documents\\\\Documents\\\\MVA\\\\Stage\\\\DLCProject\\\\Code\\\\GitHubRep\\\\Behavioral_Tagging_of_Mice_in_multiple_Mice_dataset_using_Deep_Learning\\\\src\\\\DataDLC.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dataloader)\n",
    "importlib.reload(models)\n",
    "importlib.reload(DataDLC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is only to create an eassy graph to test the build_graph_2 function**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    data_dlc.coords = data_dlc.coords.iloc[range(3), :]\n",
    "    data_dlc.n_frames = 3\n",
    "    data_dlc.save(r'C:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\DataLoaderTestFormat\\output1.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset\n",
    "\n",
    "**Obs:** This is just a test to see if the model is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print numpy version\n",
    "print(np.__version__)\n",
    "\n",
    "# print pytorch version\n",
    "print(torch.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dataloader)\n",
    "importlib.reload(DataDLC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataloader.reload_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deactivate warnings\n",
    "if False:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "    data_loader = dataloader.DLCDataLoader(r'C:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\DataLoaderTrainTest', batch_size=1, num_workers=0, device='cpu', window_size=3, stride = 1, build_graph=True)\n",
    "    #data_loader = dataloader.DLCDataLoader(r'C:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\DataLoaderTestDataset', batch_size=1, num_workers=0, device='cpu', window_size=3, stride = 1, build_graph=True, behaviour='contacts generaux (R + V) active')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "*Graphs were already created and saved in the data folder*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Load the data\n",
    "dataset = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\datasets\\new_entire_dataset.pkl', map_location=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The dataset has %d samples' % len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the behaviour to classify (Grooming in this case)\n",
    "indx_behaviour1 = 0\n",
    "indx_behaviour2 = 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Train-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suffle the dataset\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Test split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "test_dataset = dataset[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].behaviour_names[indx_behaviour1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balance in the training set\n",
    "behaviour = [sample.behaviour[indx_behaviour1] for sample in train_dataset]\n",
    "behaviour = np.array(behaviour)\n",
    "print('The class balance in the training set is:')\n",
    "print(np.unique(behaviour, return_counts=True))\n",
    "\n",
    "plt.hist(behaviour, bins=2)\n",
    "plt.title('Class balance in the training set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Merging the behaviours')\n",
    "augmentation.merge_symetric_behaviours_version2(indx_behaviour1, indx_behaviour2, train_dataset)\n",
    "print('Generating rotation augmentation')\n",
    "# Rotate the dataset\n",
    "augmentation.rotate_samples(train_dataset, indx_behaviour1)\n",
    "#print('Downsampling the inactive behaviours')\n",
    "#train_dataset = augmentation.downsample_majority_class(train_dataset, indx_behaviour1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                \n",
    "for i in range(len(train_dataset)):\n",
    "    train_dataset[i].behaviour = train_dataset[i].behaviour[indx_behaviour1]\n",
    "for i in range(len(test_dataset)):\n",
    "    test_dataset[i].behaviour = test_dataset[i].behaviour[indx_behaviour1]\n",
    "print('Done selecting the behaviour')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The train dataset has %d samples' % len(train_dataset))\n",
    "print('The test dataset has %d samples' % len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balance in the training set\n",
    "behaviour = [sample.behaviour for sample in train_dataset]\n",
    "behaviour = np.array(behaviour)\n",
    "print('The class balance in the training set is:')\n",
    "print(np.unique(behaviour, return_counts=True))\n",
    "\n",
    "plt.hist(behaviour, bins=2)\n",
    "plt.title('Class balance in the training set')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute weights for the loss function\n",
    "\n",
    "\n",
    "weights = sklearn.utils.class_weight.compute_class_weight('balanced', classes = np.unique(behaviour), y = behaviour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The weights for the loss function are:')\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Create the dataloaders for train, validation and test\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "graphencoder = models.GATEncoder(nout = 64, nhid=32, attention_heads = 2, n_in = 4, n_layers=4, dropout=0.2)\n",
    "class_head = models.ClassificationHead(n_latent=64, nhid = 32, nout = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.GraphClassifier(graphencoder, class_head, readout = 'mean')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print('The model has %d trainable parameters' % sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling_per_graph(embbed, batch, frame_mask):\n",
    "    ''' Mean pooling of the embeddings per graph, only the central frame '''\n",
    "    out = []\n",
    "    for i in range(batch.max()+1):\n",
    "        out.append(embbed[batch==i][frame_mask[batch==i] == frame_mask[batch==i].median()].mean(dim=0))\n",
    "    return torch.stack(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_0 = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = graphencoder(batch_0.x, batch_0.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = mean_pooling_per_graph(embed, batch_0.batch, batch_0.frame_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = class_head(lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save the model checkpoints\n",
    "checkpoint_dir = r'./deletefolder/checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, path):\n",
    "    # Save the model, optimizer state, epoch, and loss\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f\"Checkpoint saved at {path}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded from {path}, at epoch {epoch}\")\n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import f1_score and matthews_corrcoef from sklearn\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "metric_0 = f1_score\n",
    "metric_1 = matthews_corrcoef\n",
    "\n",
    "if True:\n",
    "    # Training loop\n",
    "    actual_epoch = 0\n",
    "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    \n",
    "    \n",
    "\n",
    "if False:\n",
    "    # Load the model from a checkpoint\n",
    "    checkpoint_path = r'/gpfs/users/alvarezj/workdir/Project/Data/Checkpoints/GAT_Sniffin_Anal/checkpoint_epoch_170.pth'\n",
    "    actual_epoch = load_checkpoint(model, optimizer, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor(weights, dtype=torch.float32).to(device))\n",
    "writer = SummaryWriter(log_dir='./deletefolder/runs/GAT_Following_w11_new_encoder_2')  # TensorBoard writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()  # Time the training\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    correct_class_0 = 0\n",
    "    correct_class_1 = 0\n",
    "    total_class_0 = 0\n",
    "    total_class_1 = 0\n",
    "    total = 0\n",
    "    i = 0\n",
    "\n",
    "    for data in tqdm.tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        labels = data.behaviour\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        predicted = outputs.argmax(dim=1)\n",
    "        correct_class_0 += (predicted[labels == 0] == labels[labels == 0]).sum().item()\n",
    "        correct_class_1 += (predicted[labels == 1] == labels[labels == 1]).sum().item()\n",
    "        total_class_0 += (labels == 0).sum().item()\n",
    "        total_class_1 += (labels == 1).sum().item()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Log training loss and accuracy at each step\n",
    "        if i % 100 == 0:  # Log every 100 iterations, adjust as needed\n",
    "            writer.add_scalar('Loss/Train', loss.item(), (actual_epoch + epoch) * len(train_loader) + i)\n",
    "            writer.add_scalar('Accuracy/Train', correct / total, (actual_epoch + epoch) * len(train_loader) + i)\n",
    "            # Metrics \n",
    "            writer.add_scalar('Metrics/Train/F1', metric_0(labels, predicted), (actual_epoch + epoch) * len(train_loader) + i)\n",
    "            writer.add_scalar('Metrics/Train/Matthews', metric_1(labels, predicted), (actual_epoch + epoch) * len(train_loader) + i)\n",
    "        i += 1\n",
    "\n",
    "    train_accuracy = correct / total\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + actual_epoch + 1}, Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    correct_class_0 = 0\n",
    "    correct_class_1 = 0\n",
    "    total_class_0 = 0\n",
    "    total_class_1 = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_data in tqdm.tqdm(test_loader):\n",
    "            val_outputs = model(val_data)\n",
    "            val_labels = val_data.behaviour\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "            val_predicted = val_outputs.argmax(dim=1)\n",
    "            correct_class_0 += (val_predicted[val_labels == 0] == val_labels[val_labels == 0]).sum().item()\n",
    "            correct_class_1 += (val_predicted[val_labels == 1] == val_labels[val_labels == 1]).sum().item()\n",
    "            total_class_0 += (val_labels == 0).sum().item()\n",
    "            total_class_1 += (val_labels == 1).sum().item()\n",
    "            correct += (val_predicted == val_labels).sum().item()\n",
    "            total += val_labels.size(0)\n",
    "\n",
    "    val_accuracy = correct / total\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Log validation metrics\n",
    "    writer.add_scalar('Loss/Validation', avg_val_loss, actual_epoch + epoch)\n",
    "    writer.add_scalar('Accuracy/Validation', val_accuracy, actual_epoch + epoch)\n",
    "    writer.add_scalar('Accuracy/Avarage_inactive_class_Validation', correct_class_0 / total_class_0, actual_epoch + epoch)\n",
    "    writer.add_scalar('Accuracy/Avarage_active_class_Validation', correct_class_1 / total_class_1, actual_epoch + epoch)\n",
    "    writer.add_scalar('Accuracy/Average_per_class_Validation', ((correct_class_0 / total_class_0) + (correct_class_1 / total_class_1)) / 2, actual_epoch + epoch)\n",
    "    # Metrics\n",
    "    writer.add_scalar('Metrics/Validation/F1', metric_0(val_labels, val_predicted), actual_epoch + epoch)\n",
    "    writer.add_scalar('Metrics/Validation/Matthews', metric_1(val_labels, val_predicted), actual_epoch + epoch)\n",
    "\n",
    "    # Step the scheduler\n",
    "    #scheduler.step()\n",
    "\n",
    "    # Log learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    writer.add_scalar('Learning Rate', current_lr, actual_epoch + epoch)\n",
    "    print(f\"Learning Rate after epoch {epoch + 1}: {current_lr}\")\n",
    "\n",
    "    # Save checkpoint after each 5 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch + actual_epoch + 1}.pth')\n",
    "        save_checkpoint(model, optimizer, epoch + 1, avg_train_loss, checkpoint_path)\n",
    "\n",
    "# Save the final model\n",
    "if num_epochs % 5 != 0:\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch + actual_epoch + 1}.pth')\n",
    "    save_checkpoint(model, optimizer, epoch + 1, avg_train_loss, checkpoint_path)\n",
    "\n",
    "# Time the training\n",
    "end_time = time.time()\n",
    "print(f\"Training took {end_time - start_time} seconds, for {num_epochs} epochs\")\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n",
    "\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "x, edge_index, batch, frame_mask = batch.x, batch.edge_index, batch.batch, batch.frame_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.SimpleMLPforGraph(n_in=144, n_hid=128, n_out=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainning loop\n",
    "num_epochs = 10\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(log_dir='runs/gcn_action_detection')  # TensorBoard writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, data in tqdm.tqdm(enumerate(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data).unsqueeze(0)\n",
    "        labels = data.y\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        train_loss += loss.item()\n",
    "        predicted = outputs.argmax(dim=1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        # Log training loss and accuracy at each step\n",
    "        if i % 10 == 0:  # Log every 10 iterations, adjust as needed\n",
    "            writer.add_scalar('Loss/Train', loss.item(), epoch * len(train_loader) + i)\n",
    "            writer.add_scalar('Accuracy/Train', correct / total, epoch * len(train_loader) + i)\n",
    "            #print(f\"Epoch {epoch+1}, Step {i}, Loss: {loss.item()}, Accuracy: {correct / total}\")\n",
    "\n",
    "    train_accuracy = correct / total\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_data in tqdm.tqdm(test_loader):\n",
    "            val_outputs = model(val_data).unsqueeze(0)\n",
    "            val_labels = val_data.y\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "            val_predicted = val_outputs.argmax(dim=1)\n",
    "            correct += (val_predicted == val_labels).sum().item()\n",
    "            total += val_labels.size(0)\n",
    "    \n",
    "    val_accuracy = correct / total\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    \n",
    "    print(f\"Validation Loss: {avg_val_loss}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Log validation metrics\n",
    "    writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/Validation', val_accuracy, epoch)\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i, data in tqdm.tqdm(enumerate(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        labels = data.y\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        train_loss += loss.item()\n",
    "        predicted = outputs.argmax(dim=1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "        # Log training loss and accuracy at each step\n",
    "        if i % 10 == 0:  # Log every 10 iterations, adjust as needed\n",
    "            writer.add_scalar('Loss/Train', loss.item(), epoch * len(train_loader) + i)\n",
    "            writer.add_scalar('Accuracy/Train', correct / total, epoch * len(train_loader) + i)\n",
    "            #print(f\"Epoch {epoch+1}, Step {i}, Loss: {loss.item()}, Accuracy: {correct / total}\")\n",
    "\n",
    "    train_accuracy = correct / total\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_data in test_loader:\n",
    "            val_outputs = model(val_data)\n",
    "            val_labels = val_data.y\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "            val_predicted = val_outputs.argmax(dim=1)\n",
    "            correct += (val_predicted == val_labels).sum().item()\n",
    "            total += val_labels.size(0)\n",
    "    \n",
    "    val_accuracy = correct / total\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    \n",
    "    print(f\"Validation Loss: {avg_val_loss}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Log validation metrics\n",
    "    writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/Validation', val_accuracy, epoch)\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning loop\n",
    "epochs = 50\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    las\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        out = model.forward(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = GraphAE.forward(data_loader.dataset[0].x, data_loader.dataset[0].edge_index, data_loader.dataset[0].frame_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss = GraphAE.loss(data_loader.dataset[0].x, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "encoder = models.GATEncoder(nout = 64, nhid=16, attention_hidden=2, n_in=3, dropout=0.5).to(device)\n",
    "print(encoder)\n",
    "decoder = models.GATDecoder(n_latent=64, n_hidden=16, n_out=3).to(device)\n",
    "print(decoder)\n",
    "model = models.GraphAE(encoder, decoder).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "data = data_loader.dataset\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    for i in range(len(data)):\n",
    "\n",
    "        out = model(data[i].x.to(device), data[i].edge_index.to(device), data[i].frame_mask.to(device))\n",
    "        loss = model.loss(data[i].x, out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch}, Loss {loss.item()}')\n",
    "\n",
    "model.eval()\n",
    "out = model(data[0].x, data[0].edge_index, data[0].frame_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyout = out[0][0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the output of the model, the first dimension are the points, and the second one is the x and y coordinates\n",
    "plt.scatter(numpyout[:,0], numpyout[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_loader.dataset[0].x.shape)\n",
    "print(x[0].shape)\n",
    "print(x[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_loader.dataset[0].x.shape)\n",
    "print(x[0].shape)\n",
    "print(x[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = behaviour.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dataloader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import time\n",
    "from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
    "# reload library\n",
    "import importlib\n",
    "import cv2\n",
    "#import utils as ut\n",
    "import pandas as pd\n",
    "import DataDLC\n",
    "from torch_geometric.data import Data, DataLoader, DataListLoader\n",
    "import tqdm\n",
    "import time\n",
    "import augmentation\n",
    "import sklearn\n",
    "# Import f1_score and matthews_corrcoef from sklearn\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import pickle as pkl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'augmentation' from 'c:\\\\Users\\\\Usuario\\\\Documents\\\\Documents\\\\MVA\\\\Stage\\\\DLCProject\\\\Code\\\\GitHubRep\\\\Behavioral_Tagging_of_Mice_in_multiple_Mice_dataset_using_Deep_Learning\\\\src\\\\augmentation.py'>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_15436\\1586004789.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\datasets\\dataset_w1.pkl', map_location=device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load the data\n",
    "dataset = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\datasets\\dataset_w1.pkl', map_location=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Index(['General_Contacts', 'Sniffing_R', 'Sniffing_head_R', 'Sniffing_other_R',\n",
    "    #    'Sniffing_anal_R', 'Poursuit_R', 'Dominance_R', 'Rearing_R',\n",
    "    #    'Grooming_R', 'Sniffing_V', 'Sniffing_head_V', 'Sniffing_other_V',\n",
    "    #    'Sniffing_anal_V', 'Poursuit_V', 'Dominance_V', 'Rearing_V',\n",
    "    #    'Grooming_V'],\n",
    "    #   dtype='object')\n",
    "# Select the behaviour to classify (Grooming in this case)\n",
    "indx_behaviour1 = 1\n",
    "indx_behaviour2 = 6\n",
    "\n",
    "# Select the behaviour to classify\n",
    "name_behaviour = dataset[0].behaviour_names[indx_behaviour1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#print('Selecting the behaviour')\n",
    "#for i in range(len(dataset)):\n",
    "#    dataset[i].behaviour = dataset[i].behaviour[indx_behaviour1]\n",
    "\n",
    "window_size = 5\n",
    "seq_dataset = dataloader.SequenceDataset(dataset, sequence_length=window_size)\n",
    "\n",
    "def split_dataset(dataset, split_ratio=0.8):\n",
    "    dataset.shuffle()  # Shuffle the sequences\n",
    "    split_idx = int(len(dataset) * split_ratio)\n",
    "    train_data = dataset.sequences[:split_idx]\n",
    "    test_data = dataset.sequences[split_idx:]\n",
    "    return train_data, test_data\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_data, test_data = split_dataset(seq_dataset, split_ratio=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset has 124219 samples\n",
      "The test dataset has 31055 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('The train dataset has %d samples' % len(train_data))\n",
    "print('The test dataset has %d samples' % len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[1][indx_behaviour1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation.merge_symetric_behaviours_sequences(indx_behaviour1, indx_behaviour2, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i in range(len(dataset)):\n",
    "    if dataset[i].behaviour[behaviour] == torch.tensor(1):\n",
    "        indices.append(i)\n",
    "# Symetric wrt y axis\n",
    "for indx in indices:\n",
    "    new_sample = dataset[indx].clone()\n",
    "    new_sample.x[:,0] = torch.tensor(1) - new_sample.x[:,0]\n",
    "    dataset.append(new_sample)\n",
    "# Symetric wrt x axis\n",
    "for indx in indices:\n",
    "    new_sample = dataset[indx].clone()\n",
    "    new_sample.x[:,1] = torch.tensor(1) - new_sample.x[:,1]\n",
    "    dataset.append(new_sample)\n",
    "# Transpose\n",
    "for indx in indices:\n",
    "    new_sample = dataset[indx].clone()\n",
    "    new_sample.x[:,0], new_sample.x[:,1] = new_sample.x[:,1], new_sample.x[:,0]\n",
    "    dataset.append(new_sample)\n",
    "# Rotate 180 degrees\n",
    "for indx in indices:\n",
    "    new_sample = dataset[indx].clone()\n",
    "    new_sample.x[:,0] = torch.tensor(1) - new_sample.x[:,0]\n",
    "    new_sample.x[:,1] = torch.tensor(1) - new_sample.x[:,1]\n",
    "    dataset.append(new_sample)\n",
    "return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Merging the behaviours')\n",
    "#augmentation.merge_symetric_behaviours_version2(indx_behaviour1, indx_behaviour2, train_dataset)\n",
    "#print('Generating rotation augmentation')\n",
    "# Rotate the dataset\n",
    "#augmentation.rotate_samples(train_dataset, indx_behaviour1)\n",
    "#print('Downsampling the inactive behaviours')\n",
    "#train_dataset = augmentation.downsample_majority_class(train_dataset, indx_behaviour1)\n",
    "                                                 \n",
    "# #for i in range(len(train_dataset)):\n",
    "#     train_dataset[i].behaviour = train_dataset[i].behaviour[indx_behaviour1]\n",
    "# for i in range(len(test_dataset)):\n",
    "#     test_dataset[i].behaviour = test_dataset[i].behaviour[indx_behaviour1]\n",
    "# print('Done selecting the behaviour')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset has 132973 samples\n",
      "The test dataset has 31055 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('The train dataset has %d samples' % len(train_data))\n",
    "print('The test dataset has %d samples' % len(test_data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# behaviour = [sample.behaviour for sample in train_dataset]\n",
    "# behaviour = np.array(behaviour)\n",
    "\n",
    "# weights_ = sklearn.utils.class_weight.compute_class_weight('balanced', classes = np.unique(behaviour), y = behaviour)\n",
    "# del behaviour\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "# Create the dataloaders for train, validation and test\n",
    "train_loader = DataListLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataListLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define the model\n",
    "model = models.GAT_LSTM(input_dim = 4, hidden_dim=64, lstm_hidden_dim=128, num_classes=1, num_nodes=36, heads=4)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print('The model has %d trainable parameters' % sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "\n",
    "# Directory to save the model checkpoints\n",
    "checkpoint_dir = r'/gpfs/users/alvarezj/workdir/Project/Data/Checkpoints/GAT_LSTM/%s' % name_behaviour\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, path):\n",
    "    # Save the model, optimizer state, epoch, and loss\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f\"Checkpoint saved at {path}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded from {path}, at epoch {epoch}\")\n",
    "    return epoch\n",
    "\n",
    "num_epochs = 200\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "if True:\n",
    "    # Training loop\n",
    "    actual_epoch = 0\n",
    "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    \n",
    "    \n",
    "\n",
    "if False:\n",
    "    # Load the model from a checkpoint\n",
    "    checkpoint_path = r'/gpfs/users/alvarezj/workdir/Project/Data/Checkpoints/GAT_Sniffin_Anal/checkpoint_epoch_170.pth'\n",
    "    actual_epoch = load_checkpoint(model, optimizer, checkpoint_path)\n",
    "\n",
    "#y = [d.behaviour.cpu().detach().numpy() for d in dataset]\n",
    "#y = np.array(y)\n",
    "#weight_ = sklearn.utils.class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
    "#weight_ = torch.tensor([0.55852461, 4.7717076]).to(device) # Grooming (before adding last analysis)\n",
    "#weight_ = torch.tensor([0.76221058, 1.45343216]).to(device) # Dominance (before adding last analysis)\n",
    "#weight_ = torch.tensor([0.58626763, 3.39795837]).to(device) # Rearing (before adding last analysis)\n",
    "#weight_ = torch.tensor([0.60796284, 2.81561145]).to(device) # Sniffing anal\n",
    "#weight_ = torch.tensor([0.66321035, 2.03176556]).to(device) # Following with only rotation augmentation\n",
    "#weight_ = torch.tensor([0.5331574 , 8.03979407]).to(device) # Following with merged behaviours only\n",
    "#print(' The class weights are: ', weight_)\n",
    "# Destroy y\n",
    "#criterion = nn.CrossEntropyLoss(weight=torch.tensor(weights_, dtype=torch.float32).to(device))\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy with logits\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "name_file = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "writer = SummaryWriter(log_dir=os.path.join('runs/GAT_LSTM/%s/' % name_behaviour, name_file))\n",
    "\n",
    "f = open(os.path.join('runs/GAT_LSTM/%s/' % name_behaviour, name_file, 'info.txt'), 'w')\n",
    "f.write('Dataset used: new_dataset_large.pkl\\n')\n",
    "f.write('Behaviour selected: %s\\n' % name_behaviour)\n",
    "f.write('Number of epochs: %d\\n' % num_epochs)\n",
    "f.write('Batch size: %d\\n' % batch_size)\n",
    "f.write('Learning rate: %f\\n' % lr)\n",
    "f.write('Window size: %d\\n' % window_size)\n",
    "f.write('Model used:%s\\n' % str(model))\n",
    "f.write('Number of trainable parameters: %d\\n' % sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "f.write('Criterion: BCEWithLogitsLoss\\n')\n",
    "f.write('Optimizer: Adam\\n')\n",
    "f.write('Scheduler: None\\n')\n",
    "f.write('Data augmentation: None\\n')\n",
    "#f.write('Class weights: %s\\n' % str(weights_))\n",
    "f.close()\n",
    "\n",
    "\n",
    "start_time = time.time()  # Time the training\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_idx = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Loop over each batch from the DataListLoader\n",
    "    for batch in tqdm.tqdm(train_loader):\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        # Unpack batch (sequence and label)\n",
    "        sequences, labels = zip(*batch)  # batch is a list of (sequence, label) tuples\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        output = model(sequences)\n",
    "\n",
    "        # Assuming labels are already tensors, no need to convert them again\n",
    "        labels = torch.tensor(labels, dtype=torch.float32).to(device).unsqueeze(1)  # Add singleton dimension for BCELoss\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Predictions and accuracy computation\n",
    "        predictions = torch.sigmoid(output).round()  # Convert logits to probabilities and round for binary\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        if batch_idx % 100 == 0:  # Log every 100 iterations, adjust as needed\n",
    "            # Log metrics to TensorBoard after each batch\n",
    "            writer.add_scalar('Loss/train', loss.item(), epoch * len(train_loader) + batch_idx)\n",
    "            writer.add_scalar('Accuracy/train', correct / total * 100, epoch * len(train_loader) + batch_idx)\n",
    "\n",
    "        batch_idx += 1\n",
    "\n",
    "    # Print epoch loss and training accuracy\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    accuracy_train = correct / total * 100\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy_train:.2f}%')\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_running_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_correct_class_0 = 0\n",
    "    val_correct_class_1 = 0\n",
    "    val_total_class_0 = 0\n",
    "    val_total_class_1 = 0\n",
    "    val_all_labels = []\n",
    "    val_all_predictions = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for validation\n",
    "        for val_batch in tqdm.tqdm(test_loader):\n",
    "            # Unpack validation batch\n",
    "            val_sequences, val_labels = zip(*val_batch)  # batch is a list of (sequence, label) tuples\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            val_output = model(val_sequences)\n",
    "\n",
    "            # Convert labels to tensor\n",
    "            val_labels = torch.tensor(val_labels, dtype=torch.float32).to(device).unsqueeze(1)  # Add singleton dimension for BCELoss\n",
    "\n",
    "            # Compute the loss\n",
    "            val_loss = criterion(val_output, val_labels)\n",
    "            val_running_loss += val_loss.item()\n",
    "\n",
    "            # Predictions and accuracy computation\n",
    "            val_predictions = torch.sigmoid(val_output).round()  # Convert logits to probabilities and round for binary\n",
    "            val_correct += (val_predictions == val_labels).sum().item()\n",
    "            val_total += val_labels.size(0)\n",
    "            val_correct_class_0 += (val_predictions[val_labels == 0] == val_labels[val_labels == 0]).sum().item()\n",
    "            val_correct_class_1 += (val_predictions[val_labels == 1] == val_labels[val_labels == 1]).sum().item()\n",
    "            val_total_class_0 += (val_labels == 0).sum().item()\n",
    "            val_total_class_1 += (val_labels == 1).sum().item()\n",
    "\n",
    "            # Store predictions and labels for metrics\n",
    "            val_all_labels.extend(val_labels.cpu().numpy())\n",
    "            val_all_predictions.extend(val_predictions.cpu().numpy())\n",
    "        \n",
    "\n",
    "    # Calculate validation metrics\n",
    "    f1_val = f1_score(val_all_labels, val_all_predictions)\n",
    "    mcc_val = matthews_corrcoef(val_all_labels, val_all_predictions)\n",
    "\n",
    "    # Print validation metrics\n",
    "    val_epoch_loss = val_running_loss / len(test_loader)\n",
    "    accuracy_val = val_correct / val_total * 100\n",
    "    print(f'Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {accuracy_val:.2f}%, F1 Score: {f1_val:.4f}, MCC: {mcc_val:.4f}')\n",
    "\n",
    "    # Log validation metrics to TensorBoard\n",
    "    writer.add_scalar('Loss/validation', val_epoch_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/validation', accuracy_val, epoch)\n",
    "    writer.add_scalar('Accuracy/Avarage_inactive_class_validation', val_correct_class_0 / val_total_class_0, epoch)\n",
    "    writer.add_scalar('Accuracy/Avarage_active_class_validation', val_correct_class_1 / val_total_class_1, epoch)\n",
    "    writer.add_scalar('Accuracy/Average_per_class_validation', ((val_correct_class_0 / val_total_class_0) + (val_correct_class_1 / val_total_class_1)) / 2, epoch)\n",
    "    writer.add_scalar('F1 Score/validation', f1_val, epoch)\n",
    "    writer.add_scalar('MCC/validation', mcc_val, epoch)\n",
    "\n",
    "    # Step the scheduler\n",
    "    #scheduler.step()\n",
    "\n",
    "    # # Log learning rate\n",
    "    # current_lr = optimizer.param_groups[0]['lr']\n",
    "    # writer.add_scalar('Learning Rate', current_lr, actual_epoch + epoch)\n",
    "    # print(f\"Learning Rate after epoch {epoch + 1}: {current_lr}\")\n",
    "\n",
    "    # Save checkpoint after each 5 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch + actual_epoch + 1}.pth')\n",
    "        save_checkpoint(model, optimizer, epoch + 1, epoch_loss, checkpoint_path)\n",
    "\n",
    "# Save the final model\n",
    "if num_epochs % 10 != 0:\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch + actual_epoch + 1}.pth')\n",
    "    save_checkpoint(model, optimizer, epoch + 1, epoch_loss, checkpoint_path)\n",
    "\n",
    "# Time the training\n",
    "end_time = time.time()\n",
    "print(f\"Training took {end_time - start_time} seconds, for {num_epochs} epochs\")\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n",
    "\n",
    "print(\"Training finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envProj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
