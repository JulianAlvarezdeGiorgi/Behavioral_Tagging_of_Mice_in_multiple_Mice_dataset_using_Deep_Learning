{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the ENC-DEC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dataloader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import time\n",
    "from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
    "# reload library\n",
    "import importlib\n",
    "import cv2\n",
    "#import utils as ut\n",
    "import pandas as pd\n",
    "import DataDLC\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import tqdm\n",
    "import time\n",
    "import augmentation\n",
    "import sklearn\n",
    "\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import pickle as pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'DataDLC' from 'c:\\\\Users\\\\Usuario\\\\Documents\\\\Documents\\\\MVA\\\\Stage\\\\DLCProject\\\\Code\\\\GitHubRep\\\\Behavioral_Tagging_of_Mice_in_multiple_Mice_dataset_using_Deep_Learning\\\\src\\\\DataDLC.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dataloader)\n",
    "importlib.reload(models)\n",
    "importlib.reload(DataDLC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is only to create an eassy graph to test the build_graph_2 function**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    data_dlc.coords = data_dlc.coords.iloc[range(3), :]\n",
    "    data_dlc.n_frames = 3\n",
    "    data_dlc.save(r'C:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\DataLoaderTestFormat\\output1.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset\n",
    "\n",
    "**Obs:** This is just a test to see if the model is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n",
      "2.4.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# print numpy version\n",
    "print(np.__version__)\n",
    "\n",
    "# print pytorch version\n",
    "print(torch.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'DataDLC' from 'c:\\\\Users\\\\Usuario\\\\Documents\\\\Documents\\\\MVA\\\\Stage\\\\DLCProject\\\\Code\\\\GitHubRep\\\\Behavioral_Tagging_of_Mice_in_multiple_Mice_dataset_using_Deep_Learning\\\\src\\\\DataDLC.py'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dataloader)\n",
    "importlib.reload(DataDLC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DMD_mal_Test_1DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5', 'DMD_mal_Test_2DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5']\n",
      "Loading data from C:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\DataLoaderTestFormat, where we have 2 files\n",
      "We have 2 files\n",
      "Loading file DMD_mal_Test_1DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2628/2628 [00:31<00:00, 82.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file DMD_mal_Test_2DLC_dlcrnetms5_More_BodyPartsJul9shuffle1_740000_el_filtered.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2633/2633 [00:32<00:00, 80.66it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# deactivate warnings\n",
    "if True:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "    data_loader = dataloader.DLCDataLoader(r'C:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\DataLoaderTestFormat', window_size=5, stride = 1, build_graph=True)\n",
    "    #data_loader = dataloader.DLCDataLoader(r'C:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\DataLoaderTestDataset', batch_size=1, num_workers=0, device='cpu', window_size=3, stride = 1, build_graph=True, behaviour='contacts generaux (R + V) active')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.save_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "*Graphs were already created and saved in the data folder*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mdataset\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_24344\\4265510721.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\datasets\\dataset_5.pkl', map_location=device)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Load the data\n",
    "dataset = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\datasets\\dataset_5.pkl', map_location=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 310077 samples\n"
     ]
    }
   ],
   "source": [
    "print('The dataset has %d samples' % len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the behaviour to classify (Grooming in this case)\n",
    "indx_behaviour1 = 1\n",
    "indx_behaviour2 = 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Train-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suffle the dataset\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Test split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "test_dataset = dataset[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248061\n",
      "62016\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sniffing_R'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].behaviour_names[indx_behaviour1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Class balance in the training set\u001b[39;00m\n\u001b[0;32m      2\u001b[0m behaviour \u001b[38;5;241m=\u001b[39m [sample\u001b[38;5;241m.\u001b[39mbehaviour[indx_behaviour1] \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m train_dataset]\n\u001b[1;32m----> 3\u001b[0m behaviour \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbehaviour\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe class balance in the training set is:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(behaviour, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\deepof\\lib\\site-packages\\torch\\_tensor.py:966\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;66;03m# Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\u001b[39;00m\n\u001b[0;32m    964\u001b[0m __array_priority__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m  \u001b[38;5;66;03m# prefer Tensor ops over numpy ones\u001b[39;00m\n\u001b[1;32m--> 966\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    968\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Class balance in the training set\n",
    "behaviour = [sample.behaviour[indx_behaviour1] for sample in train_dataset]\n",
    "behaviour = np.array(behaviour)\n",
    "print('The class balance in the training set is:')\n",
    "print(np.unique(behaviour, return_counts=True))\n",
    "\n",
    "plt.hist(behaviour, bins=2)\n",
    "plt.title('Class balance in the training set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Merging the behaviours')\n",
    "augmentation.merge_symetric_behaviours_version2(indx_behaviour1, indx_behaviour2, train_dataset)\n",
    "print('Generating rotation augmentation')\n",
    "# Rotate the dataset\n",
    "augmentation.rotate_samples(train_dataset, indx_behaviour1)\n",
    "#print('Downsampling the inactive behaviours')\n",
    "#train_dataset = augmentation.downsample_majority_class(train_dataset, indx_behaviour1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done selecting the behaviour\n"
     ]
    }
   ],
   "source": [
    "                                                \n",
    "for i in range(len(train_dataset)):\n",
    "    train_dataset[i].behaviour = train_dataset[i].behaviour[indx_behaviour1]\n",
    "for i in range(len(test_dataset)):\n",
    "    test_dataset[i].behaviour = test_dataset[i].behaviour[indx_behaviour1]\n",
    "print('Done selecting the behaviour')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset has 248061 samples\n",
      "The test dataset has 62016 samples\n"
     ]
    }
   ],
   "source": [
    "print('The train dataset has %d samples' % len(train_dataset))\n",
    "print('The test dataset has %d samples' % len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balance in the training set\n",
    "behaviour = [sample.behaviour for sample in train_dataset]\n",
    "behaviour = np.array(behaviour)\n",
    "print('The class balance in the training set is:')\n",
    "print(np.unique(behaviour, return_counts=True))\n",
    "\n",
    "plt.hist(behaviour, bins=2)\n",
    "plt.title('Class balance in the training set')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute weights for the loss function\n",
    "\n",
    "\n",
    "weights = sklearn.utils.class_weight.compute_class_weight('balanced', classes = np.unique(behaviour), y = behaviour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The weights for the loss function are:')\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Create the dataloaders for train, validation and test\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from 'c:\\\\Users\\\\Usuario\\\\Documents\\\\Documents\\\\MVA\\\\Stage\\\\DLCProject\\\\Code\\\\GitHubRep\\\\Behavioral_Tagging_of_Mice_in_multiple_Mice_dataset_using_Deep_Learning\\\\src\\\\models.py'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "graphencoder = models.GATEncoder(nout = 64, nhid=32, attention_heads = 2, n_in = 4, n_layers=4, dropout=0.2)\n",
    "class_head = models.ClassificationHead(n_latent=64, nhid = 32, nout = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 37698 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model = models.GraphClassifier(graphencoder, class_head, readout = 'max')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print('The model has %d trainable parameters' % sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling_per_graph(embbed, batch, frame_mask):\n",
    "    ''' Mean pooling of the embeddings per graph, only the central frame '''\n",
    "    out = []\n",
    "    for i in range(batch.max()+1):\n",
    "        out.append(embbed[batch==i][frame_mask[batch==i] == frame_mask[batch==i].median()].mean(dim=0))\n",
    "    return torch.stack(out)\n",
    "\n",
    "\n",
    "def concatenate_per_graph(embbed, batch, frame_mask):\n",
    "    ''' Concatenate the embeddings per graph, only the central frame '''\n",
    "    out = []\n",
    "    for i in range(batch.max()+1):\n",
    "        out.append(embbed[batch==i][frame_mask[batch==i] == frame_mask[batch==i].median()].flatten())\n",
    "    return torch.stack(out)\n",
    "\n",
    "def max_pooling_per_graph(embbed, batch, frame_mask):\n",
    "    ''' Max pooling of the embeddings per graph, only the central frame '''\n",
    "    out = []\n",
    "    for i in range(batch.max()+1):\n",
    "        out.append(embbed[batch==i][frame_mask[batch==i] == frame_mask[batch==i].median()].max(dim=0).values)\n",
    "    return torch.stack(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_0 = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[5760, 4], edge_index=[2, 118976], file=[32], frame_mask=[5760], behaviour=[32], behaviour_names=[32], batch=[5760], ptr=[33])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = graphencoder(batch_0.x, batch_0.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5760, 64])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "for i in range(batch_0.batch.max()+1):\n",
    "    print(embed[batch_0.batch==i][batch_0.frame_mask[batch_0.batch==i] == batch_0.frame_mask[batch_0.batch==i].median()].max(dim=0)[0]\n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([5.0883e-03, 8.1585e-03, 4.3802e-03, 3.5544e-03, 4.3949e-03, 3.5384e-03,\n",
       "        4.6042e-04, 5.5279e-03, 2.9600e-03, 1.0077e-04, 2.7982e-03, 2.7952e-03,\n",
       "        8.3778e-04, 3.7137e-03, 3.8124e-03, 2.9417e-03, 0.0000e+00, 3.5733e-03,\n",
       "        0.0000e+00, 3.5473e-03, 4.2139e-04, 7.0827e-03, 0.0000e+00, 8.0968e-03,\n",
       "        1.2436e-03, 4.5070e-04, 3.1641e-04, 5.4739e-03, 0.0000e+00, 7.3010e-03,\n",
       "        7.9257e-03, 0.0000e+00, 0.0000e+00, 1.9442e-03, 2.5030e-05, 9.4625e-04,\n",
       "        3.3356e-03, 7.5000e-03, 5.6323e-03, 7.4694e-03, 2.2197e-03, 1.1076e-02,\n",
       "        8.9971e-04, 5.5176e-03, 5.6259e-03, 0.0000e+00, 2.4363e-03, 5.9433e-03,\n",
       "        2.4236e-03, 5.3212e-03, 7.3526e-04, 5.9791e-03, 4.0593e-03, 6.9017e-03,\n",
       "        3.5334e-03, 1.0755e-02, 2.9385e-03, 6.2121e-03, 7.7667e-03, 4.8786e-03,\n",
       "        2.7011e-03, 0.0000e+00, 4.4211e-03, 3.1820e-03],\n",
       "       grad_fn=<MaxBackward0>),\n",
       "indices=tensor([29, 29, 29, 14, 29, 24, 28, 29, 30, 29, 28, 33, 33, 28, 21, 33,  0, 19,\n",
       "         0, 19, 19, 28,  0, 29, 29, 33, 23, 32,  0, 32, 32,  0,  0, 33,  8, 19,\n",
       "         7, 32, 28, 28, 21, 28, 33, 14, 28,  0, 23, 11, 29, 29, 23, 29,  7, 32,\n",
       "        28, 29, 23, 32, 32,  6, 30,  0, 29, 32]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = max_pooling_per_graph(embed, batch_0.batch, batch_0.frame_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = class_head(lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, path):\n",
    "    # Save the model, optimizer state, epoch, and loss\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f\"Checkpoint saved at {path}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded from {path}, at epoch {epoch}\")\n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import f1_score and matthews_corrcoef from sklearn\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "metric_0 = f1_score\n",
    "metric_1 = matthews_corrcoef\n",
    "\n",
    "if True:\n",
    "    # Training loop\n",
    "    actual_epoch = 0\n",
    "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    \n",
    "    \n",
    "\n",
    "if False:\n",
    "    # Load the model from a checkpoint\n",
    "    checkpoint_path = r'/gpfs/users/alvarezj/workdir/Project/Data/Checkpoints/GAT_Sniffin_Anal/checkpoint_epoch_170.pth'\n",
    "    actual_epoch = load_checkpoint(model, optimizer, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(log_dir='./deletefolder/runs/GAT_Following_w11_new_encoder_2')  # TensorBoard writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/7752 [00:03<2:32:21,  1.18s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(train_loader):\n\u001b[0;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 15\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     labels \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mbehaviour\n\u001b[0;32m     18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Code\\GitHubRep\\Behavioral_Tagging_of_Mice_in_multiple_Mice_dataset_using_Deep_Learning\\src\\models.py:285\u001b[0m, in \u001b[0;36mGraphClassifier.forward\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    284\u001b[0m     x, edge_index, frame_mask, graph_batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mx, batch\u001b[38;5;241m.\u001b[39medge_index, batch\u001b[38;5;241m.\u001b[39mframe_mask, batch\u001b[38;5;241m.\u001b[39mbatch\n\u001b[1;32m--> 285\u001b[0m     embbed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreadout \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    287\u001b[0m         embbed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_pooling_per_graph(embbed, graph_batch, frame_mask)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Code\\GitHubRep\\Behavioral_Tagging_of_Mice_in_multiple_Mice_dataset_using_Deep_Learning\\src\\models.py:43\u001b[0m, in \u001b[0;36mGATEncoder.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m---> 43\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGAT_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x1)\n\u001b[0;32m     45\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m x1\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py:302\u001b[0m, in \u001b[0;36mGATv2Conv.forward\u001b[1;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[0;32m    298\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_updater(edge_index, x\u001b[38;5;241m=\u001b[39m(x_l, x_r),\n\u001b[0;32m    299\u001b[0m                           edge_attr\u001b[38;5;241m=\u001b[39medge_attr)\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: PairTensor, alpha: Tensor)\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_r\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcat:\n\u001b[0;32m    305\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.gatv2_conv_GATv2Conv_propagate_arz1uqi2.py:167\u001b[0m, in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, x, alpha, size)\u001b[0m\n\u001b[0;32m    161\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage(\n\u001b[0;32m    162\u001b[0m     x_j\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mx_j,\n\u001b[0;32m    163\u001b[0m     alpha\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39malpha,\n\u001b[0;32m    164\u001b[0m )\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# Begin Message Forward Hook ###########################################\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_scripting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m    169\u001b[0m         hook_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    170\u001b[0m             x_j\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mx_j,\n\u001b[0;32m    171\u001b[0m             alpha\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39malpha,\n\u001b[0;32m    172\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch\\_jit_internal.py:1130\u001b[0m, in \u001b[0;36mis_scripting\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m7\u001b[39m):\n\u001b[0;32m   1127\u001b[0m     \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBroadcastingList\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m BroadcastingList1\n\u001b[1;32m-> 1130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_scripting\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;124;03m    Function that returns True when in compilation and False otherwise. This\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;124;03m    is useful especially with the @unused decorator to leave code in your\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;124;03m              return unsupported_linear_op(x)\u001b[39;00m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()  # Time the training\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    correct_class_0 = 0\n",
    "    correct_class_1 = 0\n",
    "    total_class_0 = 0\n",
    "    total_class_1 = 0\n",
    "    total = 0\n",
    "    i = 0\n",
    "\n",
    "    for data in tqdm.tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        labels = data.behaviour\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        predicted = outputs.argmax(dim=1)\n",
    "        correct_class_0 += (predicted[labels == 0] == labels[labels == 0]).sum().item()\n",
    "        correct_class_1 += (predicted[labels == 1] == labels[labels == 1]).sum().item()\n",
    "        total_class_0 += (labels == 0).sum().item()\n",
    "        total_class_1 += (labels == 1).sum().item()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Log training loss and accuracy at each step\n",
    "        if i % 100 == 0:  # Log every 100 iterations, adjust as needed\n",
    "            writer.add_scalar('Loss/Train', loss.item(), (actual_epoch + epoch) * len(train_loader) + i)\n",
    "            writer.add_scalar('Accuracy/Train', correct / total, (actual_epoch + epoch) * len(train_loader) + i)\n",
    "            # Metrics \n",
    "            writer.add_scalar('Metrics/Train/F1', metric_0(labels, predicted), (actual_epoch + epoch) * len(train_loader) + i)\n",
    "            writer.add_scalar('Metrics/Train/Matthews', metric_1(labels, predicted), (actual_epoch + epoch) * len(train_loader) + i)\n",
    "        i += 1\n",
    "\n",
    "    train_accuracy = correct / total\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + actual_epoch + 1}, Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    correct_class_0 = 0\n",
    "    correct_class_1 = 0\n",
    "    total_class_0 = 0\n",
    "    total_class_1 = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_data in tqdm.tqdm(test_loader):\n",
    "            val_outputs = model(val_data)\n",
    "            val_labels = val_data.behaviour\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "            val_predicted = val_outputs.argmax(dim=1)\n",
    "            correct_class_0 += (val_predicted[val_labels == 0] == val_labels[val_labels == 0]).sum().item()\n",
    "            correct_class_1 += (val_predicted[val_labels == 1] == val_labels[val_labels == 1]).sum().item()\n",
    "            total_class_0 += (val_labels == 0).sum().item()\n",
    "            total_class_1 += (val_labels == 1).sum().item()\n",
    "            correct += (val_predicted == val_labels).sum().item()\n",
    "            total += val_labels.size(0)\n",
    "\n",
    "    val_accuracy = correct / total\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Log validation metrics\n",
    "    writer.add_scalar('Loss/Validation', avg_val_loss, actual_epoch + epoch)\n",
    "    writer.add_scalar('Accuracy/Validation', val_accuracy, actual_epoch + epoch)\n",
    "    writer.add_scalar('Accuracy/Avarage_inactive_class_Validation', correct_class_0 / total_class_0, actual_epoch + epoch)\n",
    "    writer.add_scalar('Accuracy/Avarage_active_class_Validation', correct_class_1 / total_class_1, actual_epoch + epoch)\n",
    "    writer.add_scalar('Accuracy/Average_per_class_Validation', ((correct_class_0 / total_class_0) + (correct_class_1 / total_class_1)) / 2, actual_epoch + epoch)\n",
    "    # Metrics\n",
    "    writer.add_scalar('Metrics/Validation/F1', metric_0(val_labels, val_predicted), actual_epoch + epoch)\n",
    "    writer.add_scalar('Metrics/Validation/Matthews', metric_1(val_labels, val_predicted), actual_epoch + epoch)\n",
    "\n",
    "    # Step the scheduler\n",
    "    #scheduler.step()\n",
    "\n",
    "    # Log learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    writer.add_scalar('Learning Rate', current_lr, actual_epoch + epoch)\n",
    "    print(f\"Learning Rate after epoch {epoch + 1}: {current_lr}\")\n",
    "\n",
    "    # Save checkpoint after each 5 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch + actual_epoch + 1}.pth')\n",
    "        save_checkpoint(model, optimizer, epoch + 1, avg_train_loss, checkpoint_path)\n",
    "\n",
    "# Save the final model\n",
    "if num_epochs % 5 != 0:\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch + actual_epoch + 1}.pth')\n",
    "    save_checkpoint(model, optimizer, epoch + 1, avg_train_loss, checkpoint_path)\n",
    "\n",
    "# Time the training\n",
    "end_time = time.time()\n",
    "print(f\"Training took {end_time - start_time} seconds, for {num_epochs} epochs\")\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n",
    "\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "x, edge_index, batch, frame_mask = batch.x, batch.edge_index, batch.batch, batch.frame_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.SimpleMLPforGraph(n_in=144, n_hid=128, n_out=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainning loop\n",
    "num_epochs = 10\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(log_dir='runs/gcn_action_detection')  # TensorBoard writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, data in tqdm.tqdm(enumerate(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data).unsqueeze(0)\n",
    "        labels = data.y\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        train_loss += loss.item()\n",
    "        predicted = outputs.argmax(dim=1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        # Log training loss and accuracy at each step\n",
    "        if i % 10 == 0:  # Log every 10 iterations, adjust as needed\n",
    "            writer.add_scalar('Loss/Train', loss.item(), epoch * len(train_loader) + i)\n",
    "            writer.add_scalar('Accuracy/Train', correct / total, epoch * len(train_loader) + i)\n",
    "            #print(f\"Epoch {epoch+1}, Step {i}, Loss: {loss.item()}, Accuracy: {correct / total}\")\n",
    "\n",
    "    train_accuracy = correct / total\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_data in tqdm.tqdm(test_loader):\n",
    "            val_outputs = model(val_data).unsqueeze(0)\n",
    "            val_labels = val_data.y\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "            val_predicted = val_outputs.argmax(dim=1)\n",
    "            correct += (val_predicted == val_labels).sum().item()\n",
    "            total += val_labels.size(0)\n",
    "    \n",
    "    val_accuracy = correct / total\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    \n",
    "    print(f\"Validation Loss: {avg_val_loss}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Log validation metrics\n",
    "    writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/Validation', val_accuracy, epoch)\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i, data in tqdm.tqdm(enumerate(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        labels = data.y\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        train_loss += loss.item()\n",
    "        predicted = outputs.argmax(dim=1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "        # Log training loss and accuracy at each step\n",
    "        if i % 10 == 0:  # Log every 10 iterations, adjust as needed\n",
    "            writer.add_scalar('Loss/Train', loss.item(), epoch * len(train_loader) + i)\n",
    "            writer.add_scalar('Accuracy/Train', correct / total, epoch * len(train_loader) + i)\n",
    "            #print(f\"Epoch {epoch+1}, Step {i}, Loss: {loss.item()}, Accuracy: {correct / total}\")\n",
    "\n",
    "    train_accuracy = correct / total\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_data in test_loader:\n",
    "            val_outputs = model(val_data)\n",
    "            val_labels = val_data.y\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "            val_predicted = val_outputs.argmax(dim=1)\n",
    "            correct += (val_predicted == val_labels).sum().item()\n",
    "            total += val_labels.size(0)\n",
    "    \n",
    "    val_accuracy = correct / total\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    \n",
    "    print(f\"Validation Loss: {avg_val_loss}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Log validation metrics\n",
    "    writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/Validation', val_accuracy, epoch)\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning loop\n",
    "epochs = 50\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    las\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        out = model.forward(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = GraphAE.forward(data_loader.dataset[0].x, data_loader.dataset[0].edge_index, data_loader.dataset[0].frame_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss = GraphAE.loss(data_loader.dataset[0].x, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "encoder = models.GATEncoder(nout = 64, nhid=16, attention_hidden=2, n_in=3, dropout=0.5).to(device)\n",
    "print(encoder)\n",
    "decoder = models.GATDecoder(n_latent=64, n_hidden=16, n_out=3).to(device)\n",
    "print(decoder)\n",
    "model = models.GraphAE(encoder, decoder).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "data = data_loader.dataset\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    for i in range(len(data)):\n",
    "\n",
    "        out = model(data[i].x.to(device), data[i].edge_index.to(device), data[i].frame_mask.to(device))\n",
    "        loss = model.loss(data[i].x, out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch}, Loss {loss.item()}')\n",
    "\n",
    "model.eval()\n",
    "out = model(data[0].x, data[0].edge_index, data[0].frame_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyout = out[0][0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the output of the model, the first dimension are the points, and the second one is the x and y coordinates\n",
    "plt.scatter(numpyout[:,0], numpyout[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_loader.dataset[0].x.shape)\n",
    "print(x[0].shape)\n",
    "print(x[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_loader.dataset[0].x.shape)\n",
    "print(x[0].shape)\n",
    "print(x[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = behaviour.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dataloader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import time\n",
    "from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
    "# reload library\n",
    "import importlib\n",
    "import cv2\n",
    "#import utils as ut\n",
    "import pandas as pd\n",
    "import DataDLC\n",
    "from torch_geometric.data import Data, DataLoader, DataListLoader\n",
    "import tqdm\n",
    "import time\n",
    "import augmentation\n",
    "import sklearn\n",
    "# Import f1_score and matthews_corrcoef from sklearn\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import pickle as pkl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'augmentation' from 'c:\\\\Users\\\\Usuario\\\\Documents\\\\Documents\\\\MVA\\\\Stage\\\\DLCProject\\\\Code\\\\GitHubRep\\\\Behavioral_Tagging_of_Mice_in_multiple_Mice_dataset_using_Deep_Learning\\\\src\\\\augmentation.py'>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_15436\\1586004789.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\datasets\\dataset_w1.pkl', map_location=device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load the data\n",
    "dataset = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\datasets\\dataset_w1.pkl', map_location=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Index(['General_Contacts', 'Sniffing_R', 'Sniffing_head_R', 'Sniffing_other_R',\n",
    "    #    'Sniffing_anal_R', 'Poursuit_R', 'Dominance_R', 'Rearing_R',\n",
    "    #    'Grooming_R', 'Sniffing_V', 'Sniffing_head_V', 'Sniffing_other_V',\n",
    "    #    'Sniffing_anal_V', 'Poursuit_V', 'Dominance_V', 'Rearing_V',\n",
    "    #    'Grooming_V'],\n",
    "    #   dtype='object')\n",
    "# Select the behaviour to classify (Grooming in this case)\n",
    "indx_behaviour1 = 1\n",
    "indx_behaviour2 = 6\n",
    "\n",
    "# Select the behaviour to classify\n",
    "name_behaviour = dataset[0].behaviour_names[indx_behaviour1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#print('Selecting the behaviour')\n",
    "#for i in range(len(dataset)):\n",
    "#    dataset[i].behaviour = dataset[i].behaviour[indx_behaviour1]\n",
    "\n",
    "window_size = 5\n",
    "seq_dataset = dataloader.SequenceDataset(dataset, sequence_length=window_size)\n",
    "\n",
    "def split_dataset(dataset, split_ratio=0.8):\n",
    "    dataset.shuffle()  # Shuffle the sequences\n",
    "    split_idx = int(len(dataset) * split_ratio)\n",
    "    train_data = dataset.sequences[:split_idx]\n",
    "    test_data = dataset.sequences[split_idx:]\n",
    "    return train_data, test_data\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_data, test_data = split_dataset(seq_dataset, split_ratio=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset has 124219 samples\n",
      "The test dataset has 31055 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('The train dataset has %d samples' % len(train_data))\n",
    "print('The test dataset has %d samples' % len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[1][indx_behaviour1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation.merge_symetric_behaviours_sequences(indx_behaviour1, indx_behaviour2, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i in range(len(dataset)):\n",
    "    if dataset[i].behaviour[behaviour] == torch.tensor(1):\n",
    "        indices.append(i)\n",
    "# Symetric wrt y axis\n",
    "for indx in indices:\n",
    "    new_sample = dataset[indx].clone()\n",
    "    new_sample.x[:,0] = torch.tensor(1) - new_sample.x[:,0]\n",
    "    dataset.append(new_sample)\n",
    "# Symetric wrt x axis\n",
    "for indx in indices:\n",
    "    new_sample = dataset[indx].clone()\n",
    "    new_sample.x[:,1] = torch.tensor(1) - new_sample.x[:,1]\n",
    "    dataset.append(new_sample)\n",
    "# Transpose\n",
    "for indx in indices:\n",
    "    new_sample = dataset[indx].clone()\n",
    "    new_sample.x[:,0], new_sample.x[:,1] = new_sample.x[:,1], new_sample.x[:,0]\n",
    "    dataset.append(new_sample)\n",
    "# Rotate 180 degrees\n",
    "for indx in indices:\n",
    "    new_sample = dataset[indx].clone()\n",
    "    new_sample.x[:,0] = torch.tensor(1) - new_sample.x[:,0]\n",
    "    new_sample.x[:,1] = torch.tensor(1) - new_sample.x[:,1]\n",
    "    dataset.append(new_sample)\n",
    "return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Merging the behaviours')\n",
    "#augmentation.merge_symetric_behaviours_version2(indx_behaviour1, indx_behaviour2, train_dataset)\n",
    "#print('Generating rotation augmentation')\n",
    "# Rotate the dataset\n",
    "#augmentation.rotate_samples(train_dataset, indx_behaviour1)\n",
    "#print('Downsampling the inactive behaviours')\n",
    "#train_dataset = augmentation.downsample_majority_class(train_dataset, indx_behaviour1)\n",
    "                                                 \n",
    "# #for i in range(len(train_dataset)):\n",
    "#     train_dataset[i].behaviour = train_dataset[i].behaviour[indx_behaviour1]\n",
    "# for i in range(len(test_dataset)):\n",
    "#     test_dataset[i].behaviour = test_dataset[i].behaviour[indx_behaviour1]\n",
    "# print('Done selecting the behaviour')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset has 132973 samples\n",
      "The test dataset has 31055 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('The train dataset has %d samples' % len(train_data))\n",
    "print('The test dataset has %d samples' % len(test_data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# behaviour = [sample.behaviour for sample in train_dataset]\n",
    "# behaviour = np.array(behaviour)\n",
    "\n",
    "# weights_ = sklearn.utils.class_weight.compute_class_weight('balanced', classes = np.unique(behaviour), y = behaviour)\n",
    "# del behaviour\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "# Create the dataloaders for train, validation and test\n",
    "train_loader = DataListLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataListLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define the model\n",
    "model = models.GAT_LSTM(input_dim = 4, hidden_dim=64, lstm_hidden_dim=128, num_classes=1, num_nodes=36, heads=4)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print('The model has %d trainable parameters' % sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "\n",
    "# Directory to save the model checkpoints\n",
    "checkpoint_dir = r'/gpfs/users/alvarezj/workdir/Project/Data/Checkpoints/GAT_LSTM/%s' % name_behaviour\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, path):\n",
    "    # Save the model, optimizer state, epoch, and loss\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f\"Checkpoint saved at {path}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded from {path}, at epoch {epoch}\")\n",
    "    return epoch\n",
    "\n",
    "num_epochs = 200\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "if True:\n",
    "    # Training loop\n",
    "    actual_epoch = 0\n",
    "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    \n",
    "    \n",
    "\n",
    "if False:\n",
    "    # Load the model from a checkpoint\n",
    "    checkpoint_path = r'/gpfs/users/alvarezj/workdir/Project/Data/Checkpoints/GAT_Sniffin_Anal/checkpoint_epoch_170.pth'\n",
    "    actual_epoch = load_checkpoint(model, optimizer, checkpoint_path)\n",
    "\n",
    "#y = [d.behaviour.cpu().detach().numpy() for d in dataset]\n",
    "#y = np.array(y)\n",
    "#weight_ = sklearn.utils.class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
    "#weight_ = torch.tensor([0.55852461, 4.7717076]).to(device) # Grooming (before adding last analysis)\n",
    "#weight_ = torch.tensor([0.76221058, 1.45343216]).to(device) # Dominance (before adding last analysis)\n",
    "#weight_ = torch.tensor([0.58626763, 3.39795837]).to(device) # Rearing (before adding last analysis)\n",
    "#weight_ = torch.tensor([0.60796284, 2.81561145]).to(device) # Sniffing anal\n",
    "#weight_ = torch.tensor([0.66321035, 2.03176556]).to(device) # Following with only rotation augmentation\n",
    "#weight_ = torch.tensor([0.5331574 , 8.03979407]).to(device) # Following with merged behaviours only\n",
    "#print(' The class weights are: ', weight_)\n",
    "# Destroy y\n",
    "#criterion = nn.CrossEntropyLoss(weight=torch.tensor(weights_, dtype=torch.float32).to(device))\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy with logits\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "name_file = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "writer = SummaryWriter(log_dir=os.path.join('runs/GAT_LSTM/%s/' % name_behaviour, name_file))\n",
    "\n",
    "f = open(os.path.join('runs/GAT_LSTM/%s/' % name_behaviour, name_file, 'info.txt'), 'w')\n",
    "f.write('Dataset used: new_dataset_large.pkl\\n')\n",
    "f.write('Behaviour selected: %s\\n' % name_behaviour)\n",
    "f.write('Number of epochs: %d\\n' % num_epochs)\n",
    "f.write('Batch size: %d\\n' % batch_size)\n",
    "f.write('Learning rate: %f\\n' % lr)\n",
    "f.write('Window size: %d\\n' % window_size)\n",
    "f.write('Model used:%s\\n' % str(model))\n",
    "f.write('Number of trainable parameters: %d\\n' % sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "f.write('Criterion: BCEWithLogitsLoss\\n')\n",
    "f.write('Optimizer: Adam\\n')\n",
    "f.write('Scheduler: None\\n')\n",
    "f.write('Data augmentation: None\\n')\n",
    "#f.write('Class weights: %s\\n' % str(weights_))\n",
    "f.close()\n",
    "\n",
    "\n",
    "start_time = time.time()  # Time the training\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_idx = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Loop over each batch from the DataListLoader\n",
    "    for batch in tqdm.tqdm(train_loader):\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        # Unpack batch (sequence and label)\n",
    "        sequences, labels = zip(*batch)  # batch is a list of (sequence, label) tuples\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        output = model(sequences)\n",
    "\n",
    "        # Assuming labels are already tensors, no need to convert them again\n",
    "        labels = torch.tensor(labels, dtype=torch.float32).to(device).unsqueeze(1)  # Add singleton dimension for BCELoss\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Predictions and accuracy computation\n",
    "        predictions = torch.sigmoid(output).round()  # Convert logits to probabilities and round for binary\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        if batch_idx % 100 == 0:  # Log every 100 iterations, adjust as needed\n",
    "            # Log metrics to TensorBoard after each batch\n",
    "            writer.add_scalar('Loss/train', loss.item(), epoch * len(train_loader) + batch_idx)\n",
    "            writer.add_scalar('Accuracy/train', correct / total * 100, epoch * len(train_loader) + batch_idx)\n",
    "\n",
    "        batch_idx += 1\n",
    "\n",
    "    # Print epoch loss and training accuracy\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    accuracy_train = correct / total * 100\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy_train:.2f}%')\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_running_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_correct_class_0 = 0\n",
    "    val_correct_class_1 = 0\n",
    "    val_total_class_0 = 0\n",
    "    val_total_class_1 = 0\n",
    "    val_all_labels = []\n",
    "    val_all_predictions = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for validation\n",
    "        for val_batch in tqdm.tqdm(test_loader):\n",
    "            # Unpack validation batch\n",
    "            val_sequences, val_labels = zip(*val_batch)  # batch is a list of (sequence, label) tuples\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            val_output = model(val_sequences)\n",
    "\n",
    "            # Convert labels to tensor\n",
    "            val_labels = torch.tensor(val_labels, dtype=torch.float32).to(device).unsqueeze(1)  # Add singleton dimension for BCELoss\n",
    "\n",
    "            # Compute the loss\n",
    "            val_loss = criterion(val_output, val_labels)\n",
    "            val_running_loss += val_loss.item()\n",
    "\n",
    "            # Predictions and accuracy computation\n",
    "            val_predictions = torch.sigmoid(val_output).round()  # Convert logits to probabilities and round for binary\n",
    "            val_correct += (val_predictions == val_labels).sum().item()\n",
    "            val_total += val_labels.size(0)\n",
    "            val_correct_class_0 += (val_predictions[val_labels == 0] == val_labels[val_labels == 0]).sum().item()\n",
    "            val_correct_class_1 += (val_predictions[val_labels == 1] == val_labels[val_labels == 1]).sum().item()\n",
    "            val_total_class_0 += (val_labels == 0).sum().item()\n",
    "            val_total_class_1 += (val_labels == 1).sum().item()\n",
    "\n",
    "            # Store predictions and labels for metrics\n",
    "            val_all_labels.extend(val_labels.cpu().numpy())\n",
    "            val_all_predictions.extend(val_predictions.cpu().numpy())\n",
    "        \n",
    "\n",
    "    # Calculate validation metrics\n",
    "    f1_val = f1_score(val_all_labels, val_all_predictions)\n",
    "    mcc_val = matthews_corrcoef(val_all_labels, val_all_predictions)\n",
    "\n",
    "    # Print validation metrics\n",
    "    val_epoch_loss = val_running_loss / len(test_loader)\n",
    "    accuracy_val = val_correct / val_total * 100\n",
    "    print(f'Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {accuracy_val:.2f}%, F1 Score: {f1_val:.4f}, MCC: {mcc_val:.4f}')\n",
    "\n",
    "    # Log validation metrics to TensorBoard\n",
    "    writer.add_scalar('Loss/validation', val_epoch_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/validation', accuracy_val, epoch)\n",
    "    writer.add_scalar('Accuracy/Avarage_inactive_class_validation', val_correct_class_0 / val_total_class_0, epoch)\n",
    "    writer.add_scalar('Accuracy/Avarage_active_class_validation', val_correct_class_1 / val_total_class_1, epoch)\n",
    "    writer.add_scalar('Accuracy/Average_per_class_validation', ((val_correct_class_0 / val_total_class_0) + (val_correct_class_1 / val_total_class_1)) / 2, epoch)\n",
    "    writer.add_scalar('F1 Score/validation', f1_val, epoch)\n",
    "    writer.add_scalar('MCC/validation', mcc_val, epoch)\n",
    "\n",
    "    # Step the scheduler\n",
    "    #scheduler.step()\n",
    "\n",
    "    # # Log learning rate\n",
    "    # current_lr = optimizer.param_groups[0]['lr']\n",
    "    # writer.add_scalar('Learning Rate', current_lr, actual_epoch + epoch)\n",
    "    # print(f\"Learning Rate after epoch {epoch + 1}: {current_lr}\")\n",
    "\n",
    "    # Save checkpoint after each 5 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch + actual_epoch + 1}.pth')\n",
    "        save_checkpoint(model, optimizer, epoch + 1, epoch_loss, checkpoint_path)\n",
    "\n",
    "# Save the final model\n",
    "if num_epochs % 10 != 0:\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch + actual_epoch + 1}.pth')\n",
    "    save_checkpoint(model, optimizer, epoch + 1, epoch_loss, checkpoint_path)\n",
    "\n",
    "# Time the training\n",
    "end_time = time.time()\n",
    "print(f\"Training took {end_time - start_time} seconds, for {num_epochs} epochs\")\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n",
    "\n",
    "print(\"Training finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envProj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
