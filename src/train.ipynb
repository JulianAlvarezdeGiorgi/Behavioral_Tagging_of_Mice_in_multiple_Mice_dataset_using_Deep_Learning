{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the ENC-DEC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dataloader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import time\n",
    "from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
    "# reload library\n",
    "import importlib\n",
    "import cv2\n",
    "#import utils as ut\n",
    "import pandas as pd\n",
    "import DataDLC\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import tqdm\n",
    "import time\n",
    "import augmentation\n",
    "import sklearn\n",
    "\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import pickle as pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'DataDLC' from 'c:\\\\Users\\\\Usuario\\\\Documents\\\\Documents\\\\MVA\\\\Stage\\\\DLCProject\\\\Code\\\\GitHubRep\\\\Behavioral_Tagging_of_Mice_in_multiple_Mice_dataset_using_Deep_Learning\\\\src\\\\DataDLC.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dataloader)\n",
    "importlib.reload(models)\n",
    "importlib.reload(DataDLC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is only to create an eassy graph to test the build_graph_2 function**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    data_dlc.coords = data_dlc.coords.iloc[range(3), :]\n",
    "    data_dlc.n_frames = 3\n",
    "    data_dlc.save(r'C:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\DataLoaderTestFormat\\output1.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset\n",
    "\n",
    "**Obs:** This is just a test to see if the model is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print numpy version\n",
    "print(np.__version__)\n",
    "\n",
    "# print pytorch version\n",
    "print(torch.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dataloader)\n",
    "importlib.reload(DataDLC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataloader.reload_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deactivate warnings\n",
    "if False:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "    data_loader = dataloader.DLCDataLoader(r'C:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\DataLoaderTrainTest', batch_size=1, num_workers=0, device='cpu', window_size=3, stride = 1, build_graph=True)\n",
    "    #data_loader = dataloader.DLCDataLoader(r'C:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\DataLoaderTestDataset', batch_size=1, num_workers=0, device='cpu', window_size=3, stride = 1, build_graph=True, behaviour='contacts generaux (R + V) active')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "*Graphs were already created and saved in the data folder*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mdataset\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_27168\\348082568.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\datasets\\new_entire_dataset.pkl', map_location=device)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Load the data\n",
    "dataset = torch.load(r'c:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Data\\datasets\\new_entire_dataset.pkl', map_location=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 310077 samples\n"
     ]
    }
   ],
   "source": [
    "print('The dataset has %d samples' % len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the behaviour to classify (Grooming in this case)\n",
    "indx_behaviour1 = 1\n",
    "indx_behaviour2 = 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Train-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suffle the dataset\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Test split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "test_dataset = dataset[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248061\n",
      "62016\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sniffing_R'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].behaviour_names[indx_behaviour1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class balance in the training set is:\n",
      "(array([0, 1], dtype=int64), array([132337, 115724], dtype=int64))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class balance in the training set\n",
    "behaviour = [sample.behaviour[indx_behaviour1] for sample in train_dataset]\n",
    "behaviour = np.array(behaviour)\n",
    "print('The class balance in the training set is:')\n",
    "print(np.unique(behaviour, return_counts=True))\n",
    "\n",
    "plt.hist(behaviour, bins=2)\n",
    "plt.title('Class balance in the training set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging the behaviours\n",
      "Generating rotation augmentation\n"
     ]
    }
   ],
   "source": [
    "print('Merging the behaviours')\n",
    "augmentation.merge_symetric_behaviours_version2(indx_behaviour1, indx_behaviour2, train_dataset)\n",
    "print('Generating rotation augmentation')\n",
    "# Rotate the dataset\n",
    "augmentation.rotate_samples(train_dataset, indx_behaviour1)\n",
    "#print('Downsampling the inactive behaviours')\n",
    "#train_dataset = augmentation.downsample_majority_class(train_dataset, indx_behaviour1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done selecting the behaviour\n"
     ]
    }
   ],
   "source": [
    "                                                \n",
    "for i in range(len(train_dataset)):\n",
    "    train_dataset[i].behaviour = train_dataset[i].behaviour[indx_behaviour1]\n",
    "for i in range(len(test_dataset)):\n",
    "    test_dataset[i].behaviour = test_dataset[i].behaviour[indx_behaviour1]\n",
    "print('Done selecting the behaviour')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset has 248061 samples\n",
      "The test dataset has 62016 samples\n"
     ]
    }
   ],
   "source": [
    "print('The train dataset has %d samples' % len(train_dataset))\n",
    "print('The test dataset has %d samples' % len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class balance in the training set is:\n",
      "(array([0, 1], dtype=int64), array([122801, 125260], dtype=int64))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class balance in the training set\n",
    "behaviour = [sample.behaviour for sample in train_dataset]\n",
    "behaviour = np.array(behaviour)\n",
    "print('The class balance in the training set is:')\n",
    "print(np.unique(behaviour, return_counts=True))\n",
    "\n",
    "plt.hist(behaviour, bins=2)\n",
    "plt.title('Class balance in the training set')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute weights for the loss function\n",
    "\n",
    "\n",
    "weights = sklearn.utils.class_weight.compute_class_weight('balanced', classes = np.unique(behaviour), y = behaviour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights for the loss function are:\n",
      "[1.01001213 0.99018442]\n"
     ]
    }
   ],
   "source": [
    "print('The weights for the loss function are:')\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Create the dataloaders for train, validation and test\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from 'c:\\\\Users\\\\Usuario\\\\Documents\\\\Documents\\\\MVA\\\\Stage\\\\DLCProject\\\\Code\\\\GitHubRep\\\\Behavioral_Tagging_of_Mice_in_multiple_Mice_dataset_using_Deep_Learning\\\\src\\\\models.py'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "graphencoder = models.GATEncoder(nout = 64, nhid=32, attention_hidden=2, n_in=4, dropout=0.5)\n",
    "class_head = models.ClassificationHead(n_latent=64, nhid = 32, nout = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 24962 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model = models.GraphClassifier(graphencoder, class_head, readout = 'mean')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print('The model has %d trainable parameters' % sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling_per_graph(embbed, batch, frame_mask):\n",
    "    ''' Mean pooling of the embeddings per graph, only the central frame '''\n",
    "    out = []\n",
    "    for i in range(batch.max()+1):\n",
    "        out.append(embbed[batch==i][frame_mask[batch==i] == frame_mask[batch==i].median()].mean(dim=0))\n",
    "    return torch.stack(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_0 = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[5760, 4], edge_index=[2, 124416], file=[32], frame_mask=[5760], behaviour=[32], behaviour_names=[32], batch=[5760], ptr=[33])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = graphencoder(batch_0.x, batch_0.edge_index, batch_0.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5760, 64])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = mean_pooling_per_graph(embed, batch_0.batch, batch_0.frame_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = class_head(lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save the model checkpoints\n",
    "checkpoint_dir = r'./deletefolder/checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, path):\n",
    "    # Save the model, optimizer state, epoch, and loss\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f\"Checkpoint saved at {path}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded from {path}, at epoch {epoch}\")\n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import f1_score and matthews_corrcoef from sklearn\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "metric_0 = f1_score\n",
    "metric_1 = matthews_corrcoef\n",
    "\n",
    "if True:\n",
    "    # Training loop\n",
    "    actual_epoch = 0\n",
    "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    \n",
    "    \n",
    "\n",
    "if False:\n",
    "    # Load the model from a checkpoint\n",
    "    checkpoint_path = r'/gpfs/users/alvarezj/workdir/Project/Data/Checkpoints/GAT_Sniffin_Anal/checkpoint_epoch_170.pth'\n",
    "    actual_epoch = load_checkpoint(model, optimizer, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor(weights, dtype=torch.float32).to(device))\n",
    "writer = SummaryWriter(log_dir='./deletefolder/runs/GAT_Following_w11_new_encoder_2')  # TensorBoard writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/7752 [00:03<2:26:09,  1.13s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(train_loader):\n\u001b[0;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 15\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     labels \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mbehaviour\n\u001b[0;32m     18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Code\\GitHubRep\\Behavioral_Tagging_of_Mice_in_multiple_Mice_dataset_using_Deep_Learning\\src\\models.py:237\u001b[0m, in \u001b[0;36mGraphClassifier.forward\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    236\u001b[0m     x, edge_index, frame_mask, graph_batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mx, batch\u001b[38;5;241m.\u001b[39medge_index, batch\u001b[38;5;241m.\u001b[39mframe_mask, batch\u001b[38;5;241m.\u001b[39mbatch\n\u001b[1;32m--> 237\u001b[0m     embbed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreadout \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    239\u001b[0m         embbed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_pooling_per_graph(embbed, graph_batch, frame_mask)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\Documents\\MVA\\Stage\\DLCProject\\Code\\GitHubRep\\Behavioral_Tagging_of_Mice_in_multiple_Mice_dataset_using_Deep_Learning\\src\\models.py:41\u001b[0m, in \u001b[0;36mGATEncoder.forward\u001b[1;34m(self, x, edge_index, frame_mask)\u001b[0m\n\u001b[0;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres_conn[\u001b[38;5;241m0\u001b[39m](x) \u001b[38;5;241m+\u001b[39m x1\n\u001b[0;32m     40\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres_conn[\u001b[38;5;241m1\u001b[39m](x)\n\u001b[1;32m---> 41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgatenc2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py:298\u001b[0m, in \u001b[0;36mGATv2Conv.forward\u001b[1;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    293\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe usage of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd_self_loops\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimultaneously is currently not yet supported for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    295\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseTensor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m form\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;66;03m# edge_updater_type: (x: PairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_updater\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_r\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m                          \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: PairTensor, alpha: Tensor)\u001b[39;00m\n\u001b[0;32m    302\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39m(x_l, x_r), alpha\u001b[38;5;241m=\u001b[39malpha)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.gatv2_conv_GATv2Conv_edge_updater_o4f0_ki3.py:169\u001b[0m, in \u001b[0;36medge_updater\u001b[1;34m(self, edge_index, x, edge_attr, size)\u001b[0m\n\u001b[0;32m    159\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[0;32m    160\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_j\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    161\u001b[0m                 x_i\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_i\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    166\u001b[0m             )\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# End Edge Update Forward Pre Hook #########################################\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_j\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_j\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# Begin Edge Update Forward Hook ###########################################\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py:338\u001b[0m, in \u001b[0;36mGATv2Conv.edge_update\u001b[1;34m(self, x_j, x_i, edge_attr, index, ptr, dim_size)\u001b[0m\n\u001b[0;32m    335\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m edge_attr\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels)\n\u001b[0;32m    336\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m edge_attr\n\u001b[1;32m--> 338\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaky_relu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_slope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m alpha \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    340\u001b[0m alpha \u001b[38;5;241m=\u001b[39m softmax(alpha, index, ptr, dim_size)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\envProj\\Lib\\site-packages\\torch\\nn\\functional.py:1663\u001b[0m, in \u001b[0;36mleaky_relu\u001b[1;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[0;32m   1650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m   1653\u001b[0m celu_ \u001b[38;5;241m=\u001b[39m _add_docstr(\n\u001b[0;32m   1654\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcelu_,\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1659\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m,\n\u001b[0;32m   1660\u001b[0m )\n\u001b[1;32m-> 1663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mleaky_relu\u001b[39m(\u001b[38;5;28minput\u001b[39m: Tensor, negative_slope: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m, inplace: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:  \u001b[38;5;66;03m# noqa: D400,D402\u001b[39;00m\n\u001b[0;32m   1664\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1665\u001b[0m \u001b[38;5;124;03m    leaky_relu(input, negative_slope=0.01, inplace=False) -> Tensor\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1670\u001b[0m \u001b[38;5;124;03m    See :class:`~torch.nn.LeakyReLU` for more details.\u001b[39;00m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()  # Time the training\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    correct_class_0 = 0\n",
    "    correct_class_1 = 0\n",
    "    total_class_0 = 0\n",
    "    total_class_1 = 0\n",
    "    total = 0\n",
    "    i = 0\n",
    "\n",
    "    for data in tqdm.tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        labels = data.behaviour\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        predicted = outputs.argmax(dim=1)\n",
    "        correct_class_0 += (predicted[labels == 0] == labels[labels == 0]).sum().item()\n",
    "        correct_class_1 += (predicted[labels == 1] == labels[labels == 1]).sum().item()\n",
    "        total_class_0 += (labels == 0).sum().item()\n",
    "        total_class_1 += (labels == 1).sum().item()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Log training loss and accuracy at each step\n",
    "        if i % 100 == 0:  # Log every 100 iterations, adjust as needed\n",
    "            writer.add_scalar('Loss/Train', loss.item(), (actual_epoch + epoch) * len(train_loader) + i)\n",
    "            writer.add_scalar('Accuracy/Train', correct / total, (actual_epoch + epoch) * len(train_loader) + i)\n",
    "            # Metrics \n",
    "            writer.add_scalar('Metrics/Train/F1', metric_0(labels, predicted), (actual_epoch + epoch) * len(train_loader) + i)\n",
    "            writer.add_scalar('Metrics/Train/Matthews', metric_1(labels, predicted), (actual_epoch + epoch) * len(train_loader) + i)\n",
    "        i += 1\n",
    "\n",
    "    train_accuracy = correct / total\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + actual_epoch + 1}, Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    correct_class_0 = 0\n",
    "    correct_class_1 = 0\n",
    "    total_class_0 = 0\n",
    "    total_class_1 = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_data in tqdm.tqdm(test_loader):\n",
    "            val_outputs = model(val_data)\n",
    "            val_labels = val_data.behaviour\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "            val_predicted = val_outputs.argmax(dim=1)\n",
    "            correct_class_0 += (val_predicted[val_labels == 0] == val_labels[val_labels == 0]).sum().item()\n",
    "            correct_class_1 += (val_predicted[val_labels == 1] == val_labels[val_labels == 1]).sum().item()\n",
    "            total_class_0 += (val_labels == 0).sum().item()\n",
    "            total_class_1 += (val_labels == 1).sum().item()\n",
    "            correct += (val_predicted == val_labels).sum().item()\n",
    "            total += val_labels.size(0)\n",
    "\n",
    "    val_accuracy = correct / total\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Log validation metrics\n",
    "    writer.add_scalar('Loss/Validation', avg_val_loss, actual_epoch + epoch)\n",
    "    writer.add_scalar('Accuracy/Validation', val_accuracy, actual_epoch + epoch)\n",
    "    writer.add_scalar('Accuracy/Avarage_inactive_class_Validation', correct_class_0 / total_class_0, actual_epoch + epoch)\n",
    "    writer.add_scalar('Accuracy/Avarage_active_class_Validation', correct_class_1 / total_class_1, actual_epoch + epoch)\n",
    "    writer.add_scalar('Accuracy/Average_per_class_Validation', ((correct_class_0 / total_class_0) + (correct_class_1 / total_class_1)) / 2, actual_epoch + epoch)\n",
    "    # Metrics\n",
    "    writer.add_scalar('Metrics/Validation/F1', metric_0(val_labels, val_predicted), actual_epoch + epoch)\n",
    "    writer.add_scalar('Metrics/Validation/Matthews', metric_1(val_labels, val_predicted), actual_epoch + epoch)\n",
    "\n",
    "    # Step the scheduler\n",
    "    #scheduler.step()\n",
    "\n",
    "    # Log learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    writer.add_scalar('Learning Rate', current_lr, actual_epoch + epoch)\n",
    "    print(f\"Learning Rate after epoch {epoch + 1}: {current_lr}\")\n",
    "\n",
    "    # Save checkpoint after each 5 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch + actual_epoch + 1}.pth')\n",
    "        save_checkpoint(model, optimizer, epoch + 1, avg_train_loss, checkpoint_path)\n",
    "\n",
    "# Save the final model\n",
    "if num_epochs % 5 != 0:\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch + actual_epoch + 1}.pth')\n",
    "    save_checkpoint(model, optimizer, epoch + 1, avg_train_loss, checkpoint_path)\n",
    "\n",
    "# Time the training\n",
    "end_time = time.time()\n",
    "print(f\"Training took {end_time - start_time} seconds, for {num_epochs} epochs\")\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n",
    "\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "x, edge_index, batch, frame_mask = batch.x, batch.edge_index, batch.batch, batch.frame_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.SimpleMLPforGraph(n_in=144, n_hid=128, n_out=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainning loop\n",
    "num_epochs = 10\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(log_dir='runs/gcn_action_detection')  # TensorBoard writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, data in tqdm.tqdm(enumerate(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data).unsqueeze(0)\n",
    "        labels = data.y\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        train_loss += loss.item()\n",
    "        predicted = outputs.argmax(dim=1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        # Log training loss and accuracy at each step\n",
    "        if i % 10 == 0:  # Log every 10 iterations, adjust as needed\n",
    "            writer.add_scalar('Loss/Train', loss.item(), epoch * len(train_loader) + i)\n",
    "            writer.add_scalar('Accuracy/Train', correct / total, epoch * len(train_loader) + i)\n",
    "            #print(f\"Epoch {epoch+1}, Step {i}, Loss: {loss.item()}, Accuracy: {correct / total}\")\n",
    "\n",
    "    train_accuracy = correct / total\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_data in tqdm.tqdm(test_loader):\n",
    "            val_outputs = model(val_data).unsqueeze(0)\n",
    "            val_labels = val_data.y\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "            val_predicted = val_outputs.argmax(dim=1)\n",
    "            correct += (val_predicted == val_labels).sum().item()\n",
    "            total += val_labels.size(0)\n",
    "    \n",
    "    val_accuracy = correct / total\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    \n",
    "    print(f\"Validation Loss: {avg_val_loss}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Log validation metrics\n",
    "    writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/Validation', val_accuracy, epoch)\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i, data in tqdm.tqdm(enumerate(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        labels = data.y\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        train_loss += loss.item()\n",
    "        predicted = outputs.argmax(dim=1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "        # Log training loss and accuracy at each step\n",
    "        if i % 10 == 0:  # Log every 10 iterations, adjust as needed\n",
    "            writer.add_scalar('Loss/Train', loss.item(), epoch * len(train_loader) + i)\n",
    "            writer.add_scalar('Accuracy/Train', correct / total, epoch * len(train_loader) + i)\n",
    "            #print(f\"Epoch {epoch+1}, Step {i}, Loss: {loss.item()}, Accuracy: {correct / total}\")\n",
    "\n",
    "    train_accuracy = correct / total\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_data in test_loader:\n",
    "            val_outputs = model(val_data)\n",
    "            val_labels = val_data.y\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "            val_predicted = val_outputs.argmax(dim=1)\n",
    "            correct += (val_predicted == val_labels).sum().item()\n",
    "            total += val_labels.size(0)\n",
    "    \n",
    "    val_accuracy = correct / total\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    \n",
    "    print(f\"Validation Loss: {avg_val_loss}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Log validation metrics\n",
    "    writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/Validation', val_accuracy, epoch)\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning loop\n",
    "epochs = 50\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    las\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        out = model.forward(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = GraphAE.forward(data_loader.dataset[0].x, data_loader.dataset[0].edge_index, data_loader.dataset[0].frame_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss = GraphAE.loss(data_loader.dataset[0].x, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "encoder = models.GATEncoder(nout = 64, nhid=16, attention_hidden=2, n_in=3, dropout=0.5).to(device)\n",
    "print(encoder)\n",
    "decoder = models.GATDecoder(n_latent=64, n_hidden=16, n_out=3).to(device)\n",
    "print(decoder)\n",
    "model = models.GraphAE(encoder, decoder).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "data = data_loader.dataset\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    for i in range(len(data)):\n",
    "\n",
    "        out = model(data[i].x.to(device), data[i].edge_index.to(device), data[i].frame_mask.to(device))\n",
    "        loss = model.loss(data[i].x, out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch}, Loss {loss.item()}')\n",
    "\n",
    "model.eval()\n",
    "out = model(data[0].x, data[0].edge_index, data[0].frame_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyout = out[0][0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the output of the model, the first dimension are the points, and the second one is the x and y coordinates\n",
    "plt.scatter(numpyout[:,0], numpyout[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_loader.dataset[0].x.shape)\n",
    "print(x[0].shape)\n",
    "print(x[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_loader.dataset[0].x.shape)\n",
    "print(x[0].shape)\n",
    "print(x[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = behaviour.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
